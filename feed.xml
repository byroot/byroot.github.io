<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://byroot.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://byroot.github.io/" rel="alternate" type="text/html" /><updated>2025-01-05T10:39:53+00:00</updated><id>https://byroot.github.io/feed.xml</id><title type="html">byroot’s blog</title><subtitle>Various ramblings.</subtitle><entry><title type="html">Optimizing Ruby’s JSON, Part 5</title><link href="https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 5" /><published>2025-01-04T19:28:51+00:00</published><updated>2025-01-04T19:28:51+00:00</updated><id>https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html"><![CDATA[<p><a href="/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html">In the previous post</a>, we showed how we eliminated two <code class="language-plaintext highlighter-rouge">malloc/free</code> pairs of calls
when generating small JSON documents, and how that put us ahead of Oj when reusing the <code class="language-plaintext highlighter-rouge">JSON::State</code> object.</p>

<p>But that API isn’t the one people use, so if we wanted to come out ahead in the micro-benchmarks users might perform themselves, we had to
find a way to get rid of that <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation too, or to somehow make it faster.</p>

<h2 id="typed-data">Typed Data</h2>

<p>Because that <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation, isn’t just about any allocation. In Ruby, everything is an object, but not all objects are created equal.
In previous parts I touched on how some objects aren’t actually allocated, and called “immediates”, I also touched on how core objects like <code class="language-plaintext highlighter-rouge">String</code> and
<code class="language-plaintext highlighter-rouge">Array</code> have both “embedded” and “heap” representations.</p>

<p><code class="language-plaintext highlighter-rouge">JSON::State</code> is a type defined in C from the extension, using the <code class="language-plaintext highlighter-rouge">TypedData</code> API. <a href="https://blog.peterzhu.ca/ruby-c-ext-part-7/">Peter Zhu has a great blog post that goes in-depth into
how these work and how to use them</a>, but I’ll offer a quicker explanation here.</p>

<p>To define a custom object type, you start by defining a C structure that holds the type metadata:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="n">rb_data_type_t</span> <span class="n">JSON_Generator_State_type</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"JSON/Generator/State"</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="p">.</span><span class="n">dmark</span> <span class="o">=</span> <span class="n">State_mark</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dfree</span> <span class="o">=</span> <span class="n">State_free</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dsize</span> <span class="o">=</span> <span class="n">State_memsize</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dcompact</span> <span class="o">=</span> <span class="n">State_compact</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">RUBY_TYPED_WB_PROTECTED</span> <span class="o">|</span> <span class="n">RUBY_TYPED_FREE_IMMEDIATELY</span> <span class="o">|</span> <span class="n">RUBY_TYPED_FROZEN_SHAREABLE</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure>

<p>You can read Peter’s post if you want to know all the juicy details, but in short, it’s a collection of flags and callbacks to instruct the GC
on how to deal with this object. For instance <code class="language-plaintext highlighter-rouge">State_mark</code> allows the GC to list all the references this object has to other objects.</p>

<p>And then you define an allocator function, that will replace the default <code class="language-plaintext highlighter-rouge">Class#allocate</code> method for that class when you register it with <code class="language-plaintext highlighter-rouge">rb_define_alloc_func</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_s_allocate</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">klass</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">TypedData_Make_Struct</span><span class="p">(</span>
      <span class="n">klass</span><span class="p">,</span>
      <span class="n">JSON_Generator_State</span><span class="p">,</span>
      <span class="o">&amp;</span><span class="n">JSON_Generator_State_type</span><span class="p">,</span>
      <span class="n">state</span>
    <span class="p">);</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">buffer_initial_length</span> <span class="o">=</span> <span class="n">FBUFFER_INITIAL_LENGTH_DEFAULT</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">obj</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// snip...</span>

<span class="kt">void</span> <span class="nf">Init_generator</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">mJSON</span> <span class="o">=</span> <span class="n">rb_define_module</span><span class="p">(</span><span class="s">"JSON"</span><span class="p">);</span>
    <span class="n">VALUE</span> <span class="n">mExt</span> <span class="o">=</span> <span class="n">rb_define_module_under</span><span class="p">(</span><span class="n">mJSON</span><span class="p">,</span> <span class="s">"Ext"</span><span class="p">);</span>
    <span class="n">VALUE</span> <span class="n">mGenerator</span> <span class="o">=</span> <span class="n">rb_define_module_under</span><span class="p">(</span><span class="n">mExt</span><span class="p">,</span> <span class="s">"Generator"</span><span class="p">);</span>

    <span class="n">cState</span> <span class="o">=</span> <span class="n">rb_define_class_under</span><span class="p">(</span><span class="n">mGenerator</span><span class="p">,</span> <span class="s">"State"</span><span class="p">,</span> <span class="n">rb_cObject</span><span class="p">);</span>
    <span class="n">rb_define_alloc_func</span><span class="p">(</span><span class="n">cState</span><span class="p">,</span> <span class="n">cState_s_allocate</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">TypedData_Make_Struct</code> macro takes care of allocating a <code class="language-plaintext highlighter-rouge">40B</code> object slots of type <code class="language-plaintext highlighter-rouge">T_DATA</code>, as well as to call <code class="language-plaintext highlighter-rouge">ruby_xcalloc(sizeof(JSON_Generator_State))</code>
so we have some heap memory to store the object state.</p>

<p>The difference between <code class="language-plaintext highlighter-rouge">calloc</code> and <code class="language-plaintext highlighter-rouge">malloc</code>, is that when you use <code class="language-plaintext highlighter-rouge">malloc</code>, the memory that is allocated for you is left as is, with whatever data was
in it when it was last freed. Whereas <code class="language-plaintext highlighter-rouge">calloc</code> will do some extra work to fill that memory with zeros.</p>

<p>The struct used to interpret the content of the <code class="language-plaintext highlighter-rouge">40B</code> slot is <a href="https://github.com/ruby/ruby/blob/c936699431477a565b9e4036bc3b1fc186ac9918/include/ruby/internal/core/rtypeddata.h#L350-L371"><code class="language-plaintext highlighter-rouge">RTypedData</code> defined in <code class="language-plaintext highlighter-rouge">rtypeddata.h</code></a>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">RTypedData</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">RBasic</span> <span class="n">basic</span><span class="p">;</span>
    <span class="k">const</span> <span class="n">rb_data_type_t</span> <span class="o">*</span><span class="k">const</span> <span class="n">type</span><span class="p">;</span>
    <span class="k">const</span> <span class="n">VALUE</span> <span class="n">typed_flag</span><span class="p">;</span>
    <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>type</th>
      <th>typed_flag</th>
      <th>*data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x0c</td>
      <td>0xffeff</td>
      <td>0xbbbef</td>
      <td>0x1</td>
      <td>0xcccdef</td>
    </tr>
  </tbody>
</table>

<p>As for the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct, it’s a simple struct holding our configuration, for a total of <code class="language-plaintext highlighter-rouge">72B</code> on 64-bit platforms:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">JSON_Generator_StateStruct</span> <span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">indent</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">space</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">space_before</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">object_nl</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">array_nl</span><span class="p">;</span>

    <span class="kt">long</span> <span class="n">max_nesting</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">depth</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">buffer_initial_length</span><span class="p">;</span>

    <span class="n">bool</span> <span class="n">allow_nan</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">ascii_only</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">script_safe</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">strict</span><span class="p">;</span>
<span class="p">}</span> <span class="n">JSON_Generator_State</span><span class="p">;</span></code></pre></figure>

<p>With this explanation, you may have understood that it’s not a simple object allocation we’re dealing with, but a noticeably more expensive operation.
This can be easily confirmed by profiling yet again:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>If we consider the cost of the object slot allocation, plus the heap allocation, and also the extra cost of Ruby’s GC having to call
<code class="language-plaintext highlighter-rouge">ruby_xfree</code> when these objects are garbage collected, it all amounts to practically 30% of the overall runtime, which is massive:</p>

<p><img src="/assets/articles/json-5/json-state-alloc-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/40odFp1">Full profile</a></p>

<p>In addition, you can see inside <code class="language-plaintext highlighter-rouge">rb_class_new_instance_pass_kw</code> that we’re spending quite a bit of time inside <code class="language-plaintext highlighter-rouge">rb_call0</code>.
That’s because when you call <code class="language-plaintext highlighter-rouge">.new</code> on a Ruby class, it pretty much works like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Class</span>
  <span class="k">def</span> <span class="nf">new</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="n">allocate</span>
    <span class="n">instance</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:initialize</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="n">instance</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>But as of Ruby 3.4, this logic is implemented in C, so it can’t benefit from an inline cache and other niceties,
instead, it has to rely on the Global Call Cache Cache Table, but also forwards arguments from C, which isn’t the most efficient.</p>

<p>That’s why <a href="https://github.com/ruby/ruby/pull/9289">Aaron Patterson has been trying to reimplement <code class="language-plaintext highlighter-rouge">Class#new</code> in Ruby</a>, but it’s not quite ready yet.</p>

<h2 id="embeding-rtypeddata">Embeding RTypedData</h2>

<p>As you might have noticed on the flame graph, allocating the object slot really is the least of our problems, it’s really the heap allocation and
deallocation that’s impacting performance very negatively.
Given that the existing API somewhat imposes a <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation, if we can’t eliminate it, we can instead try to make it cheaper.</p>

<p>Since our <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> is only <code class="language-plaintext highlighter-rouge">72B</code>, with the extra <code class="language-plaintext highlighter-rouge">32B</code> imposed by <code class="language-plaintext highlighter-rouge">RTypedData</code> it could theoretically fit in a <code class="language-plaintext highlighter-rouge">160B</code> slot,
which would be perfect.</p>

<p>Back in 2023, <a href="https://github.com/ruby/ruby/pull/7440">I paired with Peter on allowing <code class="language-plaintext highlighter-rouge">TypedData</code> objects to be embeded</a>,
and we used that new capability to embed various core classes, <a href="https://github.com/ruby/ruby/pull/7440">the most notable one being <code class="language-plaintext highlighter-rouge">Time</code></a>, and it
did almost cut the cost of <code class="language-plaintext highlighter-rouge">Time.now</code> in half:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|                        |compare-ruby|built-ruby|
|:-----------------------|-----------:|---------:|
|Time.now                |     12.150M|   22.025M|
|                        |           -|     1.81x|
|Time.now(in: "+09:00")  |      3.545M|    4.794M|
|                        |           -|     1.35x|
</code></pre></div></div>

<p>So embedding <code class="language-plaintext highlighter-rouge">JSON::State</code> would be a big win with very little effort.
I’d just need to add <code class="language-plaintext highlighter-rouge">RUBY_TYPED_EMBEDDABLE</code> in the <code class="language-plaintext highlighter-rouge">JSON_Generator_State_type</code>, and remove the <code class="language-plaintext highlighter-rouge">ruby_xfree</code> call in <code class="language-plaintext highlighter-rouge">State_free</code>, and that’s it,
the setup cost would be cut in half.</p>

<p>Except there was one problem: we never made <code class="language-plaintext highlighter-rouge">RUBY_TYPED_EMBEDDABLE</code> a public API, as we thought it might be too easy to shoot yourself in
the foot with it, and we didn’t want to expose the C API users to a whole new class of hard-to-understand crashes.</p>

<p>Embedded objects are hard to use from C because, since Ruby 2.7, Ruby’s GC is capable of compacting the heap, which means moving live objects from one
slot to another. So when working in C with an embedded object, you have to be very careful not to hold onto a native pointer that is pointing inside
the object slot, because if the GC moves the object, the pointer you previously got is now pointing inside a totally different object, which can
cause all sorts of memory corruption issues, and from experience these are among the hardest bugs to investigate and fix.</p>

<p>Maybe we should still expose this API, it could definitely lead to some nice performance gains for some native gems, but that requires some careful
considerations, and would take time. When I was working on this patch, we were already almost in November, way too late in the Ruby release cycle to
hope to get a decision before the Ruby 3.4 release.</p>

<p>So that wasn’t a viable option, I needed to find another solution.</p>

<h2 id="using-a-t_object">Using a T_OBJECT</h2>

<p>That’s where I thought about using a “regular” object, AKA a <code class="language-plaintext highlighter-rouge">T_OBJECT</code>. That’s the internal type of all the objects you define in pure Ruby,
and as long as you define all the instance variables in the <code class="language-plaintext highlighter-rouge">initialize</code> method, they’re pretty much guaranteed to be embedded too.</p>

<p>After all, I recently moved the <code class="language-plaintext highlighter-rouge">State#configure</code> method from C into Ruby, I could go further and turn
<code class="language-plaintext highlighter-rouge">JSON::State</code> into a PORO. That would for sure make it much faster to allocate and initialize, plus it would benefit from JIT, and would allow sharing
more code with the JRuby and TruffleRuby implementations of <code class="language-plaintext highlighter-rouge">JSON.generate</code>.</p>

<p>But while the instantiation would get faster, access to the <code class="language-plaintext highlighter-rouge">JSON::State</code> fields from C would get slower, and that is for two reasons.</p>

<p>First, all the native fields in the struct, like <code class="language-plaintext highlighter-rouge">long depth</code>, would now need to be boxed (<a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html#boxing-day">I explained what it means in part 3</a>).
So that means some small overhead for every access, but it would probably be negligible.</p>

<p>The real problem would be uncached instance variable lookups. Because to look up an instance variable, just like for methods,
you need quite a bit of work. Here again, you can check <a href="https://railsatscale.com/2023-10-24-memoization-pattern-and-object-shapes/">my previous post on Object Shapes to understand why</a>.</p>

<p>When that lookup is done from Ruby code, we benefit from inline caches, so most of the time it’s just an integer comparison to revalidate the cache,
and then a simple memory read at an offset.</p>

<p>But when looking up the instance variables of an object from C extensions, the only possible API is <code class="language-plaintext highlighter-rouge">rb_ivar_get</code>, so that means no inline caches.
Contrary to uncached method lookups, you have no equivalent to the Global Call Cache Cache Table for instance variables, you have to go through a
full lookup every time. It’s less expensive than for a method, but still, you have to walk up the shape tree, so that’s potentially a lot of pointer
chasing.</p>

<p>If there was a C API to do cached instance variable lookups, I think using a <code class="language-plaintext highlighter-rouge">T_OBJECT</code> would have been a great solution, but since it isn’t
the case, I quickly gave up on the idea, it wasn’t even worth prototyping and profiling, and I 100% expected it not to perform well enough.</p>

<p>I also quickly considered using a Ruby <code class="language-plaintext highlighter-rouge">Struct</code> class, as those aren’t <code class="language-plaintext highlighter-rouge">T_OBJECT</code> but <code class="language-plaintext highlighter-rouge">T_STRUCT</code>, they’re also embedded, but the position of each
member is stored in an Array, so in some cases, it can be a bit faster to look up uncached, but I wasn’t hopeful it would move the needle enough.</p>

<h2 id="reusing-state">Reusing State</h2>

<p>If I couldn’t make the allocation faster, another avenue would be to find a way to reuse the object.</p>

<p>Technically, the <code class="language-plaintext highlighter-rouge">JSON::State</code> is mutable, and the various <code class="language-plaintext highlighter-rouge">#to_json</code> methods are free to add arbitrary fields into it, like some sort of Hash,
as a way to pass information around. But in practice, no-one really uses that, so I was OK with considering such a minor breaking change.</p>

<p>But a bigger challenge was JSON’s global configuration.</p>

<p>If you look at the <code class="language-plaintext highlighter-rouge">JSON.generate</code> method:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">opts</span>
  <span class="k">else</span>
    <span class="n">state</span> <span class="o">=</span> <span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">end</span>
  <span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>It would be easy to avoid allocating a new <code class="language-plaintext highlighter-rouge">State</code> object when <code class="language-plaintext highlighter-rouge">opts</code> is <code class="language-plaintext highlighter-rouge">nil</code> and instead use a single immutable <code class="language-plaintext highlighter-rouge">State</code> object.
That would definitely speed up <code class="language-plaintext highlighter-rouge">JSON.generate</code> enough to get ahead on all or at least most micro-benchmarks.</p>

<p>But even though the benchmarks inside <code class="language-plaintext highlighter-rouge">ruby/json</code> call <code class="language-plaintext highlighter-rouge">JSON.generate</code>, a lot of code out there, and presumably other people’s benchmarks might just as
well call <code class="language-plaintext highlighter-rouge">JSON.dump</code>, and in such case, <code class="language-plaintext highlighter-rouge">opts</code> wouldn’t be <code class="language-plaintext highlighter-rouge">nil</code>, but set to <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> or another Hash derived from it, hence that
optimization would be out the window pretty quickly.</p>

<p>I toyed with various ideas on how I could detect changes to <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> to keep a cached <code class="language-plaintext highlighter-rouge">JSON::State</code> object around,
but that’s not realistic because it defaults to a mutable hash, so I’d need to monkey-patch dozens of methods to be notified when it is mutated.</p>

<p>As a side note, I really hate <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code>. It’s really not a good idea to
globally change how a library behaves like this, as the various other libraries that depend on the <code class="language-plaintext highlighter-rouge">json</code> gem likely don’t expect it at all.
I’d like to deprecate it for the next major version, but we’ll see.</p>

<h2 id="lazy-allocation">Lazy Allocation</h2>

<p>At that point, I had been thinking about this problem for a few days, with no real solution in sight, until it hit me: the <code class="language-plaintext highlighter-rouge">JSON::State</code> only needs to be
allocated if a <code class="language-plaintext highlighter-rouge">#to_json</code> method has to be called, and it’s not that frequent.
If you are using some serialization framework in the style of Active Model Serializers, it most likely already converts all objects that don’t directly
map to a JSON type into some more primitive Ruby objects that are serializable without having to call <code class="language-plaintext highlighter-rouge">#to_json</code> on them.</p>

<p>Similarly, if you use Rails JSON rendering, likely via something like <code class="language-plaintext highlighter-rouge">render json: obj</code>, <a href="https://github.com/rails/rails/blob/e64e5d31cdeafee142e32e604b513a39de779651/activesupport/lib/active_support/json/encoding.rb#L57-L88">it first converts the given object tree into primitive types</a>,
so here again, <code class="language-plaintext highlighter-rouge">#to_json</code> calls are unlikely.</p>

<p>Overall, if <code class="language-plaintext highlighter-rouge">#to_json</code> needs to be called, we’re likely not in a situation where that one extra allocation will make a measurable difference.</p>

<p>But even if we don’t need to allocate the <code class="language-plaintext highlighter-rouge">JSON::State</code> instance, we still need to have some memory somewhere for a <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct,
because our C code needs to be able to check the configuration somehow.
Since it’s only <code class="language-plaintext highlighter-rouge">72B</code>, it can very comfortably fit in the C stack, making it close to free.</p>

<p>The downside though, is that <a href="/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html#jump-tables">the <code class="language-plaintext highlighter-rouge">State#configure</code> method we moved from C to Ruby in part two</a>,
well <a href="https://github.com/ruby/json/commit/5c0d428d4c518e651edd3d57dca83ab601944505">it had to go back to C</a>.
I was a bit sad, but as we say here, sometimes you need to take a step back in order to take a big jump forward.</p>

<p>The next step was to introduce a new internal API to allow to bypass <code class="language-plaintext highlighter-rouge">State#generate</code>, so that <code class="language-plaintext highlighter-rouge">JSON.generate</code> was now:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
    <span class="n">opts</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
  <span class="k">else</span>
    <span class="no">State</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>By calling into a class method, we don’t require the allocation.
For the pure-Ruby version of the generator, it didn’t change much, as there would be now way to elide the allocation, so I implemented
<code class="language-plaintext highlighter-rouge">JSON::Pure::State.generate</code> in a fairly obvious way:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">module</span> <span class="nn">JSON</span>
  <span class="k">module</span> <span class="nn">Pure</span>
    <span class="k">module</span> <span class="nn">Generator</span>
    <span class="k">class</span> <span class="nc">State</span>
      <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
        <span class="n">new</span><span class="p">(</span><span class="n">opts</span><span class="p">).</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>For the C extension, this allowed to allocate the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> on the stack:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_m_generate</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">klass</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">obj</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">opts</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">JSON_Generator_State</span> <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
    <span class="n">state_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">state</span><span class="p">);</span>
    <span class="n">configure_state</span><span class="p">(</span><span class="o">&amp;</span><span class="n">state</span><span class="p">,</span> <span class="n">opts</span><span class="p">);</span>
    <span class="kt">char</span> <span class="n">stack_buffer</span><span class="p">[</span><span class="n">FBUFFER_STACK_SIZE</span><span class="p">];</span>
    <span class="n">FBuffer</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
    <span class="n">fbuffer_stack_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffer</span><span class="p">,</span> <span class="n">state</span><span class="p">.</span><span class="n">buffer_initial_length</span><span class="p">,</span> <span class="n">stack_buffer</span><span class="p">,</span> <span class="n">FBUFFER_STACK_SIZE</span><span class="p">);</span>
    <span class="k">struct</span> <span class="n">generate_json_data</span> <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">buffer</span><span class="p">,</span>
        <span class="p">.</span><span class="n">vstate</span> <span class="o">=</span> <span class="n">Qfalse</span><span class="p">,</span>
        <span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">state</span><span class="p">,</span>
        <span class="p">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">obj</span><span class="p">,</span>
        <span class="p">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">generate_json</span><span class="p">,</span>
    <span class="p">};</span>
    <span class="n">rb_rescue</span><span class="p">(</span><span class="n">generate_json_try</span><span class="p">,</span> <span class="p">(</span><span class="n">VALUE</span><span class="p">)</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span> <span class="n">generate_json_rescue</span><span class="p">,</span> <span class="p">(</span><span class="n">VALUE</span><span class="p">)</span><span class="o">&amp;</span><span class="n">data</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">fbuffer_to_s</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffer</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>If you are unfamiliar with the <code class="language-plaintext highlighter-rouge">state = {0};</code> syntax, it’s asking the compiler to zero out the memory it allocated on the stack, because otherwise
our struct would just be initialized with whatever was left on the stack, which isn’t great.</p>

<p>The other important thing to notice here is the <code class="language-plaintext highlighter-rouge">struct generate_json_data</code>, which is defined as this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="p">{</span>
    <span class="n">FBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">vstate</span><span class="p">;</span>
    <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">obj</span><span class="p">;</span>
    <span class="n">generator_func</span> <span class="n">func</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<p>That structure isn’t new, it was there before the patch, but you can notice it has both <code class="language-plaintext highlighter-rouge">JSON_Generator_State *state</code>, in other words, a pointer
to the struct holding our configuration, and <code class="language-plaintext highlighter-rouge">VALUE vstate</code> which is a reference to the <code class="language-plaintext highlighter-rouge">TypedData</code> that holds the pointer.</p>

<p>It’s a bit of a duplication, but that avoids some pointer chasing every time the code needs to check if some configuration flag is set.</p>

<p>The <code class="language-plaintext highlighter-rouge">vstate</code> used to be initialized to <code class="language-plaintext highlighter-rouge">self</code>, but now we initialize it to <code class="language-plaintext highlighter-rouge">Qfalse</code>, which conceptually is the global reference to Ruby’s singleton
<code class="language-plaintext highlighter-rouge">false</code> object. But in practice <code class="language-plaintext highlighter-rouge">false</code> is an immediate, and simply <code class="language-plaintext highlighter-rouge">0</code>.</p>

<p>With that in place, I could then implement the lazy initialization. A lot of internal functions used to receive the <code class="language-plaintext highlighter-rouge">vstate</code> as an argument, and in C
arguments are passed by copy, so if I wanted to lazily allocate the <code class="language-plaintext highlighter-rouge">State</code> object, it had to be passed by reference instead.</p>

<p>In short, it meant changing the signature of many functions like this:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gd">- static void generate_json_integer(FBuffer *buffer, VALUE Vstate, JSON_Generator_State *state, VALUE obj)
</span><span class="gi">+ static void generate_json_integer(FBuffer *buffer, struct generate_json_data *data, JSON_Generator_State *state, VALUE obj)</span></code></pre></figure>

<p>And then change the one place where we call <code class="language-plaintext highlighter-rouge">#to_json</code>, to use a new <code class="language-plaintext highlighter-rouge">vstate_get</code> helper:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gd">- tmp = rb_funcall(obj, i_to_json, 1, Vstate);
</span><span class="gi">+ tmp = rb_funcall(obj, i_to_json, 1, vstate_get(data));</span></code></pre></figure>

<p>Which is in concept very similar to the class memoization pattern in Ruby:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">vstate_spill</span><span class="p">(</span><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">vstate</span> <span class="o">=</span> <span class="n">cState_s_allocate</span><span class="p">(</span><span class="n">cState</span><span class="p">);</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">vstate</span><span class="p">);</span>
    <span class="n">MEMCPY</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">state</span><span class="p">,</span> <span class="n">JSON_Generator_State</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">data</span><span class="o">-&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">;</span>
    <span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span> <span class="o">=</span> <span class="n">vstate</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">VALUE</span> <span class="nf">vstate_get</span><span class="p">(</span><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">vstate_spill</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>As always, C code makes it a bit cryptic, but you should be able to recognize the memoization pattern in <code class="language-plaintext highlighter-rouge">vstate_get</code>.</p>

<p>As for <code class="language-plaintext highlighter-rouge">vstate_spill</code>, spilling is a term often used when moving data from registers onto the RAM because it can’t fit there anymore.
Similarly here, we’re “spilling” the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct from the stack onto the heap.</p>

<p>We also update the <code class="language-plaintext highlighter-rouge">data-&gt;state</code> pointer, so that if the <code class="language-plaintext highlighter-rouge">#to_json</code> method we called mutate the configuration,
it’s immediately reflected (but please don’t do this, I beg you).</p>

<p>As predicted by the flame graph, avoiding this allocation had a massive impact on micro-benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   506.104k i/100ms
Calculating -------------------------------------
               after      5.389M (± 0.2%) i/s  (185.57 ns/i) -     27.330M in   5.071556s

Comparison:
              before:  3113113.5 i/s
               after:  5388830.4 i/s - 1.73x  faster
</code></pre></div></div>

<p>Enough of a jump that <code class="language-plaintext highlighter-rouge">JSON.generate</code> performance was now almost on par with re-using the <code class="language-plaintext highlighter-rouge">JSON::State</code> object, and a bit ahead of <code class="language-plaintext highlighter-rouge">Oj</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                json   613.914k i/100ms
        json (reuse)   624.068k i/100ms
                  oj   545.935k i/100ms
Calculating -------------------------------------
                json      6.550M (± 0.1%) i/s  (152.67 ns/i) -     33.151M in   5.061360s
        json (reuse)      6.667M (± 0.1%) i/s  (149.99 ns/i) -     33.700M in   5.054534s
                  oj      5.822M (± 0.1%) i/s  (171.76 ns/i) -     29.480M in   5.063498s

Comparison:
                json:  6549898.9 i/s
        json (reuse):  6667228.7 i/s - 1.02x  faster
                  oj:  5822168.8 i/s - 1.12x  slower
</code></pre></div></div>

<p>And now, the setup cost was finally almost invisible on the flame graph:</p>

<p><img src="/assets/articles/json-5/final-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4abYzY8">Full profile</a></p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>This was the final optimization done to the generator worth detailing here.</p>

<p>Hence, I can finally start talking about the parser in the next part.</p>

<p>I think I’ll only need two, maybe three parts for the parsing side.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, we showed how we eliminated two malloc/free pairs of calls when generating small JSON documents, and how that put us ahead of Oj when reusing the JSON::State object.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 4</title><link href="https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 4" /><published>2024-12-29T18:21:51+00:00</published><updated>2024-12-29T18:21:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html"><![CDATA[<p><a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html">In the previous post</a>, we established that as long as <code class="language-plaintext highlighter-rouge">ruby/json</code> wasn’t competitive on
micro-benchmarks, public perception wouldn’t change. Since what made <code class="language-plaintext highlighter-rouge">ruby/json</code> appear so bad on micro-benchmarks was its setup cost, we had to
find ways to reduce it further.</p>

<h2 id="spot-the-seven-differences">Spot the Seven Differences</h2>

<p>So I decided to file <a href="https://github.com/ruby/json/issues/655">this performance discrepancy as a bug</a>, and investigate it as such and started
profiling Stephen’s micro-benchmark with both <code class="language-plaintext highlighter-rouge">ruby/json</code> and <code class="language-plaintext highlighter-rouge">oj</code>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"small mixed"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span></code></pre></figure>

<p>As mentioned in previous parts, I expected the extra allocation would be the main issue, and that re-using the <code class="language-plaintext highlighter-rouge">JSON::State</code> object would
put us on par with <code class="language-plaintext highlighter-rouge">Oj</code>, but it’s always good to revalidate our assumptions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
        json (reuse)   467.051k i/100ms
                json   252.570k i/100ms
                  oj   529.741k i/100ms
Calculating -------------------------------------
        json (reuse)      4.857M (± 1.9%) i/s  (205.88 ns/i) -     24.287M in   5.001995s
                json      2.689M (± 0.5%) i/s  (371.86 ns/i) -     13.639M in   5.071865s
                  oj      5.860M (± 0.6%) i/s  (170.65 ns/i) -     29.665M in   5.062753s

Comparison:
        json (reuse):  4857171.1 i/s
                  oj:  5859811.8 i/s - 1.21x  faster
                json:  2689181.9 i/s - 1.81x  slower
</code></pre></div></div>

<p>Even without that extra allocation, we were still 20% slower, that was unexpected, and should be fixed before exploring ways to eliminate the <code class="language-plaintext highlighter-rouge">State</code> allocation.</p>

<p>As always, this meant profiling, but this time I profiled both <code class="language-plaintext highlighter-rouge">ruby/json</code> and <code class="language-plaintext highlighter-rouge">Oj</code> to see where the difference might be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="n">state</span> <span class="o">=</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><a href="https://share.firefox.dev/3W29huf">Full profile</a></p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"oj"</span>

<span class="no">Oj</span><span class="p">.</span><span class="nf">default_options</span> <span class="o">=</span> <span class="no">Oj</span><span class="p">.</span><span class="nf">default_options</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">mode: :compat</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">Oj</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><a href="https://share.firefox.dev/40d4VTH">Full profile</a></p>

<p>Once I got the two profiles, it was a matter of playing “Spot the seven differences”.</p>

<p><img src="/assets/articles/json-4/oj-flamegraph.png" alt="" /></p>

<p><img src="/assets/articles/json-4/json-flamegraph.png" alt="" /></p>

<p>Something that jumped to me quite quickly, is that on that micro-benchmark, even though we’re re-using our <code class="language-plaintext highlighter-rouge">JSON::State</code> object,
we still spend a significant amount of time allocating and freeing our internal buffer. Still, on the <code class="language-plaintext highlighter-rouge">Oj</code> profile, there wasn’t
any <code class="language-plaintext highlighter-rouge">malloc</code> or <code class="language-plaintext highlighter-rouge">free</code> call. This suggested that <code class="language-plaintext highlighter-rouge">Oj</code> re-used a persistent buffer across calls or allocated it on the stack.</p>

<p>A quick investigation of <code class="language-plaintext highlighter-rouge">Oj</code>’s source code confirmed it was the latter:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">_out</span> <span class="p">{</span>
    <span class="kt">char</span>      <span class="n">stack_buffer</span><span class="p">[</span><span class="mi">4096</span><span class="p">];</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">buf</span><span class="p">;</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">end</span><span class="p">;</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">cur</span><span class="p">;</span>
    <span class="c1">// ...</span>
<span class="p">}</span> <span class="o">*</span><span class="n">Out</span><span class="p">;</span>

<span class="c1">// ...</span>

<span class="cm">/* Document-method: dump
 * call-seq: dump(obj, options={})
 *
 * Dumps an Object (obj) to a string.
 * - *obj* [_Object_] Object to serialize as an JSON document String
 * - *options* [_Hash_] same as default_options
 */</span>
<span class="k">static</span> <span class="n">VALUE</span> <span class="nf">dump</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">argv</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">dump_arg</span> <span class="n">arg</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">_out</span>     <span class="n">out</span><span class="p">;</span> <span class="c1">// Stack allocation</span>
    <span class="k">struct</span> <span class="n">_options</span> <span class="n">copts</span> <span class="o">=</span> <span class="n">oj_default_options</span><span class="p">;</span>
    <span class="c1">// ...</span>
<span class="p">}</span></code></pre></figure>

<h2 id="stack-and-heap">Stack and Heap</h2>

<p>Since this post is intended for people not necessarily familiar with C, I need to explain a bit what the stack and the heap are.
This is just meant as a quick introduction.</p>

<p>The heap is most of the RAM available on your system, if you need memory to store some data, you call <code class="language-plaintext highlighter-rouge">malloc(number_of_bytes)</code>
and get a pointer back that is at least as big as the number of bytes you asked for, and once you are done with it you call <code class="language-plaintext highlighter-rouge">free(pointer)</code>.</p>

<p>There are many different allocators (e.g. <code class="language-plaintext highlighter-rouge">jemalloc</code>, <code class="language-plaintext highlighter-rouge">tcmalloc</code>), using various algorithms and techniques to keep track of which memory is used and
how large each allocated chunk is, but even with the best allocators, <code class="language-plaintext highlighter-rouge">malloc</code> and <code class="language-plaintext highlighter-rouge">free</code> are somewhat costly. In addition, if you don’t know upfront
how much memory you actually need, you might need to call <code class="language-plaintext highlighter-rouge">new_pointer = realloc(pointer, new_size)</code> to allocate a larger chunk and copy the content
over and free the old chunk, this is fairly expensive.</p>

<p>And for Ruby C extensions specifically, you generally don’t use <code class="language-plaintext highlighter-rouge">malloc / free / realloc</code>, but <code class="language-plaintext highlighter-rouge">ruby_xmalloc / ruby_xfree / ruby_xrealloc</code>,
which are wrappers around the standard functions which additionally update Ruby GC statistics, so that the GC can trigger after some
threshold is reached which can further increase the cost of heap allocations.</p>

<p>On the other hand, the stack is a memory region that’s preallocated for each native thread, and that is used to store the current state of a function,
such as local variables while calling another function. For instance, if you have a function <code class="language-plaintext highlighter-rouge">f</code> with two <code class="language-plaintext highlighter-rouge">int64_t</code> local variables <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>,
<code class="language-plaintext highlighter-rouge">a</code> will be stored at <code class="language-plaintext highlighter-rouge">stack_pointer + 0</code> and <code class="language-plaintext highlighter-rouge">b</code> at <code class="language-plaintext highlighter-rouge">stack_pointer + 8</code>. And if <code class="language-plaintext highlighter-rouge">f</code> calls into another function <code class="language-plaintext highlighter-rouge">f2</code>, the stack pointer will be
incremented by <code class="language-plaintext highlighter-rouge">16</code> before entering <code class="language-plaintext highlighter-rouge">f2</code>, and restored back to its previous value when returning from <code class="language-plaintext highlighter-rouge">f2</code>.</p>

<p>This makes stack allocations essentially free, at least compared to heap allocations, and it’s almost guaranteed data stored there will be in the CPU
cache as it’s a very “hot” memory region.</p>

<p>But stack allocation isn’t a silver bullet, first because whenever you return from the function that memory should be considered freed, so in many
cases that’s not suitable. You can also not resize (<code class="language-plaintext highlighter-rouge">realloc</code>) it from a callee function.
Additionally, the stack is limited in size.
On most modern UNIX-like systems you got a fairly generous <code class="language-plaintext highlighter-rouge">8MiB</code> of stack space for the main thread, but only <code class="language-plaintext highlighter-rouge">1MiB</code> on Windows.
And most systems give less stack space to additional threads, for instance, Alpine Linux which uses the <code class="language-plaintext highlighter-rouge">musl libc</code> only gives
<code class="language-plaintext highlighter-rouge">128kiB</code> of stack space to additional threads, which really isn’t a lot. That’s why it’s not rare for Ruby C extension maintainers
to get Alpine-specific bug reports.</p>

<h2 id="stack-allocated-buffer-struct">Stack Allocated Buffer Struct</h2>

<p>So stack allocations should be used carefully and reasonably, the conventional wisdom being to not allocate more than <code class="language-plaintext highlighter-rouge">1kiB</code> on the stack, and to only
do it in leaf functions (that don’t call any other functions), or functions that only call into a few known functions.</p>

<p>In our case, the <code class="language-plaintext highlighter-rouge">JSON::State#generate</code> method isn’t a leaf function, and might call into arbitrary Ruby code if it needs to call <code class="language-plaintext highlighter-rouge">#to_json</code> or
<code class="language-plaintext highlighter-rouge">#to_s</code> on an object, so <code class="language-plaintext highlighter-rouge">4kiB</code> seemed a bit excessive to me, but still, we could use stack allocations reasonably to gain some performance.</p>

<p><code class="language-plaintext highlighter-rouge">ruby/json</code> wasn’t just doing one <code class="language-plaintext highlighter-rouge">malloc+free</code> call, but two. The first one in <code class="language-plaintext highlighter-rouge">cState_prepare_buffer</code> allocates the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct, which
contains the buffer metadata, such as its capacity:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">FBufferStruct</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">initial_length</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">capa</span><span class="p">;</span>
<span class="p">}</span> <span class="n">FBuffer</span><span class="p">;</span></code></pre></figure>

<p>That struct being just <code class="language-plaintext highlighter-rouge">32B</code> large, it makes a lot of sense to allocate it on the stack, which would save a pair of <code class="language-plaintext highlighter-rouge">malloc+free</code> calls,
and only increase the stack size by a negligible amount.</p>

<p><a href="https://github.com/ruby/json/pull/657/">You can see the diff</a>, it’s not complicated but requires a lot of small changes across the
codebase. Additionally, since the parser also used <code class="language-plaintext highlighter-rouge">FBuffer</code>, it had to be modified too to embed the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct inside the <code class="language-plaintext highlighter-rouge">JSON_ParserStruct</code>
instead of just keeping a pointer.</p>

<p>The gains were pretty good for such a small change:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   265.435k i/100ms
Calculating -------------------------------------
               after      2.831M (± 1.2%) i/s  (353.28 ns/i) -     14.333M in   5.064502s

Comparison:
              before:  2630445.8 i/s
               after:  2830628.7 i/s - 1.08x  faster
</code></pre></div></div>

<p>But still not enough.</p>

<h2 id="efficient-integer-printing">Efficient Integer Printing</h2>

<p>Before continuing on reducing the setup cost, another thing that surprised me on that profile was the <code class="language-plaintext highlighter-rouge">3.6%</code> spent in <code class="language-plaintext highlighter-rouge">fltoa</code>.
Not that <code class="language-plaintext highlighter-rouge">3.6%</code> is anywhere near a hotspot, but that’s a bit much for such a simple function.
If you are not familiar with C naming conventions, you may wonder what this function is doing. In the C standard library you have
several functions to parse strings as various integer types, such as <code class="language-plaintext highlighter-rouge">atoi</code>, <code class="language-plaintext highlighter-rouge">atol</code>, and <code class="language-plaintext highlighter-rouge">atoll</code>, for <code class="language-plaintext highlighter-rouge">int</code>, <code class="language-plaintext highlighter-rouge">long</code> and <code class="language-plaintext highlighter-rouge">long long</code>
respectively. Why <code class="language-plaintext highlighter-rouge">ato</code>? Because these functions assume a stream of ASCII encoded bytes<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, hence “ASCII to int” -&gt; <code class="language-plaintext highlighter-rouge">atoi</code>. That’s also probably
where the Ruby <code class="language-plaintext highlighter-rouge">#to_i</code> method got its name from.</p>

<p>So here, <code class="language-plaintext highlighter-rouge">fltoa</code> is a <code class="language-plaintext highlighter-rouge">long to ASCII</code> conversion function, and <code class="language-plaintext highlighter-rouge">f</code> is just the namespace for the <code class="language-plaintext highlighter-rouge">fbuffer.h</code> file.</p>

<p>Let’s have a look at how it is done:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">freverse</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">c</span><span class="p">;</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">end</span> <span class="o">&gt;</span> <span class="n">start</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">c</span> <span class="o">=</span> <span class="o">*</span><span class="n">end</span><span class="p">,</span> <span class="o">*</span><span class="n">end</span><span class="o">--</span> <span class="o">=</span> <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="o">*</span><span class="n">start</span><span class="o">++</span> <span class="o">=</span> <span class="n">c</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">long</span> <span class="nf">fltoa</span><span class="p">(</span><span class="kt">long</span> <span class="n">number</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">buf</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">static</span> <span class="kt">char</span> <span class="n">digits</span><span class="p">[]</span> <span class="o">=</span> <span class="s">"0123456789"</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">sign</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="kt">char</span><span class="o">*</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">buf</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="n">number</span> <span class="o">=</span> <span class="o">-</span><span class="n">number</span><span class="p">;</span>
    <span class="k">do</span> <span class="o">*</span><span class="n">tmp</span><span class="o">++</span> <span class="o">=</span> <span class="n">digits</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">];</span> <span class="k">while</span> <span class="p">(</span><span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span><span class="n">tmp</span><span class="o">++</span> <span class="o">=</span> <span class="sc">'-'</span><span class="p">;</span>
    <span class="n">freverse</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">tmp</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">tmp</span> <span class="o">-</span> <span class="n">buf</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_append_long</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">long</span> <span class="n">number</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">20</span><span class="p">];</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>There’s something quite odd here. First, we allocate a <code class="language-plaintext highlighter-rouge">20B</code> buffer on the stack, write the number in reverse in the buffer, reverse the string
and finally copy the stack buffer onto the output buffer.</p>

<p>In Ruby, it would look like:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">DIGITS</span> <span class="o">=</span> <span class="p">(</span><span class="sc">'0'</span><span class="p">..</span><span class="sc">'9'</span><span class="p">).</span><span class="n">to_a</span>

<span class="n">def</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
  <span class="n">negative</span> <span class="o">=</span> <span class="n">number</span><span class="p">.</span><span class="n">negative</span><span class="o">?</span>
  <span class="n">number</span> <span class="o">=</span> <span class="n">number</span><span class="p">.</span><span class="n">abs</span>

  <span class="n">buffer</span> <span class="o">=</span> <span class="s">""</span><span class="p">.</span><span class="n">b</span>

  <span class="n">loop</span> <span class="k">do</span>
    <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">DIGITS</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">]</span>
    <span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span>
    <span class="k">break</span> <span class="k">if</span> <span class="n">number</span><span class="p">.</span><span class="n">zero</span><span class="o">?</span>
  <span class="n">end</span>

  <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s">"-"</span> <span class="k">if</span> <span class="n">negative</span>

  <span class="n">buffer</span><span class="p">.</span><span class="n">reverse</span><span class="o">!</span>
  <span class="n">buffer</span>
<span class="n">end</span></code></pre></figure>

<p>Writing the number in reverse can be a useful trick if you are appending it to an existing buffer of dynamic length because you don’t know upfront
how long the number will be nor where the buffer ends.</p>

<p>But here we’re writing inside a stack buffer of known size and then copying the result, so it’s a bit wasteful.</p>

<p>Instead <a href="https://github.com/ruby/json/pull/656">we can write in the stack buffer backward, starting from the end of the buffer</a>,
and save on having to reverse the digits at the end.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">long</span> <span class="nf">fltoa</span><span class="p">(</span><span class="kt">long</span> <span class="n">number</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">buf</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">static</span> <span class="k">const</span> <span class="kt">char</span> <span class="n">digits</span><span class="p">[]</span> <span class="o">=</span> <span class="s">"0123456789"</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">sign</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="kt">char</span><span class="o">*</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">buf</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="n">number</span> <span class="o">=</span> <span class="o">-</span><span class="n">number</span><span class="p">;</span>
    <span class="k">do</span> <span class="o">*</span><span class="n">tmp</span><span class="o">--</span> <span class="o">=</span> <span class="n">digits</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">];</span> <span class="k">while</span> <span class="p">(</span><span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span><span class="n">tmp</span><span class="o">--</span> <span class="o">=</span> <span class="sc">'-'</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">buf</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#define LONG_BUFFER_SIZE 20
</span><span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_append_long</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">long</span> <span class="n">number</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="n">LONG_BUFFER_SIZE</span><span class="p">];</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">buffer_end</span> <span class="o">=</span> <span class="n">buf</span> <span class="o">+</span> <span class="n">LONG_BUFFER_SIZE</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">,</span> <span class="n">buffer_end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">buffer_end</span> <span class="o">-</span> <span class="n">len</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>Here again, it’s a small optimization on a very specific part of the generator, so I crafted a micro-benchmark to see if it had the expected benefits:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"integers"</span><span class="p">,</span> <span class="p">(</span><span class="mi">1_000_000</span><span class="o">..</span><span class="mi">1_001_000</span><span class="p">).</span><span class="nf">to_a</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding integers (8009 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after     9.770k i/100ms
Calculating -------------------------------------
               after     97.929k (± 0.9%) i/s   (10.21 μs/i) -    498.270k in   5.088542s

Comparison:
              before:    88309.9 i/s
               after:    97928.6 i/s - 1.11x  faster
</code></pre></div></div>

<p>Not bad, probably will only be noticeable for documents containing lots of large integers, but also a very simple optimization.</p>

<p>This can probably be optimized further by writing directly in the output buffer so that we don’t need to copy, and maybe even use <code class="language-plaintext highlighter-rouge">log</code> to
compute upfront how many digits the number has, but that was good enough for now, so I went back to reduce setup cost.</p>

<h2 id="using-an-rstring-as-buffer">Using an RString as Buffer</h2>

<p>So I went to profile Stephen’s micro-benchmark again:</p>

<p><img src="/assets/articles/json-4/json-flamegraph-2.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4a4oocr">Full profile</a></p>

<p>As you can see, we’re now calling <code class="language-plaintext highlighter-rouge">malloc</code> and <code class="language-plaintext highlighter-rouge">free</code> half as much, but still 100% more than <code class="language-plaintext highlighter-rouge">Oj</code>, and once we’re done filling our buffer,
we copy all its content in another memory region managed by Ruby when calling <code class="language-plaintext highlighter-rouge">str_enc_new</code> (actually <code class="language-plaintext highlighter-rouge">rb_utf8_str_new</code>, but the profiler doesn’t see it because of inlining).</p>

<p>On micro-benchmarks the copy is negligible, but on larger ones like <code class="language-plaintext highlighter-rouge">twitter.json</code>, it can amount to as much as 4% of the overall runtime:</p>

<p><img src="/assets/articles/json-4/strnew-flamegraph.png" alt="" /></p>

<p>The cost of allocating the String object is close to invisible compared to the copy.</p>

<p>So at that point, you are probably wondering why not simply directly use the Ruby String as our buffer.
We would let Ruby manage the memory right from the start, save the copy, and for micro-benchmarks, we’d probably
fit inside an embedded String (more on that later). We also wouldn’t have to be extra careful to free our internal buffer
in case an exception is raised, so it would eliminate many potential sources of memory leaks.</p>

<p>That’s not exactly a novel idea, there are a bunch of methods inside Ruby itself that do that exact thing, like <code class="language-plaintext highlighter-rouge">Time#strftime</code>,
and <a href="https://github.com/ruby/json/compare/master...etiennebarrie:json:use-ruby-strings">I had prototyped it a couple of month prior during a pairing session</a>
with <a href="https://github.com/etiennebarrie">Étienne Barrié</a>.</p>

<p>So I went on <a href="https://github.com/byroot/json/commit/8e61886e009f4df1e447f1808293f8e62a09c90a">to reimplement that again</a>, given so much had
changed since then that rebasing would have been harder.</p>

<p>Unfortunately, it wasn’t the win you could expect, quite the opposite:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   208.242k i/100ms
Calculating -------------------------------------
               after      2.201M (± 1.0%) i/s  (454.41 ns/i) -     11.037M in   5.015727s

Comparison:
              before:  2648506.5 i/s
               after:  2200665.8 i/s - 1.20x  slower


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   205.000 i/100ms
Calculating -------------------------------------
               after      2.065k (± 1.5%) i/s  (484.37 μs/i) -     10.455k in   5.065262s

Comparison:
              before:     2099.6 i/s
               after:     2064.5 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>It didn’t move the needle on real-world benchmarks, and noticeably degraded performance on micro-benchmarks.</p>

<p><img src="/assets/articles/json-4/rstring-buffer-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/40dqHXk">Full profile</a>.</p>

<p>Why did it end up slower? The answer is it depends. When resizing a Ruby String, Ruby doesn’t simply call <code class="language-plaintext highlighter-rouge">realloc</code> like <code class="language-plaintext highlighter-rouge">ruby/json</code>
does for its raw buffer, it also calls <a href="https://man7.org/linux/man-pages/man3/malloc_usable_size.3.html"><code class="language-plaintext highlighter-rouge">malloc_usable_size</code></a>,
or the platform equivalent, <a href="https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/malloc_size.3.html"><code class="language-plaintext highlighter-rouge">malloc_size</code> on <code class="language-plaintext highlighter-rouge">macOS</code></a>
or <a href="https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/msize?view=msvc-170"><code class="language-plaintext highlighter-rouge">_msize</code> on Windows</a>.</p>

<p><img src="/assets/articles/json-4/str-resize-flamegraph.png" alt="" /></p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="o">*</span>
<span class="nf">rb_gc_impl_realloc</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">objspace_ptr</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">new_size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">old_size</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snip...</span>

    <span class="n">old_size</span> <span class="o">=</span> <span class="n">objspace_malloc_size</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">old_size</span><span class="p">);</span>
    <span class="n">TRY_WITH_GC</span><span class="p">(</span><span class="n">new_size</span><span class="p">,</span> <span class="n">mem</span> <span class="o">=</span> <span class="n">RB_GNUC_EXTENSION_BLOCK</span><span class="p">(</span><span class="n">realloc</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">new_size</span><span class="p">)));</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mem</span><span class="p">)</span> <span class="k">return</span> <span class="n">mem</span><span class="p">;</span>
    <span class="n">new_size</span> <span class="o">=</span> <span class="n">objspace_malloc_size</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">new_size</span><span class="p">);</span>

    <span class="c1">// snip...</span>

    <span class="n">objspace_malloc_increase</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">new_size</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">MEMOP_TYPE_REALLOC</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">mem</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>This again is to keep the GC statistics up to date and give the opportunity to the GC to trigger if some threshold is hit.</p>

<p>Something I wonder though, and that I ought to investigate, is that <code class="language-plaintext highlighter-rouge">rb_gc_impl_realloc</code> is provided with the known <code class="language-plaintext highlighter-rouge">old_size</code>
and <code class="language-plaintext highlighter-rouge">new_size</code>. Sometimes it’s <code class="language-plaintext highlighter-rouge">0</code> when the called doesn’t know what the size was, but for strings, I believe it does, and yet
data information is simply ignored unless no <code class="language-plaintext highlighter-rouge">malloc_usable_size</code> is available:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">size_t</span>
<span class="nf">objspace_malloc_size</span><span class="p">(</span><span class="n">rb_objspace_t</span> <span class="o">*</span><span class="n">objspace</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">hint</span><span class="p">)</span>
<span class="p">{</span>
<span class="cp">#ifdef HAVE_MALLOC_USABLE_SIZE
</span>    <span class="k">return</span> <span class="n">malloc_usable_size</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
<span class="cp">#else
</span>    <span class="k">return</span> <span class="n">hint</span><span class="p">;</span>
<span class="cp">#endif
</span><span class="p">}</span></code></pre></figure>

<p>Just like <code class="language-plaintext highlighter-rouge">malloc / free</code> etc, the performance of <code class="language-plaintext highlighter-rouge">malloc_usable_size</code> varies a lot depending on the allocator, I haven’t benchmarked
on Linux, nor with <code class="language-plaintext highlighter-rouge">jemalloc</code>, so it’s possible that this overhead would have been negligible there, and that may be why Ruby doesn’t try to skip
that call when possible?</p>

<p>But as mentioned at the end of the last post, we’re here to change perception, so we have to be faster on the machines users are more likely to use
for benchmarking, and that includes <code class="language-plaintext highlighter-rouge">macOS</code> with the default allocator.</p>

<p>In hindsight, there’s something else I could have done to make using a Ruby string as a buffer faster:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gh">diff --git a/ext/json/ext/generator/generator.c b/ext/json/ext/generator/generator.c
index da78fe1..effc8cc 100644
</span><span class="gd">--- a/ext/json/ext/generator/generator.c
</span><span class="gi">+++ b/ext/json/ext/generator/generator.c
</span><span class="p">@@ -1024,8 +1024,8 @@</span> static VALUE cState_partial_generate(VALUE self, VALUE obj)
 {
     GET_STATE(self);
 
<span class="gd">-    VALUE string = rb_utf8_str_new(NULL, 0);
-    rb_str_resize(string, state-&gt;buffer_initial_length - 1);
</span><span class="gi">+    VALUE string = rb_str_buf_new(state-&gt;buffer_initial_length - 1);
+    rb_enc_associate_index(string, utf8_encindex);
</span>     SBuffer buffer = {
         .capa = state-&gt;buffer_initial_length - 1,
         .str = string,</code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   290.040k i/100ms
Calculating -------------------------------------
               after      3.127M (± 0.3%) i/s  (319.84 ns/i) -     15.662M in   5.009436s

Comparison:
              before:  2616126.5 i/s
               after:  3126563.7 i/s - 1.20x  faster


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   202.000 i/100ms
Calculating -------------------------------------
               after      2.049k (± 2.9%) i/s  (488.12 μs/i) -     10.302k in   5.032888s

Comparison:
              before:     2114.5 i/s
               after:     2048.7 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>Quite a nice gain for such a small change, and you may wonder what’s so different about these two lines of code.</p>

<h2 id="variable-width-allocation-and-embeded-objects">Variable Width Allocation and Embeded Objects</h2>

<p>When Ruby allocates an object, it doesn’t call <code class="language-plaintext highlighter-rouge">malloc</code> like a C program would.
Instead, it asks the GC for what’s called a “slot”, which means a fixed-size memory region inside a memory page
managed by the GC.</p>

<p>Up until the introduction of <a href="https://bugs.ruby-lang.org/issues/18045">Variable Width Allocation</a> by <a href="https://peterzhu.ca/">Peter Zhu</a> and
<a href="https://www.eightbitraptor.com/">Matt Valentine-House</a> in Ruby 3.2, all Ruby slots were of the same size: <code class="language-plaintext highlighter-rouge">40B</code>.</p>

<p>You might wonder, how can all objects be of the same size if you are able to create strings or arrays of arbitrary size?
That’s because many of the Ruby core types, like <code class="language-plaintext highlighter-rouge">String</code>, <code class="language-plaintext highlighter-rouge">Array</code> etc, have multiple internal representations.</p>

<p>To stick with the <code class="language-plaintext highlighter-rouge">String</code> example, here is a simplified version of what its layout looks like in <code class="language-plaintext highlighter-rouge">rstring.h</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">RString</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">RBasic</span> <span class="p">{</span>
      <span class="n">VALUE</span> <span class="n">flags</span><span class="p">;</span>
      <span class="n">VALUE</span> <span class="n">klass</span><span class="p">;</span>
    <span class="p">}</span> <span class="n">basic</span><span class="p">;</span>

    <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
    <span class="k">union</span> <span class="p">{</span>
        <span class="k">struct</span> <span class="p">{</span>
            <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>
            <span class="kt">long</span> <span class="n">capa</span><span class="p">;</span>
        <span class="p">}</span> <span class="n">heap</span><span class="p">;</span>

        <span class="k">struct</span> <span class="p">{</span>
            <span class="kt">char</span> <span class="n">ary</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
        <span class="p">}</span> <span class="n">embed</span><span class="p">;</span>
    <span class="p">}</span> <span class="n">as</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<p>If you are unfamiliar with C’s <code class="language-plaintext highlighter-rouge">union</code>, it means that the struct can contain either of its sub structs.</p>

<p>To better visualize, here’s how Ruby stores the <code class="language-plaintext highlighter-rouge">"Hello World"</code> string:</p>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>length</th>
      <th>*ptr</th>
      <th>capa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x000234</td>
      <td>0xffeff</td>
      <td>11</td>
      <td>Hello Wo</td>
      <td>rld\0</td>
    </tr>
  </tbody>
</table>

<p>Each column is 8 bytes wide, or 64 bits, the first 8 bytes are used to store the object flags, we touched on those before,
the following 8 bytes are used to store a pointer to the object class, and then the last 24 bytes are used to store the string content inside
the object slot.</p>

<p>So you can deduce that strings can be as long as 16 ASCII characters, or rather 15 because you need one byte to store the terminating <code class="language-plaintext highlighter-rouge">NULL</code> byte.
Perhaps you’ve read in the past about this limit, and remember that it was 23 characters. That was true but <a href="https://github.com/ruby/ruby/pull/7908">was recently changed by Peter</a>
because it required packing the embedded length inside the <code class="language-plaintext highlighter-rouge">flags</code> bitmap instead, which made things slower. That’s your classic memory usage vs execution speed tradeoff.</p>

<p>Now if we try to append content to that string, and go past the embedded capacity, say, 200 characters long, it will call <code class="language-plaintext highlighter-rouge">malloc(201)</code>, store the string content inside
that malloced region and the object slot will look like this instead:</p>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>length</th>
      <th>*ptr</th>
      <th>capa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x000234</td>
      <td>0xffeff</td>
      <td>200</td>
      <td>0xbbbef</td>
      <td>200</td>
    </tr>
  </tbody>
</table>

<p>But with the introduction of Variable Width Allocation, slots are still fixed-sized in a way, but there are now multiple sizes: <code class="language-plaintext highlighter-rouge">40</code>, <code class="language-plaintext highlighter-rouge">80</code>, <code class="language-plaintext highlighter-rouge">160</code>,
<code class="language-plaintext highlighter-rouge">320</code> and <code class="language-plaintext highlighter-rouge">640</code>. A slot can’t grow in size, so in the above scenario where we appended to a string, nothing changes, Ruby will still have to “spill”
the content on the string on the heap by calling <code class="language-plaintext highlighter-rouge">malloc</code>.</p>

<p>However, if we ask Ruby upfront for a larger string, it will make sure to allocate a larger slot for it if that allows it to be embedded.</p>

<p>In the diff above I call <code class="language-plaintext highlighter-rouge">rb_str_buf_new(state-&gt;buffer_initial_length - 1)</code> or <code class="language-plaintext highlighter-rouge">rb_str_buf_new(511)</code>, so on Ruby 3.2+, Ruby will allocate a <code class="language-plaintext highlighter-rouge">640B</code>
wide slot for us, allowing us to store up to <code class="language-plaintext highlighter-rouge">640 - 24 - 1 = 615</code> bytes before having to spill on the heap, and given our micro-benchmark only needs <code class="language-plaintext highlighter-rouge">34B</code>
it means no <code class="language-plaintext highlighter-rouge">malloc</code> nor <code class="language-plaintext highlighter-rouge">free</code> call for the buffer, only a Ruby object slot allocation, which is way cheaper in most cases.</p>

<p>Since we’ll need to ask Ruby to allocate us an object slot so we can return a String object, we might as well ask for a larger one in case we can 
fit in it. If the cost for a <code class="language-plaintext highlighter-rouge">40B</code> or <code class="language-plaintext highlighter-rouge">640B</code> slot is the same, might as well get the bigger one.</p>

<p>In addition to saving on the <code class="language-plaintext highlighter-rouge">malloc</code> call, we also save on the <code class="language-plaintext highlighter-rouge">free</code> call. When GC triggers and there’s no longer any reference to that slot, Ruby
will just mark the slot as available.</p>

<p>But I didn’t think of this at that time, so maybe that’s something I’ll need to revisit in the future.</p>

<h2 id="be-nice-to--your-mother">Be Nice To  Your Mother</h2>

<p>Instead <a href="https://github.com/ruby/json/commit/fe607f4806ac1d448c1ea5ae7324fdbab183d2ca">I resigned myself to using a stack allocation for the buffer content too</a>.
But I went with a much more conservative size than <code class="language-plaintext highlighter-rouge">Oj</code>, a mere <code class="language-plaintext highlighter-rouge">512B</code>.</p>

<p>The implementation is rather simple, I simply had to add one extra <code class="language-plaintext highlighter-rouge">type</code> field inside the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct
to keep track of the buffer provenance, so that we behave a bit differently inside <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> if the buffer is on the stack.
Here’s the implementation with some extra comments:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">fbuffer_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">requested</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">required</span><span class="p">;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">);</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">required</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">;</span> <span class="n">requested</span> <span class="o">&gt;</span> <span class="n">required</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">;</span> <span class="n">required</span> <span class="o">&lt;&lt;=</span> <span class="mi">1</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">required</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">type</span> <span class="o">==</span> <span class="n">STACK</span><span class="p">)</span> <span class="p">{</span>
                <span class="c1">// If the buffer is on the stack</span>
                <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">old_buffer</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">;</span>
                <span class="c1">// We allocate a larger buffer on the heap</span>
                <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">required</span><span class="p">);</span>
                <span class="c1">// Mark it as now being on the heap</span>
                <span class="n">fb</span><span class="o">-&gt;</span><span class="n">type</span> <span class="o">=</span> <span class="n">HEAP</span><span class="p">;</span>
                <span class="c1">// Copy the old content over</span>
                <span class="n">MEMCPY</span><span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">,</span> <span class="n">old_buffer</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">REALLOC_N</span><span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">required</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">required</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>This had the expected effect on micro-benchmarks, a nice 7% improvement:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   286.112k i/100ms
Calculating -------------------------------------
               after      3.024M (± 0.7%) i/s  (330.67 ns/i) -     15.164M in   5.014435s

Comparison:
              before:  2836034.1 i/s
               after:  3024200.8 i/s - 1.07x  faster
</code></pre></div></div>

<p>However, I quickly noticed that it also became way slower on real-world benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   156.000 i/100ms
Calculating -------------------------------------
               after      1.572k (± 1.7%) i/s  (636.13 μs/i) -      7.956k in   5.062686s

Comparison:
              before:     2134.0 i/s
               after:     1572.0 i/s - 1.36x  slower
</code></pre></div></div>

<p>While I was determined to spend a lot of effort in improving <code class="language-plaintext highlighter-rouge">ruby/json</code> performance on micro-benchmarks, degrading its performance
on real-world benchmarks was a huge red line for me, so I had to figure out what happened.</p>

<p>So I went back to my profiler, and started playing “Spot the seven differences” again:</p>

<p>Before:</p>

<p><img src="/assets/articles/json-4/before.png" alt="" /></p>

<p>After:</p>

<p><img src="/assets/articles/json-4/after.png" alt="" /></p>

<p>It’s far from obvious if you don’t know what to look for, but you can see that before we were spending <code class="language-plaintext highlighter-rouge">50%</code> of the runtime in <code class="language-plaintext highlighter-rouge">generate_json_string</code>, and afterward, only <code class="language-plaintext highlighter-rouge">3.1%</code>
and instead, the top was trusted by a bunch of smaller functions called by <code class="language-plaintext highlighter-rouge">generate_json_string</code>.</p>

<p>These are the signs of what is sometimes referred to as “the mother of all optimizations”: inlining.</p>

<p>Even in C, calling a function isn’t that cheap. It’s cheap enough that you generally don’t think about it but costly enough that you try to minimize
function calls in hotspots.</p>

<p>You can do that by refactoring your code to use bigger functions, or even copying code around using macros, but that gets old quickly.
Instead, the compiler does that for us, it identifies the small leaf functions that aren’t worth calling and instead copies its content inside the parent,
even if it means copy-pasting it dozens and dozens of times. In addition to saving on the overhead of a function call, it also allows to optimize the caller
and callee together, sometimes allowing to eliminate redundant computations or simply dead code.</p>

<p>That’s what the <code class="language-plaintext highlighter-rouge">inline</code> keyword is for in the <code class="language-plaintext highlighter-rouge">static inline void fbuffer_inc_capa...</code> declaration, it’s a way to tell the compiler that it would be
a good idea to inline this function. But that’s all it is, just a compiler hint, the compiler can still decide that you are wrong and that it knows better.</p>

<p>I don’t know the intricacies of <code class="language-plaintext highlighter-rouge">LLVM/clang</code> enough to know for certain why it decided to no longer inline all these functions, but I guessed that it
was because I made <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> much larger.</p>

<p>The reason it’s important <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> is inlined, is because 99%+ of the time, we return from it after just a very simple comparison:
<code class="language-plaintext highlighter-rouge">RB_UNLIKELY(requested &gt; fb-&gt;capa - fb-&gt;len)</code>. That’s the part we want inlined, so we don’t pay for a function call just for that check.
The rest of the function we don’t care so much, we rarely ever go into it.</p>

<p>So to appease the compiler, and make that conditional appealing to inline again, <a href="https://github.com/ruby/json/commit/41c021580e48754aa4bfc71c8363b1fb233ed8c8">the solution would be to extract the large amount of code that is
rarely executed in another function that isn’t marked as <code class="language-plaintext highlighter-rouge">inline</code></a>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_do_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snip...</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">fbuffer_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">requested</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">fbuffer_do_inc_capa</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">requested</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>Running the benchmarks again with both changes, we finally had what we expected:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   290.616k i/100ms
Calculating -------------------------------------
               after      3.093M (± 0.3%) i/s  (323.30 ns/i) -     15.693M in   5.073761s

Comparison:
              before:  2829771.3 i/s
               after:  3093060.4 i/s - 1.09x  faster


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   208.000 i/100ms
Calculating -------------------------------------
               after      2.088k (± 0.5%) i/s  (479.01 μs/i) -     10.608k in   5.081469s

Comparison:
              before:     2108.3 i/s
               after:     2087.6 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>We squeezed a tiny bit more performance on the micro-benchmark, and the real work benchmark wasn’t noticeably impacted.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>At that point, with all the above optimizations, we were now faster than <code class="language-plaintext highlighter-rouge">Oj</code> when reusing the <code class="language-plaintext highlighter-rouge">JSON::State</code> object,
but still quite a bit slower when allocating it on every call:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
        json (reuse)   619.700k i/100ms
                json   291.441k i/100ms
                  oj   532.966k i/100ms
Calculating -------------------------------------
        json (reuse)      6.628M (± 4.9%) i/s  (150.88 ns/i) -     33.464M in   5.064856s
                json      3.191M (± 0.5%) i/s  (313.35 ns/i) -     16.029M in   5.022818s
                  oj      5.873M (± 0.9%) i/s  (170.26 ns/i) -     29.846M in   5.082087s

Comparison:
        json (reuse):  6627811.3 i/s
                  oj:  5873337.3 i/s - 1.13x  slower
                json:  3191361.6 i/s - 2.08x  slower
</code></pre></div></div>

<p>So there was no way around it, I had to find how to automatically re-use that <code class="language-plaintext highlighter-rouge">JSON::State</code> object. Or how to not allocate it at all?</p>

<p>But that’s a story for <a href="/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html">the next part</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>In the initial version of this post I wrongly assumed the <code class="language-plaintext highlighter-rouge">a</code> suffix was referring to “arrays of bytes”. Thanks to f33d5173 and ciupicri for lettingme know the real meaning on HN. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, we established that as long as ruby/json wasn’t competitive on micro-benchmarks, public perception wouldn’t change. Since what made ruby/json appear so bad on micro-benchmarks was its setup cost, we had to find ways to reduce it further.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 3</title><link href="https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 3" /><published>2024-12-27T09:05:51+00:00</published><updated>2024-12-27T09:05:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html"><![CDATA[<p><a href="/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html">In the previous post</a>, I covered how I reimplemented <code class="language-plaintext highlighter-rouge">JSON::Generator::State#configure</code>
in Ruby and some other changes. Unfortunately, it didn’t go as well as I initially thought.</p>

<h2 id="mistakes-were-made">Mistakes Were Made</h2>

<p>The default gems that ship with Ruby are automatically copied inside <code class="language-plaintext highlighter-rouge">ruby/ruby</code>’s repo.
In short, there’s a bot aptly named <a href="https://github.com/matzbot">matzbot</a>, that replicates all the commits from the various <code class="language-plaintext highlighter-rouge">ruby/*</code> gems,
inside <code class="language-plaintext highlighter-rouge">ruby/ruby</code>, and <a href="https://github.com/ruby/ruby/commit/0e2ac4658430ae5c8beba36e0b608902b3404879">that’s what it did with my <code class="language-plaintext highlighter-rouge">State#configure</code> patch</a>.</p>

<p>The reason is that Ruby runs on many different platforms and its CI tests many different compilers, in different versions, and also test builds
with various compilation flags enabled to hopefully catch some subtle bugs, these gems will ultimately ship as part of Ruby, so they might as
well, be tested together.</p>

<p>Depending on which files the commit touches, it can trigger up to 150 CI tasks just on GitHub:</p>

<p><img src="/assets/articles/json-3/gha.png" alt="" /></p>

<p>And that’s only the beginning, after such a commit is merged, there are other secondary CIs maintained by core contributors which will
test Ruby on various OS and platforms that are hard to integrate into GitHub actions, such as Solaris and some CPU architectures
I barely know the existence of.</p>

<p>This is centralized in a channel inside Ruby committers’ Slack: <code class="language-plaintext highlighter-rouge">#alert-emoji</code>.</p>

<p>On October 17th, Mame pinged me because that <code class="language-plaintext highlighter-rouge">State#configure</code> commit <a href="https://github.com/ruby/ruby/actions/runs/11384118908">started making builds fail</a>,
with this crash report:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Assertion Failed: ../src/vm_core.h:1394:VM_ENV_FLAGS:FIXNUM_P(flags)
ruby 3.4.0dev (2024-10-17T11:35:33Z master 0e2ac46584) +PRISM [i686-linux-gnu]

-- Control frame information -----------------------------------------------
Assertion Failed: ../src/vm_core.h:1394:VM_ENV_FLAGS:FIXNUM_P(flags)
ruby 3.4.0dev (2024-10-17T11:35:33Z master 0e2ac46584) +PRISM [i686-linux-gnu]

Crashed while printing bug report
running file: /home/runner/work/ruby/ruby/src/test/json/json_common_interface_test.rb

A test worker crashed. It might be an interpreter bug or
a bug in test/unit/parallel.rb. Try again without the -j
option.
</code></pre></div></div>

<p>This is the worst for me. Normally when Ruby runs into a SEGV or some other bug, before it exits, it collects lots of debug information
including the native C stacktrace, and print a useful report that helps a lot in the debugging process.</p>

<p>But sometimes, the process is corrupted enough, that the crash reporter itself crashes while trying to collect that data, and that’s what happened here.</p>

<p>Yet, we still have a few information. Since we failed an assertion, we do know which condition was wrong:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">unsigned</span> <span class="kt">long</span>
<span class="nf">VM_ENV_FLAGS</span><span class="p">(</span><span class="k">const</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">ep</span><span class="p">,</span> <span class="kt">long</span> <span class="n">flag</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">ep</span><span class="p">[</span><span class="n">VM_ENV_DATA_INDEX_FLAGS</span><span class="p">];</span>
    <span class="n">VM_ASSERT</span><span class="p">(</span><span class="n">FIXNUM_P</span><span class="p">(</span><span class="n">flags</span><span class="p">));</span> <span class="c1">// CRASHED HERE.</span>
    <span class="k">return</span> <span class="n">flags</span> <span class="o">&amp;</span> <span class="n">flag</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>And we also do know that the crash was triggered by a test inside <code class="language-plaintext highlighter-rouge">test/json/json_common_interface_test.rb</code>, but not which one exactly.</p>

<p>Unfortunately, for some reason, I’m still not quite clear on why the crash would only happen on <code class="language-plaintext highlighter-rouge">i686</code>, aka 32-bit Intel, and all I have is an arm64 machine (I really should do something about that).
In some cases, you can use emulation layers, but it’s terribly slow, so I was looking at hours of compilation, and generally when emulating another
architecture you can’t use debuggers like <code class="language-plaintext highlighter-rouge">gdb</code> or <code class="language-plaintext highlighter-rouge">lldb</code> so it’s not that helpful.</p>

<p>So that’s where I called a favor from my colleague <a href="https://peterzhu.ca/">Peter Zhu</a>, who owns an x86_64 machine, to ask him if he could get me a proper
backtrace or something, and generally give me some more information about what was going on.</p>

<p>But Peter being Peter, <a href="https://github.com/ruby/json/pull/621">he directly opened a pull request on <code class="language-plaintext highlighter-rouge">ruby/json</code> with the fix</a>.</p>

<p>Turns out, I didn’t introduce the bug, it had been present in the <code class="language-plaintext highlighter-rouge">State#max_nesting=</code> since October 2009, 15 years!
My change caused it to be covered by tests, while before it wasn’t.</p>

<p>But you might wonder what the bug is exactly, so let me explain.</p>

<h3 id="boxing-day">Boxing Day</h3>

<p>In the Ruby VM, object references are held in the <code class="language-plaintext highlighter-rouge">VALUE</code> type, which in short is a pointer type. Meaning on 64-bit hardware it’s a 64-bit integer,
and on 32-bit hardware, it’s a 32-bit integer.</p>

<p>This is so that for objects that are allocated on the heap, their reference is simply a pointer to their location, and there’s no lookup or
transformation needed to access that reference, you simply use it like a normal C pointer. This might seem obvious, but some other VMs don’t do it this way, it’s a tradeoff.</p>

<p>But not all <code class="language-plaintext highlighter-rouge">VALUE</code> references are an actual pointer to an active memory region on the heap, some of them are what is called “immediates”.</p>

<p>This is a technique often referred to as “pointer tagging”, that exploits the fact that pointers are guaranteed to be aligned on 8 bytes, in other words all the pointers you’ll
get from malloc and such will always be divisible by 8, so that <code class="language-plaintext highlighter-rouge">(pointer % 8) == 0</code>, always.</p>

<p>In binary form, that means the last 3 bits of a pointer are always <code class="language-plaintext highlighter-rouge">0</code>, and Ruby would never leave 3 good bits to go to waste.
For objects that are fully immutable, like <code class="language-plaintext highlighter-rouge">Integer</code>, you don’t need them to be stored in allocated memory, you can simply pack them in
the pointer instead, and use these 3 bits as “tag”, to inform Ruby that it’s not a real memory pointer, but an immediate value that needs to be
massaged first to be used.</p>

<p>The way these are used is defined in <a href="https://github.com/ruby/ruby/blob/335bba0fde0c0407377b6e10050ab6c2ad0d3270/include/ruby/internal/special_consts.h#L86-L120">the <code class="language-plaintext highlighter-rouge">ruby_special_consts</code> enum in <code class="language-plaintext highlighter-rouge">special_const.h</code></a>
and can vary based on which architecture Ruby is compiled for, typically 32-bit and 64-bit Rubies are quite different.</p>

<p>Here I’ll just focus on how <code class="language-plaintext highlighter-rouge">Integer</code> is tagged. On both 32 and 64 bits, if the least significant bit is set, then we’re dealing with an immediate integer.</p>

<p>So to know if a reference is an immediate integer, you just have to check that bit:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">RUBY_FIXNUM_FLAG</span> <span class="o">=</span> <span class="mh">0x01</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span>
<span class="nf">RB_FIXNUM_P</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">obj</span> <span class="o">&amp;</span> <span class="n">RUBY_FIXNUM_FLAG</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">_P</code> prefix is the convention used by Ruby to encode question mark <code class="language-plaintext highlighter-rouge">?</code> into valid C function names, as for <code class="language-plaintext highlighter-rouge">fixnum</code>, that’s how integers small
enough to be immediates were called in the past. Before Ruby 2.4, you had two Integer classes, <code class="language-plaintext highlighter-rouge">Fixnum</code> and <code class="language-plaintext highlighter-rouge">Bignum</code>. The two were merged and now as a Ruby user you can only
observe a single <code class="language-plaintext highlighter-rouge">Integer</code> class, but internally in the virtual machine, they’re still very much distinct.</p>

<p>Based on this to convert a C integer into a Ruby fixnum you use some simple bitwise transformations:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">int_to_fixnum</span><span class="p">(</span><span class="n">int</span><span class="p">)</span>
  <span class="p">(</span><span class="n">int</span> <span class="o">&lt;&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="k">end</span>

<span class="k">def</span> <span class="nf">fixnum_to_int</span><span class="p">(</span><span class="n">fixnum</span><span class="p">)</span>
  <span class="n">fixnum</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span>
<span class="k">end</span>

<span class="nb">p</span><span class="p">(</span><span class="mi">5</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="n">int_to_fixnum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="p">})</span> <span class="c1"># =&gt; [1, 3, 5, 7, 9]</span></code></pre></figure>

<p>This sort of conversion is often referred to as “boxing” and “unboxing”, the idea being to take a native integer type, and put it in a “box” so that
it fits the same generic pattern than all other object references. And then when you need to use it you have to “unbox” it back to the native type.</p>

<p>In the Ruby C API, these types of functions are provided as <code class="language-plaintext highlighter-rouge">NUM2&lt;ctype&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;ctype&gt;2NUM</code> or <code class="language-plaintext highlighter-rouge">FIX2&lt;ctype&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;ctype&gt;2FIX</code>, for instance,
to convert a <code class="language-plaintext highlighter-rouge">FIXNUM</code> into a native C <code class="language-plaintext highlighter-rouge">long</code>, you use <code class="language-plaintext highlighter-rouge">FIX2LONG</code>.</p>

<p>Going back to our crash, what Ruby was complaining about, is that it was expecting to read a <code class="language-plaintext highlighter-rouge">FIXNUM</code> on the stack,
but somehow, the <code class="language-plaintext highlighter-rouge">VALUE</code> it read wasn’t a <code class="language-plaintext highlighter-rouge">FIXNUM</code>, as its least significant bit wasn’t set.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_max_nesting_set</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">self</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">depth</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">Check_Type</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">T_FIXNUM</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="n">NUM2LONG</span><span class="p">(</span><span class="n">depth</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>With what I explained above, you might be able to spot that <code class="language-plaintext highlighter-rouge">State#max_nesting=</code> is supposed to return a Fixnum, but actually returns the native C <code class="language-plaintext highlighter-rouge">long</code> integer,
and thanks to C’s weak typing, none of the many compilers Ruby is tested against ever complained about it.</p>

<p>You might also have deduced that this crash would only happen if <code class="language-plaintext highlighter-rouge">depth</code> happens to be an even number.</p>

<p>But also the crash was only happening on debug builds of Ruby, because that function is a setter, so unless you do something weird, the return value
is just dropped on the floor.</p>

<p>But you can easily reproduce it on older versions of the JSON gem:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">VERSION</span>
<span class="o">=&gt;</span> <span class="s2">"2.5.1"</span>
<span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="o">=</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">=&gt;</span> <span class="mi">2</span>
<span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="o">=</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="sr">/opt/</span><span class="n">rubies</span><span class="o">/</span><span class="mf">3.0</span><span class="o">.</span><span class="mi">7</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">ruby</span><span class="o">/</span><span class="mf">3.0</span><span class="o">.</span><span class="mi">0</span><span class="o">/</span><span class="n">pp</span><span class="p">.</span><span class="nf">rb</span><span class="p">:</span><span class="mi">582</span><span class="p">:</span> <span class="p">[</span><span class="no">BUG</span><span class="p">]</span> <span class="no">Segmentation</span> <span class="n">fault</span> <span class="n">at</span> <span class="mh">0x0000000000000014</span>
<span class="n">ruby</span> <span class="mf">3.0</span><span class="o">.</span><span class="mi">7</span><span class="n">p220</span> <span class="p">(</span><span class="mi">2024</span><span class="o">-</span><span class="mo">04</span><span class="o">-</span><span class="mi">23</span> <span class="n">revision</span> <span class="mi">724</span><span class="n">a071175</span><span class="p">)</span> <span class="p">[</span><span class="n">arm64</span><span class="o">-</span><span class="n">darwin23</span><span class="p">]</span>
<span class="o">....</span></code></pre></figure>

<p>But this post is named “Optimizing Ruby’s JSON”, we’re not here to talk about bugs, so let’s move on.</p>

<h2 id="path-splitting">Path Splitting</h2>

<p>After the previous optimizations I mentioned in parts 1 and 2, I still wasn’t satisfied with the <code class="language-plaintext highlighter-rouge">JSON.dump</code> performance.
So I went back to profile the <code class="language-plaintext highlighter-rouge">twitter.json</code> macro benchmark:</p>

<p><img src="/assets/articles/json-3/generate-json-string-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/3P3BTzr">Full Profile</a></p>

<p>As you can see, we’re spending 55% (13% + 28% + 14%) of our time in <code class="language-plaintext highlighter-rouge">generate_json_string</code>, and most of that is spent in <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
which is essentially our <code class="language-plaintext highlighter-rouge">escape</code> function.</p>

<p>This makes sense, of all the JSON types, it’s one of the most common and requires some costly scanning and escaping.</p>

<p>Having such an obvious hotspot is pleasant in a way, as it gives you a very specific area to focus on.</p>

<p>Looking more specifically at the heatmap of <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>, we can see that Mame’s precondition check
helps, but we’re still spending quite a lot of time in the slow path, decoding UTF-8.</p>

<p><img src="/assets/articles/json-3/generate-json-string-heatmap.png" alt="" /></p>

<p>That’s because the <code class="language-plaintext highlighter-rouge">twitter.json</code> payload happens to contain mostly Japanese tweets, hence it’s quite UTF-8
heavy, but that’s good, it means it’s not only benchmarking the happy path.</p>

<p>That said, even in this case, actual UTF-8 strings are the minority in the document, most of them are pure ASCII,
as such it would be interesting not to bother decoding UTF-8 at all when we know the string is plain ASCII.</p>

<p>As mentioned in part 1, we already know if the string is pure ASCII upfront, because we asked Ruby to compute the string coderange.</p>

<p>But you may also wonder, why we even bother decoding UTF-8, after all, UTF-8 is a superset of ASCII, and all we care about are <code class="language-plaintext highlighter-rouge">\</code> and <code class="language-plaintext highlighter-rouge">"</code> characters
as well as characters that are <code class="language-plaintext highlighter-rouge">&lt; 0x20</code>. That’s the nice thing with UTF-8, any code that only knows about ASCII will be compatible with UTF-8 as long
as it ignores characters outside the ASCII range.</p>

<p>But the reason we need to care about UTF-8 is the <code class="language-plaintext highlighter-rouge">script_safe: true</code> option. On paper, JSON is an extremely simple spec, but it also somewhat claims
to be a subset of JavaScript, hence you may want to interpolate some JSON inside JavaScript as a way to pass data from Ruby to JS. e.g.</p>

<figure class="highlight"><pre><code class="language-erb" data-lang="erb"><span class="nt">&lt;script&gt;</span>
  <span class="nx">MyLibrary</span><span class="p">.</span><span class="nx">configure</span><span class="p">(</span><span class="cp">&lt;%=</span> <span class="no">MyLib</span><span class="o">::</span><span class="no">CONFIG</span><span class="p">.</span><span class="nf">to_json</span> <span class="cp">%&gt;</span><span class="p">);</span>
<span class="nt">&lt;/script&gt;</span></code></pre></figure>

<p>And this works well except that you need to escape more characters. First forward slashes (<code class="language-plaintext highlighter-rouge">/</code>) to prevent XSS, we touched on that in part 1, but
also two weird characters, the infamous <code class="language-plaintext highlighter-rouge">U+2028</code> and <code class="language-plaintext highlighter-rouge">U+2029</code> characters aka Line Separator and Paragraph Separator.</p>

<p><a href="https://stackoverflow.com/a/9168133">The ECMAScript standard specifies that these two characters are treated as new lines</a>,
and you can’t put newlines in a JavaScript string so you end up with some syntax errors.</p>

<p>So if you plan to embed your JSON in JS, you need to care about characters outside the ASCII range, but here again,
this is the exception, not the common case, as such we should be able to implement a fast path that doesn’t care about that.</p>

<p>You can see <a href="https://github.com/ruby/json/pull/620/commits/2aefa41d51efff154f8bbd24ba6cfa35521cea87">the full commit on GitHub</a>,
but the key part can be understood by just looking at <code class="language-plaintext highlighter-rouge">generate_json_string</code>. Now it dispatches to a much simpler <code class="language-plaintext highlighter-rouge">convert_ASCII_to_JSON</code>
when possible.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">generate_json_string</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">Vstate</span><span class="p">,</span> <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">enc_utf8_compatible_p</span><span class="p">(</span><span class="n">RB_ENCODING_GET</span><span class="p">(</span><span class="n">obj</span><span class="p">)))</span> <span class="p">{</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">rb_str_export_to_enc</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">rb_utf8_encoding</span><span class="p">());</span>
    <span class="p">}</span>

    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="sc">'"'</span><span class="p">);</span>

    <span class="k">switch</span><span class="p">(</span><span class="n">rb_enc_str_coderange</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">case</span> <span class="n">ENC_CODERANGE_7BIT</span><span class="p">:</span>
            <span class="n">convert_ASCII_to_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="k">case</span> <span class="n">ENC_CODERANGE_VALID</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">state</span><span class="o">-&gt;</span><span class="n">ascii_only</span><span class="p">))</span> <span class="p">{</span>
                <span class="n">convert_UTF8_to_ASCII_only_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">convert_UTF8_to_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="nl">default:</span>
            <span class="n">rb_raise</span><span class="p">(</span><span class="n">rb_path2class</span><span class="p">(</span><span class="s">"JSON::GeneratorError"</span><span class="p">),</span> <span class="s">"source sequence is illegal/malformed utf-8"</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="sc">'"'</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>And it had a pretty nice impact:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   189.000 i/100ms
Calculating -------------------------------------
               after      1.894k (± 1.2%) i/s  (527.87 μs/i) -      9.639k in   5.088860s

Comparison:
              before:     1489.1 i/s
               after:     1894.4 i/s - 1.27x  faster
</code></pre></div></div>

<p>Note: because Mame’s lookup table patch was almost a year old when I took over the gem, it had to be rebased
and adapted quite a bit, so in reality, Mame’s lookup table patch was applied after this split of <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
<a href="https://github.com/ruby/json/pull/620">as part of a PR that combined both</a>.
If the two commits had been applied in the opposite order I suspect my patch’s impact would have been much smaller, if not null.</p>

<p>The logical followup would have been to also make optimized versions of <code class="language-plaintext highlighter-rouge">convert_</code> methods, that assume <code class="language-plaintext highlighter-rouge">script_safe = false</code>,
allowing to get one more conditional out of the loop. But I didn’t want to have to maintain this many versions of the same subroutine,
as it was already a bit tedious. And anyway, I already had another idea.</p>

<h2 id="dont-ignore-the-not-so-happy-path">Don’t Ignore the “Not So Happy” Path</h2>

<p>While we can expect most JSON strings to be ASCII only, we can also likely assume that even in strings that aren’t pure ASCII,
most of the characters still are in the ASCII range.</p>

<p>The <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark is a total counter-example because all strings in it are either English or Japanese, so either full ASCII
or close to no ASCII at all.
But over a larger corpus, you’d likely see strings that are mostly ASCII, but a few of them might contain an accent or some symbol.
Even English texts will often contain a couple of characters outside the ASCII range, be it some emojis or some word borrowed from
French to look fancy.</p>

<p>A good example of that is the <code class="language-plaintext highlighter-rouge">ctim_catalog.json</code> benchmark, which contains some French language strings:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="err">//</span><span class="w"> </span><span class="err">...</span><span class="w">
    </span><span class="nl">"areaNames"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"205705993"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705994"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705995"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon bergerie cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705996"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon bergerie jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705998"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon bergerie jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705999"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon bergerie cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706000"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706001"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706002"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706003"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706004"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème Balcon central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706005"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706006"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706007"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706008"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706009"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"342752287"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Zone physique secrète"</span><span class="w">
    </span><span class="p">}</span><span class="err">,</span></code></pre></figure>

<p>To make it easier to profile <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> in this particular case, I added another micro-benchmark in the suite:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"mixed utf8"</span><span class="p">,</span> <span class="p">([(</span><span class="s2">"a"</span> <span class="o">*</span> <span class="mi">5000</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"€"</span> <span class="o">+</span> <span class="p">(</span><span class="s2">"a"</span> <span class="o">*</span> <span class="mi">5000</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">500</span><span class="p">)</span></code></pre></figure>

<p>It’s a <code class="language-plaintext highlighter-rouge">10kiB</code> string, with just one character outside the ASCII range, and repeated <code class="language-plaintext highlighter-rouge">500</code> times to reduce
the relative cost of the setup, giving me a profile with 91% of the time spent inside <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
and a pretty clear heatmap:</p>

<p><img src="/assets/articles/json-3/mixed-utf8-heatmap.png" alt="" /></p>

<p>All this code <a href="https://github.com/ruby/json/pull/567">had recently been rewritten pretty much from scratch by Luke Shumaker</a> to resolve some
potential licensing issues with the original code from the early days of the gem.
It’s a fairly clear and straightforward implementation that first decodes UTF-8 bytes into 32-bit codepoints, then checks whether escaping is needed.
If it is, we’d then copy all the scanned bytes into the buffer, followed by the escaped character. Otherwise, the loop would just continue onto the next
codepoint.</p>

<p>While this code is very clean and generic, with a good separation of the multiple levels of abstractions, such as bytes and codepoints,
that would make it very easy to extend the escaping logic,
it isn’t taking advantage of many assumptions <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> could make to take shortcuts.</p>

<p>One of these for instance is that there’s no point validating the UTF-8 encoding because Ruby did it for us and it’s impossible to end up inside
<code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> with invalid UTF-8.</p>

<p>Another is that there are only two multi-byte characters we care about, and both start with the same <code class="language-plaintext highlighter-rouge">0xE2</code> byte, so the decoding into codepoints is a bit superfluous.</p>

<p>So what can we do about it? Well, the same thing we do every day Pinky, eliminate conditionals.</p>

<p>You can see <a href="https://github.com/ruby/json/pull/629">the full pull request</a>, but let me try to explain what it does.</p>

<p>To replace the complex conditional that defines if the character needs to be escaped, we can re-use Mame’s lookup table, but with a twist.
Instead of only storing a boolean, which tells us if the character needs to be escaped or not, we can also pack the character length.</p>

<p>Wikipedia has <a href="https://en.wikipedia.org/wiki/UTF-8#Byte_map">a pretty good table to understand how UTF-8 works</a>:</p>

<p><img src="/assets/articles/json-3/utf8-table.png" alt="" /></p>

<p>If we turn this into a lookup table, with just one pointer offset we can efficiently figure out for each byte
if it needs to be escaped or if we have to deal with a multi-byte character:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="kt">char</span> <span class="n">escape_table</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1">// ASCII Control Characters</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1">// ASCII Characters</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span> <span class="c1">// '"'</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span> <span class="c1">// '\\'</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="c1">// Continuation byte</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1">// First byte of a 2-byte code point</span>
    <span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span>
    <span class="c1">// First byte of a 4-byte code point</span>
    <span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span>
    <span class="c1">//First byte of a 4+byte code point</span>
    <span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">0</code> here means a single-byte character that doesn’t require escaping, and <code class="language-plaintext highlighter-rouge">&gt;= 2</code> means a multi-byte character.
We also have a second version of that table for the <code class="language-plaintext highlighter-rouge">script_safe: true</code> escaping mode, with forward-slash (<code class="language-plaintext highlighter-rouge">/</code>) set to <code class="language-plaintext highlighter-rouge">1</code>,
and <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> takes the table to use as an argument.</p>

<p>In pseudo-Ruby, the function would now look like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">convert_UTF8_to_JSON</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="n">lookup_table</span><span class="p">)</span>
  <span class="n">buffer</span> <span class="o">=</span> <span class="o">+</span><span class="s2">""</span>
  <span class="n">beginning</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">position</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">while</span> <span class="n">position</span> <span class="o">&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">bytesize</span>
    <span class="n">byte</span> <span class="o">=</span> <span class="n">string</span><span class="p">.</span><span class="nf">getbyte</span><span class="p">(</span><span class="n">position</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">escape</span> <span class="o">=</span> <span class="n">lookup_table</span><span class="p">[</span><span class="n">byte</span><span class="p">]</span>
      <span class="k">case</span> <span class="n">escape</span>
      <span class="k">when</span> <span class="mi">1</span>
        <span class="c1"># Copy all the bytes we saw didn't need escaping</span>
        <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">byteslice</span><span class="p">(</span><span class="n">beginning</span><span class="o">..</span><span class="n">position</span><span class="p">)</span>

        <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">escape</span><span class="p">(</span><span class="n">byte</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">beginning</span> <span class="o">=</span> <span class="n">position</span>
      <span class="k">when</span> <span class="mi">3</span>
        <span class="k">if</span> <span class="n">script_safe?</span> <span class="o">&amp;&amp;</span> <span class="n">byte</span> <span class="o">==</span> <span class="mh">0xE2</span> <span class="o">&amp;&amp;</span> <span class="n">string</span><span class="p">.</span><span class="nf">getbyte</span><span class="p">(</span><span class="n">position</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="o">...</span>
          <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">byteslice</span><span class="p">(</span><span class="n">beginning</span><span class="o">..</span><span class="n">position</span><span class="p">)</span>
          <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">escape</span><span class="p">(</span><span class="n">byte</span><span class="p">)</span>
          <span class="n">position</span> <span class="o">+=</span> <span class="mi">3</span>
          <span class="n">beginning</span> <span class="o">=</span> <span class="n">position</span>
        <span class="k">end</span> 
      <span class="k">else</span>
        <span class="n">position</span> <span class="o">+=</span> <span class="n">escape</span>
      <span class="k">end</span>
    <span class="k">else</span>
      <span class="n">position</span> <span class="o">+=</span> <span class="mi">1</span> 
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>Since our assumption is that the overwhelming majority of characters don’t need escaping and are single bytes,
for most iterations, we’re not even going to enter the <code class="language-plaintext highlighter-rouge">if escape</code> condition.</p>

<p>This resulted in the new micro-benchmark being sped up by more than 2x:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding mixed utf8 (5003001 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    37.000 i/100ms
Calculating -------------------------------------
               after    439.128 (± 8.7%) i/s    (2.28 ms/i) -      2.183k in   5.012174s

Comparison:
              before:      194.6 i/s
               after:      439.1 i/s - 2.26x  faster
</code></pre></div></div>

<p>And the function heatmap shows that we’re now down to pretty much just table lookups:</p>

<p><img src="/assets/articles/json-3/mixed-utf8-heatmap-after.png" alt="" /></p>

<p>However, this, unfortunately, didn’t translate in a particularly measurable gain on the macro-benchmarks, even <code class="language-plaintext highlighter-rouge">ctim_catalog.json</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding citm_catalog.json (500298 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   132.000 i/100ms
Calculating -------------------------------------
               after      1.351k (± 0.5%) i/s  (739.92 μs/i) -      6.864k in   5.078953s

Comparison:
              before:     1330.9 i/s
               after:     1351.5 i/s - 1.02x  faster
</code></pre></div></div>

<p>It doesn’t mean it wasn’t worth optimizing, but I misjudged how much time was spent dealing with this sort of mixed strings, and should have
prioritized another hostspot. But I still merged the improvements, because benchmarks are just arbitrary workloads, someone out there might 
significantly benefit from the improvement.</p>

<p>I also realize now that I’m writing this, that I could have used something other than <code class="language-plaintext highlighter-rouge">3</code> in the lookup table for <code class="language-plaintext highlighter-rouge">0xE2</code> so that we don’t
do any extra work for the 15 other bytes that mark the start of a 3-byte wide codepoint we’re not interested in, and also so that only the
script safe version of the escape table would ever enter this branch of the code.</p>

<h2 id="micro-benchmarks-shouldnt-matter-but-clearly-they-do">Micro-Benchmarks Shouldn’t Matter, But Clearly They Do</h2>

<p>At that point, <code class="language-plaintext highlighter-rouge">ruby/json</code> was now on par with alternatives on macro-benchmarks, and I didn’t have any more immediate ideas on how to speed it up
further.</p>

<p>We were still very significantly slower on micro-benchmarks, but micro-benchmarks as explained before were simply dominated by allocations, and because
of the API exposed by <code class="language-plaintext highlighter-rouge">ruby/json</code> we have to allocate one more object than <code class="language-plaintext highlighter-rouge">oj</code>, so it’s just impossible to match its performance there.</p>

<p>But to me, that wasn’t a big deal, because micro-benchmarks are nowhere near indicative of real-world performance. As demonstrated above,
they can be useful to help focus on optimizing a specific part of a larger system, but other than that, they don’t serve any actual purpose.
Unless of course online flamewars on who got the fastest is your purpose.</p>

<p>Additionally, if somehow you needed to generate a lot of small documents, you could use a lower-level API to elide that allocation,
by reusing the <code class="language-plaintext highlighter-rouge">Generator::State</code> object:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">state</span> <span class="o">=</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span><span class="p">)</span>
<span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">ruby_obj</span><span class="p">)</span>
<span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">another_obj</span><span class="p">)</span></code></pre></figure>

<p>Using this API, <code class="language-plaintext highlighter-rouge">ruby/json</code> was very much on par with alternatives:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small nested array (121 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                  oj   223.200k i/100ms
                json   167.997k i/100ms
        json (reuse)   237.781k i/100ms
Calculating -------------------------------------
                  oj      2.295M (± 1.2%) i/s  (435.64 ns/i) -     11.606M in   5.056904s
                json      1.742M (± 0.2%) i/s  (574.13 ns/i) -      8.736M in   5.015536s
        json (reuse)      2.449M (± 0.2%) i/s  (408.28 ns/i) -     12.365M in   5.048249s

Comparison:
                  oj:  2295492.3 i/s
        json (reuse):  2449294.2 i/s - 1.07x  faster
                json:  1741765.4 i/s - 1.32x  slower


== Encoding small hash (65 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                  oj   676.718k i/100ms
                json   269.175k i/100ms
        json (reuse)   500.536k i/100ms
Calculating -------------------------------------
                  oj      7.305M (± 0.3%) i/s  (136.90 ns/i) -     36.543M in   5.002601s
                json      2.855M (± 0.2%) i/s  (350.23 ns/i) -     14.535M in   5.090715s
        json (reuse)      5.371M (± 3.7%) i/s  (186.18 ns/i) -     27.029M in   5.041441s

Comparison:
                  oj:  7304845.2 i/s
        json (reuse):  5371216.1 i/s - 1.36x  slower
                json:  2855303.9 i/s - 2.56x  slower
</code></pre></div></div>

<p>So I started working on releasing <code class="language-plaintext highlighter-rouge">json 2.7.3</code>, and announced that from now on, I’d consider
significant performance differences on <em>realistic</em> benchmarks a bug.</p>

<p><img src="/assets/articles/json-3/tweet-release.png" alt="" /></p>

<p>I specifically said <em>realistic</em>, because I had no intention to spent time optimizing for what I consider to be unrealistic micro-benchmarks.</p>

<p>And yet, I pretty quickly got a response saying <code class="language-plaintext highlighter-rouge">ruby/json</code> was 3x slower than <code class="language-plaintext highlighter-rouge">oj</code>:</p>

<p><img src="/assets/articles/json-3/tweet-response.png" alt="" /></p>

<p>So clearly, no amount of communication on how micro-benchmarks don’t matter would be enough to change people’s perceptions.</p>

<p>If I wanted the public perception to change, I had to make <code class="language-plaintext highlighter-rouge">ruby/json</code> faster on micro-benchmarks too, and that meant
reducing the setup cost even further. But that’s a story for the next post.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>In the next post, we’ll dive into how the setup cost was optimized further, and then at some point, we’ll have to
start talking about optimizing the parser.</p>

<p>Edit: <a href="/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html">Part four is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, I covered how I reimplemented JSON::Generator::State#configure in Ruby and some other changes. Unfortunately, it didn’t go as well as I initially thought.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 2</title><link href="https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 2" /><published>2024-12-18T16:05:51+00:00</published><updated>2024-12-18T16:05:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html"><![CDATA[<p><a href="/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html">In the previous post</a>, I covered my motivations for improving <code class="language-plaintext highlighter-rouge">ruby/json</code>’s performance,
and detailed the first 4 notable optimizations applied to speed up JSON generation.</p>

<p>If I was to cover every single optimization applied, at this rate I’d end up with a dozen parts, so I’ll try to only focus on the one that made a
significant difference or used an interesting pattern.</p>

<h2 id="reducing-setup-cost---argument-parsing-edition">Reducing Setup Cost - Argument Parsing Edition</h2>

<p>As mentioned in Part 1, When your benchmark only serializes a few dozen bytes of JSON, you end up measuring the baseline overhead of 
operations needed before you get to the actual work you’re here to perform, what I call “setup cost”.</p>

<p>The very high setup cost of <code class="language-plaintext highlighter-rouge">ruby/json</code> made it perform poorly on micro-benchmarks compared to alternatives.</p>

<p>If you look at <a href="https://share.firefox.dev/3BAhuPi">the native profile</a> of <code class="language-plaintext highlighter-rouge">JSON.dump([1, "string", { a: 1, b: 2 }, [3, 4, 5]])</code>,
you can see that we only spend <code class="language-plaintext highlighter-rouge">39%</code> of the time in <code class="language-plaintext highlighter-rouge">cState_generate</code> which is where we’re actually generating JSON, everything else is the setup cost.</p>

<p><img src="/assets/articles/json-2/micro-bench-flamegraph.png" alt="" /></p>

<p>So if we want to make <code class="language-plaintext highlighter-rouge">ruby/json</code> look good on micro-benchmarks, the setup cost is what need to be reduced.</p>

<p>And a big part of that was how <code class="language-plaintext highlighter-rouge">JSON.dump</code> parses the arguments it receives, because <code class="language-plaintext highlighter-rouge">JSON.dump</code> is one of these cursed methods that can be used in
way too many different ways. Aside from the first argument which is the object to serialize, <code class="language-plaintext highlighter-rouge">dump</code> accepts 3 positional arguments that are all optional.</p>

<p>In RDoc style, the signature would be <code class="language-plaintext highlighter-rouge">dump(obj, [anIo], [depth_limit], [options])</code>. This sort of signature is quite common in old gems that predate the
introduction of keyword arguments back in Ruby 2.0, and often cause an explosion of call patterns.</p>

<p>Here are 7 different ways the method can be called.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({})</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="mi">12</span><span class="p">,</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">))</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="mi">12</span><span class="p">,</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span></code></pre></figure>

<p>Here’s how the argument parsing was implemented:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="n">io_limit_opt</span> <span class="o">=</span> <span class="p">[</span><span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">].</span><span class="nf">compact</span>
  <span class="n">kwargs</span> <span class="o">=</span> <span class="n">io_limit_opt</span><span class="p">.</span><span class="nf">pop</span> <span class="k">if</span> <span class="n">io_limit_opt</span><span class="p">.</span><span class="nf">last</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
  <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="n">io_limit_opt</span>
  <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_io</span><span class="p">)</span>
    <span class="n">anIO</span> <span class="o">=</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">to_io</span>
  <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:write</span><span class="p">)</span>
    <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">anIO</span>
  <span class="k">end</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">:max_nesting</span> <span class="o">=&gt;</span> <span class="n">limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">limit</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">merge_dump_options</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">if</span> <span class="n">kwargs</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">anIO</span>
    <span class="n">anIO</span><span class="p">.</span><span class="nf">write</span> <span class="n">result</span>
    <span class="n">anIO</span>
  <span class="k">else</span>
    <span class="n">result</span>
  <span class="k">end</span>
<span class="k">rescue</span> <span class="no">JSON</span><span class="o">::</span><span class="no">NestingError</span>
  <span class="k">raise</span> <span class="no">ArgumentError</span><span class="p">,</span> <span class="s2">"exceed depth limit"</span>
<span class="k">end</span></code></pre></figure>

<p>There are a number of operations in there that are reasonably costly in abstract, but costly enough that you don’t want to use them in hot spots.</p>

<p>The first one is <code class="language-plaintext highlighter-rouge">[anIO, limit, kwargs].compact</code>, which is used to ignore <code class="language-plaintext highlighter-rouge">nil</code> arguments. It’s quite pleasing to the eye, and fairly idiomatic Ruby,
but it means one extra allocation, which is a lot on micro-benchmarks.</p>

<p>The alternative we’re trying to catch up to, only allocates a single object on its equivalent path, the returned JSON document as a String.
But <code class="language-plaintext highlighter-rouge">ruby/json</code> also need to allocate the <code class="language-plaintext highlighter-rouge">JSON::Generator::State</code> object, so that’s a total of 3 allocations, 3 times as much as <code class="language-plaintext highlighter-rouge">oj</code> or <code class="language-plaintext highlighter-rouge">rapidjson-ruby</code>.</p>

<p>Allocations aren’t that big of a problem on modern Ruby, it’s actually quite fast, the problem is that allocating will ultimately trigger the GC,
and while that too is negligible when doing a meaningful amount of work, it’s a huge proportion of the runtime in a micro-benchmark.</p>

<p><img src="/assets/articles/json-2/setup-cost-flamegraph.png" alt="" /></p>

<p>Then, there’s the <code class="language-plaintext highlighter-rouge">respond_to?(:to_io)</code> call (and sometimes the second one), which too is totally mundane and idiomatic Ruby code, but something
you want to avoid in hot paths.</p>

<p><code class="language-plaintext highlighter-rouge">respond_to?</code> does all the same work a method call does to find which method to call, but the major difference is that method calls have an inline cache
while <code class="language-plaintext highlighter-rouge">respond_to?</code> doesn’t, so it has to do more work than most method calls.</p>

<h3 id="method-lookup">Method Lookup</h3>

<p>To give you an idea of how much work looking up a method without a cache can entail, here is what it would look like if implemented in Ruby</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Object</span>
  <span class="k">def</span> <span class="nf">respond_to?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">ancestor</span><span class="o">|</span>
      <span class="k">return</span> <span class="kp">true</span> <span class="k">if</span> <span class="n">ancestor</span><span class="p">.</span><span class="nf">methods_hash</span><span class="p">.</span><span class="nf">key?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="k">end</span>

    <span class="c1"># object doesn't respond to `method` but maybe it has a `respond_to_missing?` method.</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">ancestor</span><span class="o">|</span>
      <span class="k">if</span> <span class="n">respond_to_missing</span> <span class="o">=</span> <span class="n">ancestor</span><span class="p">.</span><span class="nf">methods_hash</span><span class="p">[</span><span class="ss">:respond_to_missing?</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">respond_to_missing</span><span class="p">.</span><span class="nf">bind_call</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="nb">method</span><span class="p">)</span>
      <span class="k">end</span>
    <span class="k">end</span>

    <span class="kp">false</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>If you assume most of the time <code class="language-plaintext highlighter-rouge">anIO</code> is <code class="language-plaintext highlighter-rouge">nil</code>, that’s a lot of needless hash lookups, because <code class="language-plaintext highlighter-rouge">nil</code> has way more ancestors than you’d think:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 4</span>
<span class="nb">require</span> <span class="s2">"json"</span>
<span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 6</span>
<span class="nb">require</span> <span class="s2">"active_support/all"</span>
<span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 9</span></code></pre></figure>

<p>And on a miss, you might actually have to do all that a second time, to check if perhaps that class implements <code class="language-plaintext highlighter-rouge">#respond_to_missing</code>.</p>

<p>As mentioned, calling a method conceptually requires as much work, however, most method calls don’t result in a <code class="language-plaintext highlighter-rouge">NoMethodError</code> so you normally don’t
go all the way up the ancestor chain, and more importantly method calls have inline caches.</p>

<h3 id="inline-caches">Inline Caches</h3>

<p><a href="https://railsatscale.com/2023-10-24-memoization-pattern-and-object-shapes/#inline-caches">I touched a bit on what inline caches are last year in my post about object shapes</a>,
but to reiterate here, when Ruby compiles your code into YARV bytecode, for every method call it leaves a little bit of space called an inline cache.</p>

<p>For instance, if Ruby has to execute <code class="language-plaintext highlighter-rouge">nil.bar</code>, it will compile that into an <code class="language-plaintext highlighter-rouge">opt_send_without_block</code> instruction:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sx">%{nil.bar}</span><span class="p">).</span><span class="nf">disasm</span>
<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(1,7)&gt;</span>
<span class="mo">0000</span> <span class="n">putnil</span>                                                           <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:bar</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="n">leave</span></code></pre></figure>

<p>Which down the line will end up in <a href="https://github.com/ruby/ruby/blob/8417d09f9381c93352fe2cddbdfd4144b5924979/vm_insnhelper.c#L2256-L2279"><code class="language-plaintext highlighter-rouge">vm_search_method_fastpath</code></a>, that has access to <code class="language-plaintext highlighter-rouge">cc</code> AKA a “callcache”.
The actual method is a bit hard to read with lots of asserts etc, but here’s a stripped-down version that should be easy to understand:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="k">struct</span> <span class="n">rb_callcache</span> <span class="o">*</span>
<span class="nf">vm_search_method_fastpath</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">cd_owner</span><span class="p">,</span> <span class="k">struct</span> <span class="n">rb_call_data</span> <span class="o">*</span><span class="n">cd</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">klass</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">struct</span> <span class="n">rb_callcache</span> <span class="o">*</span><span class="n">cc</span> <span class="o">=</span> <span class="n">cd</span><span class="o">-&gt;</span><span class="n">cc</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">LIKELY</span><span class="p">(</span><span class="n">cc</span><span class="o">-&gt;</span><span class="n">klass</span> <span class="o">==</span> <span class="n">klass</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">LIKELY</span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">cc</span><span class="o">-&gt;</span><span class="n">cme</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">INVALIDATED_FLAG</span><span class="p">))))</span> <span class="p">{</span>
            <span class="k">return</span> <span class="n">cc</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">vm_search_method_slowpath0</span><span class="p">(</span><span class="n">cd_owner</span><span class="p">,</span> <span class="n">cd</span><span class="p">,</span> <span class="n">klass</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>So in short, every single call site has a cache that contains the class of the last object this method was called on, and the result of the previous search.
Revalidating that cache is just a simple pointer comparison to ensure we’re still dealing with an instance of the same class,
and a check in a bitmap to ensure the cache wasn’t invalidated by something like <code class="language-plaintext highlighter-rouge">define_method</code> or <code class="language-plaintext highlighter-rouge">remove_method</code>.</p>

<p>That is a ton less work than the slow path, and since in practice most call sites are “monomorphic”, meaning they only ever apply to a single type,
this cache hit rate is fairly high.</p>

<p>The problem with <code class="language-plaintext highlighter-rouge">respond_to?</code> is that the name of the method we’re looking for is passed as an argument:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sx">%{nil.respond_to?(:bar)}</span><span class="p">).</span><span class="nf">disasm</span>
<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(1,21)&gt;</span>
<span class="mo">0000</span> <span class="n">putnil</span>                                                           <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">putobject</span>                              <span class="ss">:bar</span>
<span class="mo">0003</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:respond_to?</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0005</span> <span class="n">leave</span></code></pre></figure>

<p>So here we have a call cache to lookup <code class="language-plaintext highlighter-rouge">respond_to?</code> on <code class="language-plaintext highlighter-rouge">nil</code>, but nowhere to cache the lookup of <code class="language-plaintext highlighter-rouge">bar</code>.</p>

<p>It actually wouldn’t be too hard to add such a cache, we’d need to modify the Ruby compiler to compile
<code class="language-plaintext highlighter-rouge">respond_to?</code> calls into a specialized <code class="language-plaintext highlighter-rouge">opt_respond_to</code> instruction that does have two caches instead of one.
The first cache would be used to look up <code class="language-plaintext highlighter-rouge">respond_to?</code> on the object to make sure it wasn’t redefined,
and the second one to look up the method we’re interested in. Or perhaps even 3 caches, as you also need to
check if the object has a <code class="language-plaintext highlighter-rouge">respond_to_missing?</code> method defined in some cases.</p>

<p>That’s an idea I remember discussing in the past with some fellow committers, but I can’t quite remember if
there was a reason we didn’t do it yet.</p>

<h3 id="nested-caching">Nested Caching</h3>

<p>That said, even without inline caches, <code class="language-plaintext highlighter-rouge">respond_to?</code> usually avoids doing the full method lookup.</p>

<p>Given how horrendously expensive they are, method lookups have two layers of cache.
Inside the <code class="language-plaintext highlighter-rouge">Class</code> object structure, there is a field called <code class="language-plaintext highlighter-rouge">cc_tbl</code> for “call cache table”.
That’s essentially a Hash with method names as keys, and “call caches” as values.</p>

<p>So <code class="language-plaintext highlighter-rouge">respond_to?</code>’s implementation is actually more like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Object</span>
  <span class="k">def</span> <span class="nf">respond_to?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="n">cc</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">call_cache</span><span class="p">[</span><span class="nb">method</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">method_entry</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">search_method_with_cache</span><span class="p">(</span><span class="nb">method</span><span class="p">,</span> <span class="n">cc</span><span class="p">)</span>
      <span class="kp">true</span>
    <span class="k">else</span>
      <span class="n">respond_to_missing_cc</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">call_cache</span><span class="p">[</span><span class="nb">method</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">respond_to_missing</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">search_method_with_cache</span><span class="p">(</span><span class="ss">:respond_to_missing?</span><span class="p">,</span> <span class="n">cc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">respond_to_missing</span><span class="p">.</span><span class="nf">bind_call</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="nb">method</span><span class="p">)</span>
      <span class="k">end</span>
    <span class="k">end</span>
    <span class="kp">false</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>So it’s thankfully much less work than an uncached method lookup, but when <code class="language-plaintext highlighter-rouge">respond_to?</code> returns <code class="language-plaintext highlighter-rouge">false</code>
we’re still doing at least two hash lookups to get the corresponding call caches.</p>

<p>So you can see how calling <code class="language-plaintext highlighter-rouge">respond_to?</code> on <code class="language-plaintext highlighter-rouge">nil</code> is a bit of a waste.</p>

<h3 id="cheaper-argument-parsing">Cheaper Argument Parsing</h3>

<p>But enough digression, and back to the problem at hand.</p>

<p>In most cases, none of these options are set, so the goal is to avoid allocating an array,
and avoid <code class="language-plaintext highlighter-rouge">respond_to?</code> when possible, <a href="https://github.com/ruby/json/pull/616">which led me to rewrite <code class="language-plaintext highlighter-rouge">dump</code> as this</a>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">kwargs</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="k">if</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span>
      <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">anIO</span>
        <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span>
      <span class="k">end</span>
    <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
      <span class="n">kwargs</span> <span class="o">=</span> <span class="n">limit</span>
      <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="k">unless</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_io</span><span class="p">)</span>
      <span class="n">anIO</span> <span class="o">=</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">to_io</span>
    <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:write</span><span class="p">)</span>
      <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">anIO</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="n">opts</span> <span class="o">=</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">:max_nesting</span> <span class="o">=&gt;</span> <span class="n">limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">limit</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">merge_dump_options</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">if</span> <span class="n">kwargs</span>

  <span class="k">begin</span>
    <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
      <span class="n">opts</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span><span class="p">)</span>
    <span class="k">else</span>
      <span class="no">State</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">,</span> <span class="n">anIO</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">rescue</span> <span class="no">JSON</span><span class="o">::</span><span class="no">NestingError</span>
    <span class="k">raise</span> <span class="no">ArgumentError</span><span class="p">,</span> <span class="s2">"exceed depth limit"</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>So instead of using <code class="language-plaintext highlighter-rouge">Array#compact</code>, we do multiple nested <code class="language-plaintext highlighter-rouge">if thing.nil?</code> checks. It’s more verbose, but much more efficient, allocations
free, and JIT very well.</p>

<p>The <code class="language-plaintext highlighter-rouge">is_a?(Hash)</code> calls are no performance concern on Ruby 3.2+ thanks to <a href="https://www.youtube.com/watch?v=qlq-iQGtCgs">John Hawthorn’s stellar work</a>, so they can stay.</p>

<p>As for <code class="language-plaintext highlighter-rouge">respond_to?</code>, we can’t fully eliminate it, but at least we can avoid calling it when the variable is <code class="language-plaintext highlighter-rouge">nil</code>, which should be most of the time.</p>

<p>All this combined yielded a nice <code class="language-plaintext highlighter-rouge">16%</code> improvement on micro benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   227.226k i/100ms
Calculating -------------------------------------
               after      2.415M (± 0.9%) i/s  (414.02 ns/i) -     12.270M in   5.080537s

Comparison:
              before:  2078464.1 i/s
               after:  2415336.1 i/s - 1.16x  faster
</code></pre></div></div>

<p>After I merged that patch, <a href="https://github.com/eregon">Benoit Daloze</a> a fellow Ruby committer and TruffleRuby lead, suggested a funny trick that is
used very effectively in the Ruby stdlib for optimizing this sort of signature:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="p">(</span><span class="n">no_args_set</span> <span class="o">=</span> <span class="kp">true</span><span class="p">;</span> <span class="kp">nil</span><span class="p">),</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">unless</span> <span class="n">no_args_set</span>
    <span class="c1"># do the whole argument parsing</span>
  <span class="k">end</span>

  <span class="c1"># ...</span>
<span class="k">end</span></code></pre></figure>

<p>I love that trick because it exploits the fact that, like pretty much everything in Ruby, arguments’ default values are expressions.</p>

<p>This trick is most commonly used when you need to know if an argument was passed as <code class="language-plaintext highlighter-rouge">nil</code> or just not passed, <a href="https://github.com/ruby/ruby/blob/8417d09f9381c93352fe2cddbdfd4144b5924979/hash.rb#L37-L39">an example of that
is <code class="language-plaintext highlighter-rouge">Hash#initialize</code></a></p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Hash</span>
  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">ifnone</span> <span class="o">=</span> <span class="p">(</span><span class="n">ifnone_unset</span> <span class="o">=</span> <span class="kp">true</span><span class="p">),</span> <span class="ss">capacity: </span><span class="mi">0</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">block</span><span class="p">)</span>
    <span class="no">Primitive</span><span class="p">.</span><span class="nf">rb_hash_init</span><span class="p">(</span><span class="n">capacity</span><span class="p">,</span> <span class="n">ifnone_unset</span><span class="p">,</span> <span class="n">ifnone</span><span class="p">,</span> <span class="n">block</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>If it used the classic <code class="language-plaintext highlighter-rouge">ifnone = nil</code> signature, it wouldn’t be possible to differentiate <code class="language-plaintext highlighter-rouge">Hash.new</code> and <code class="language-plaintext highlighter-rouge">Hash.new(nil)</code>.</p>

<p>However in this case that trick didn’t make a measurable difference, so I didn’t include that suggestion, but I thought it was worth a mention.</p>

<h2 id="jump-tables">Jump Tables</h2>

<p>The previous optimization helped with the setup cost, but it was still way more expensive than it should.</p>

<p>So I went to craft an even more micro-benchmark, trying to reduce the time spent generating JSON to better see the setup cost:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">obj</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><img src="/assets/articles/json-2/setup-cost-flamegraph-2.png" alt="" /></p>

<p><a href="https://share.firefox.dev/41EtIkw">Full profile.</a></p>

<p>As you may have spotted on that flame graph, a huge part of the setup is spent in <code class="language-plaintext highlighter-rouge">rb_hash_aref</code> and <code class="language-plaintext highlighter-rouge">rb_hash_has_key</code>, which are the
C API equivalents of <code class="language-plaintext highlighter-rouge">Hash#[]</code> and <code class="language-plaintext highlighter-rouge">Hash#key?</code>.</p>

<p>And all of this was in the <code class="language-plaintext highlighter-rouge">JSON::Generator::State#configure</code> method, implemented in C this way:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define option_given_p(opts, key) RTEST(rb_funcall(opts, i_key_p, 1, key))
</span>
<span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_configure</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">self</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">opts</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_check_convert_type</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">T_HASH</span><span class="p">,</span> <span class="s">"Hash"</span><span class="p">,</span> <span class="s">"to_hash"</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_convert_type</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">T_HASH</span><span class="p">,</span> <span class="s">"Hash"</span><span class="p">,</span> <span class="s">"to_h"</span><span class="p">);</span>
    <span class="n">opts</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_indent</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
        <span class="n">Check_Type</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">T_STRING</span><span class="p">);</span>
        <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">indent</span> <span class="o">=</span> <span class="n">fstrndup</span><span class="p">(</span><span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">tmp</span><span class="p">),</span> <span class="n">len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">indent_len</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_space</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
        <span class="n">Check_Type</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">T_STRING</span><span class="p">);</span>
        <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">space</span> <span class="o">=</span> <span class="n">fstrndup</span><span class="p">(</span><span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">tmp</span><span class="p">),</span> <span class="n">len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">space_len</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// ....</span>

    <span class="n">tmp</span> <span class="o">=</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_max_nesting</span><span class="p">);</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">option_given_p</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">VALUE</span> <span class="n">max_nesting</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">tmp</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">Check_Type</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">,</span> <span class="n">T_FIXNUM</span><span class="p">);</span>
            <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="n">FIX2LONG</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span></code></pre></figure>

<p>Which again is very verbose and noisy because it’s in C, but is essentially the naive way you’d initialize some object state from an options hash:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">configure</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">indent</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:indent</span><span class="p">]</span>
    <span class="vi">@indent</span> <span class="o">=</span> <span class="n">ensure_string</span><span class="p">(</span><span class="n">indent</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="k">if</span> <span class="n">space</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:space</span><span class="p">]</span>
    <span class="vi">@space</span> <span class="o">=</span> <span class="n">ensure_string</span><span class="p">(</span><span class="n">space</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="c1"># ...</span>

  <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">key?</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_nesting</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:max_nesting</span><span class="p">]</span>
      <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="no">Integer</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">)</span>
    <span class="k">else</span>
      <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<h3 id="gccct">gccct</h3>

<p>On the surface, there is some weirdly inefficient code here, such as using:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">RTEST</span><span class="p">(</span><span class="n">rb_funcall</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">i_key_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span></code></pre></figure>

<p>To check if the option hash contains a key. Calling a method from C is quite costly because, you guessed it, looking up a method without a cache is costly.
Here again, we don’t have an inline cache, so Ruby has yet another trick down its sleeve to not make the performance atrocious,
the <code class="language-plaintext highlighter-rouge">gccct</code>. No I’m not having a stroke, it’s the acronym for “Global Call Cache Cache Table”, and yes it’s a cache of caches.</p>

<p>I did write <a href="https://twitter.com/_byroot/status/1831417434223604146">a Twitter thread back in September that talked about the <code class="language-plaintext highlighter-rouge">gccct</code></a>, but since
that site is quite hostile to outsiders, I’ll repeat some of it here.</p>

<p>The <code class="language-plaintext highlighter-rouge">gccct</code> is just a big global array of exactly <code class="language-plaintext highlighter-rouge">1023</code> <code class="language-plaintext highlighter-rouge">call_cache</code> objects, so when you need to lookup a method and there’s no better cache you can use,
you use one of these global caches:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span> <span class="o">=</span> <span class="mi">1023</span>
<span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gccct_method_search</span><span class="p">(</span><span class="n">receiver</span><span class="p">,</span> <span class="n">method_name</span><span class="p">)</span>
  <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">receiver</span><span class="p">.</span><span class="nf">class</span><span class="p">,</span> <span class="n">method_name</span><span class="p">].</span><span class="nf">hash</span> <span class="o">%</span> <span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span>
  <span class="n">call_cache</span> <span class="o">=</span> <span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
  <span class="n">cached_method_search</span><span class="p">(</span><span class="n">receiver</span><span class="p">,</span> <span class="n">method_name</span><span class="p">,</span> <span class="n">call_cache</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>It’s as simple as that, we do a digest of the receiver class and the method name, and use that as an offset inside the array to select a call cache.</p>

<p>Of course, it can be subject to collisions, so distinct calls can end up sharing the same cache and make it flip-flop, but it still offers some decent
hit rate for cheap, so it’s better than nothing.</p>

<p>But that’s yet another digression because ultimately we just don’t need that at all, given the C API exposes some C functions
that allow us to check if a key exists without needing to go through method lookup. I suspect this may have been implemented this way
a long time ago to also support Hash-like objects, but it really isn’t worth the overhead.</p>

<p>In another Pull Request, <a href="https://github.com/luke-gru">Luke Gruber</a> had done <a href="https://github.com/ruby/json/pull/512/files#diff-2f079e65e9070fc3350059dbb4804c04be215ff9bed44144ee68b4de90faf2a6R20-R27">a similar optimization for the parser initialization</a>,
rewriting <code class="language-plaintext highlighter-rouge">option_given_p</code> into:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">hash_has_key</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">hash</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">key</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">Qundef</span> <span class="o">==</span> <span class="n">rb_hash_lookup2</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">Qundef</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Qtrue</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">Qfalse</span><span class="p">;</span>
<span class="p">}</span>
<span class="cp">#define option_given_p(opts, key) (RTEST(hash_has_key(opts, key)))</span></code></pre></figure>

<p>And I could probably have done the same here, but I had another, less conventional, idea.</p>

<h3 id="inversion-of-priorities">Inversion of Priorities</h3>

<p>There’s probably a name for that optimization, but if so I don’t know it.</p>

<p>When thinking about the problem, it occurred to me that there are 13 possible option keys we need to check,
but in the vast majority of cases, the hash will only contain a few of them.</p>

<p>By default <code class="language-plaintext highlighter-rouge">JSON.dump</code> starts from the <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> global config, so if you call dump with no extra options, that’s what we’ll get:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">  <span class="n">self</span><span class="p">.</span><span class="n">dump_default_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">:</span><span class="n">max_nesting</span> <span class="o">=&gt;</span> <span class="nb">false</span><span class="p">,</span>
    <span class="o">:</span><span class="n">allow_nan</span>   <span class="o">=&gt;</span> <span class="nb">true</span><span class="p">,</span>
    <span class="o">:</span><span class="n">script_safe</span> <span class="o">=&gt;</span> <span class="nb">false</span><span class="p">,</span>
  <span class="p">}</span></code></pre></figure>

<p>Actually, out of these 3 keys, the third one is useless, as it’s already the default, so really most of the time we only have two keys to check.</p>

<p>So what if instead of doing one to two lookups for every possible key (13), we’d iterate over the provided keys and use a <a href="https://en.wikipedia.org/wiki/Branch_table">jump table</a>?</p>

<p>The problem, however, is to do jump tables in C, you need a <code class="language-plaintext highlighter-rouge">switch</code> statement with static values, and hash keys are Ruby symbol objects, hence we can’t statically
know their value because they’re defined at runtime.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">switch</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">case</span> <span class="n">sym_max_nesting</span><span class="p">:</span> <span class="c1">// This is just not possible...</span>
    <span class="k">break</span><span class="p">;</span>
  
<span class="p">}</span></code></pre></figure>

<p>But what few people know, is that Ruby’s <code class="language-plaintext highlighter-rouge">case</code> statement do generate a jump table when possible. Let me show you:</p>

<p>By default Ruby’s <code class="language-plaintext highlighter-rouge">case</code> just compiles down to a series of <code class="language-plaintext highlighter-rouge">if / elsif</code>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="o">&lt;&lt;~</span><span class="no">RUBY</span><span class="p">).</span><span class="nf">disasm</span><span class="sh">
case key
when /foo/
  something
when /bar/
  something_else
end
</span><span class="no">RUBY</span>

<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(6,3)&gt;</span>
<span class="mo">0000</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:key</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="n">putobject</span>                              <span class="sr">/foo/</span>                     <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0005</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0007</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">000</span><span class="mi">9</span> <span class="n">branchif</span>                               <span class="mi">22</span>
<span class="mo">0011</span> <span class="n">putobject</span>                              <span class="sr">/bar/</span>                     <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0013</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0015</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0017</span> <span class="n">branchif</span>                               <span class="mi">27</span>
<span class="mo">001</span><span class="mi">9</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">1</span><span class="p">)</span>
<span class="mo">0020</span> <span class="n">putnil</span>
<span class="mo">0021</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0022</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0023</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">3</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0024</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0026</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0027</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">002</span><span class="mi">8</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">5</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">002</span><span class="mi">9</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something_else</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0031</span> <span class="n">leave</span></code></pre></figure>

<p>If you’re not familar with YARV assembly, here’s the “desugared” Ruby version of it:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">if</span> <span class="n">key</span> <span class="o">===</span> <span class="sr">/foo/</span>
  <span class="n">something</span>
<span class="k">elsif</span> <span class="n">key</span> <span class="o">===</span> <span class="sr">/bar/</span>
  <span class="n">something_else</span>
<span class="k">end</span></code></pre></figure>

<p>So it’s not a jump table, just some syntax sugar for <code class="language-plaintext highlighter-rouge">if / elsif</code>.
But if all the <code class="language-plaintext highlighter-rouge">when</code> values are essentially static (this includes literal numbers, literal symbols and literal strings),
Ruby generates some slightly different bytecode:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="o">&lt;&lt;~</span><span class="no">RUBY</span><span class="p">).</span><span class="nf">disasm</span><span class="sh">
case key
when :foo
  something
when :bar
  something_else
end
</span><span class="no">RUBY</span>

<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(6,3)&gt;</span>
<span class="mo">0000</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:key</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="nb">dup</span>
<span class="mo">0004</span> <span class="n">opt_case_dispatch</span>                      <span class="o">&lt;</span><span class="n">cdhash</span><span class="o">&gt;</span><span class="p">,</span> <span class="mi">23</span>
<span class="mo">0007</span> <span class="n">putobject</span>                              <span class="ss">:foo</span>                      <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">000</span><span class="mi">9</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0011</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0013</span> <span class="n">branchif</span>                               <span class="mi">26</span>
<span class="mo">0015</span> <span class="n">putobject</span>                              <span class="ss">:bar</span>                      <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0017</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">001</span><span class="mi">9</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0021</span> <span class="n">branchif</span>                               <span class="mi">31</span>
<span class="mo">0023</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">1</span><span class="p">)</span>
<span class="mo">0024</span> <span class="n">putnil</span>
<span class="mo">0025</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0026</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0027</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">3</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">002</span><span class="mi">8</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0030</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0031</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0032</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">5</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0033</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something_else</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0035</span> <span class="n">leave</span></code></pre></figure>

<p>The thing to notice here is the <code class="language-plaintext highlighter-rouge">opt_case_dispatch</code> instruction, which wasn’t present on the previous disassembly.
What this instruction does, is that it holds a Hash, of which the keys are the static values we use in the <code class="language-plaintext highlighter-rouge">when</code> statements
and the values are the bytecode offset to which to directly jump. The rest of the bytecode is the same, to be used as the fallback
if the <code class="language-plaintext highlighter-rouge">opt_case_dispatch</code> doesn’t match.</p>

<p>With this, we can check as many symbols as we want in somewhat constant time, all we had to do was to rewrite all that nasty C code in Ruby,
<a href="https://github.com/ruby/json/pull/617/commits/25db79dfaa8f019077ef7e713a5aa62ff6af4a99">which I did in the most straightforward way in a preparatory commit</a>.
That commit alone already brought a <code class="language-plaintext highlighter-rouge">3%</code> improvement, thanks to inline caches:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   230.150k i/100ms
Calculating -------------------------------------
               after      2.450M (± 0.5%) i/s  (408.23 ns/i) -     12.428M in   5.073603s

Comparison:
              before:  2370478.1 i/s
               after:  2449616.3 i/s - 1.03x  faster
</code></pre></div></div>

<p>But I then followed up in the same pull request, with <a href="https://github.com/ruby/json/pull/617/commits/a75c9eccfd35e1d6715b05cbd7ef4d83b1bc177e">a rewrite of <code class="language-plaintext highlighter-rouge">State#configure</code> to use a case dispatch</a>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">configure</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">unless</span> <span class="n">opts</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_hash</span><span class="p">)</span>
      <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">to_hash</span>
    <span class="k">elsif</span> <span class="n">opts</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_h</span><span class="p">)</span>
      <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">to_h</span>
    <span class="k">else</span>
      <span class="k">raise</span> <span class="no">TypeError</span><span class="p">,</span> <span class="s2">"can't convert </span><span class="si">#{</span><span class="n">opts</span><span class="p">.</span><span class="nf">class</span><span class="si">}</span><span class="s2"> into Hash"</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="n">opts</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">|</span>
    <span class="k">case</span> <span class="n">key</span>
    <span class="k">when</span> <span class="ss">:indent</span>
      <span class="nb">self</span><span class="p">.</span><span class="nf">indent</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">when</span> <span class="ss">:space</span>
      <span class="nb">self</span><span class="p">.</span><span class="nf">space</span> <span class="o">=</span> <span class="n">value</span>
    <span class="c1"># ...</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>And that brought a further <code class="language-plaintext highlighter-rouge">11%</code> improvement:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   247.127k i/100ms
Calculating -------------------------------------
               after      2.645M (± 0.6%) i/s  (378.07 ns/i) -     13.345M in   5.045454s

Comparison:
              before:  2379291.6 i/s
               after:  2645019.6 i/s - 1.11x  faster
</code></pre></div></div>

<p>So the rewrite in Ruby was a win-win, less C code to maintain, and more efficiency overall.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>I only talked about two small optimizations, but I digressed so much that it’s already longer than part one,
and I probably won’t have time to write in the next few days, so it’s probably best if I stop here for part two.</p>

<p>At this rate, and based only on the number of commits I haven’t yet covered, I may need 5 or 6 more parts,
but I hope I won’t have to disgress as much as the series progress, and not all commits may be worth talking about.</p>

<p>Edit: <a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html">Part three is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, I covered my motivations for improving ruby/json’s performance, and detailed the first 4 notable optimizations applied to speed up JSON generation.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 1</title><link href="https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 1" /><published>2024-12-15T19:19:51+00:00</published><updated>2024-12-15T19:19:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html"><![CDATA[<p>I was recently made maintainer of the <code class="language-plaintext highlighter-rouge">json</code> gem, and aside from fixing some old bugs, I focused quite a bit on its performance,
so that it is now the fastest JSON parser and generator for Ruby on most benchmarks.</p>

<p>Contrary to what one might think, there wasn’t any black magic or deep knowledge involved.
Most of the performance patches I applied were fairly simple optimizations driven by profiling.
As such, I’d like to go over these changes to show how they are quite generic and that many don’t only apply to C code.</p>

<p>But before I dive into these, let me explain why I came about working on this in the first place.</p>

<h2 id="there-should-be-no-need-for-alternatives">There Should Be No Need For Alternatives</h2>

<p>My motivation was never really performance per se. <code class="language-plaintext highlighter-rouge">ruby/json</code> was indeed slower than popular alternatives such as <code class="language-plaintext highlighter-rouge">oj</code>, but not by that much.</p>

<p>To take one benchmark as an example, parsing a JSON document consisting of <a href="https://github.com/ruby/json/blob/e1f6456499d497f33f69ae4c1afdaf9b2b9c50b3/benchmark/data/twitter.json">one hundred tweets or 467kiB</a>
would take <code class="language-plaintext highlighter-rouge">1.9ms</code> with <code class="language-plaintext highlighter-rouge">json 2.7.2</code>, and <code class="language-plaintext highlighter-rouge">1.6ms</code> with <code class="language-plaintext highlighter-rouge">oj</code>. So not that big of a difference.</p>

<p>On the generation side, <code class="language-plaintext highlighter-rouge">json 2.7.2</code> would take <code class="language-plaintext highlighter-rouge">0.8ms</code> to generate that document, and <code class="language-plaintext highlighter-rouge">oj</code> would take <code class="language-plaintext highlighter-rouge">0.4ms</code>.
Twice better, but unlikely to make a significant difference for the vast majority of use cases.
In general what’s slow is the layer above the JSON serialization, the one that turns Active Record models into basic Ruby Hashes and Arrays to feed them to the JSON serializer.
But the JSON serializer itself is generally negligible.</p>

<p>And yet, <code class="language-plaintext highlighter-rouge">oj</code> is extremely popular, I highly suspect because of its speed, and is included in the vast majority of projects I know, including Shopify’s codebase, and that annoys me.</p>

<p>This may surprise you, given generally when <code class="language-plaintext highlighter-rouge">oj</code> is mentioned online, all you can read is praises and how it’s just “free performance”, but my opinion differs very significantly here.</p>

<p>Why? Because <code class="language-plaintext highlighter-rouge">oj</code> has caused me innumerable headaches over the years, so many I couldn’t list them all here, but I can mention a few.</p>

<h3 id="with-monkey-patching-comes-great-responsibility">With Monkey Patching Comes Great Responsibility</h3>

<p>One way <code class="language-plaintext highlighter-rouge">oj</code> is frequently used is by monkey patching the <code class="language-plaintext highlighter-rouge">json</code> gem via <code class="language-plaintext highlighter-rouge">Oj.mimic_JSON</code> or <code class="language-plaintext highlighter-rouge">ActiveSupport::JSON</code> via <code class="language-plaintext highlighter-rouge">Oj.optimize_rails</code>.</p>

<p>The premise of these methods is that they’re supposed to replace less efficient implementations of JSON and do the same thing but faster.
For the most part, it holds true, but in some cases, it can go terribly wrong.</p>

<p>For instance, one day I had to deal with a security issue caused by <code class="language-plaintext highlighter-rouge">Oj.mimic_json</code>.
One gem was using <code class="language-plaintext highlighter-rouge">JSON.dump(data, script_safe: true)</code>, to safely include a JSON document inside a <code class="language-plaintext highlighter-rouge">&lt;script&gt;</code> tag:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="s2">"&lt;/script&gt;"</span><span class="p">)</span> <span class="c1"># =&gt; &lt;/script&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="s2">"&lt;/script&gt;"</span><span class="p">,</span> <span class="ss">script_safe: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; &lt;\/script&gt;</span></code></pre></figure>

<p>Except that <code class="language-plaintext highlighter-rouge">oj</code> doesn’t know about the <code class="language-plaintext highlighter-rouge">script_safe</code> option, and simply ignores it. So the gem was safe when ran alone,
but once used in an application that called <code class="language-plaintext highlighter-rouge">Oj.mimic_JSON</code>, it would open the door to XSS attacks…:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">Oj</span><span class="p">.</span><span class="nf">mimic_JSON</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="s2">"&lt;/script&gt;"</span><span class="p">,</span> <span class="ss">script_safe: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; &lt;/script&gt;</span></code></pre></figure>

<p>This isn’t to say monkey patching is wrong in essence, but it should be done with great care,
considering how the patched API may evolve in the future and how to safety fallback or at least explictly error when something is amiss.</p>

<p><code class="language-plaintext highlighter-rouge">Oj.optimize_rails</code> similarly can cause some very subtle differences in how objects are serialized, e.g.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">ActiveSupport</span><span class="o">::</span><span class="no">JSON</span><span class="o">::</span><span class="no">Encoding</span><span class="p">.</span><span class="nf">time_precision</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">t</span> <span class="o">=</span> <span class="no">Time</span><span class="p">.</span><span class="nf">now</span>

<span class="nb">puts</span> <span class="no">ActiveSupport</span><span class="o">::</span><span class="no">JSON</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="c1"># =&gt; "2024-12-16T16:00:51+01:00"</span>

<span class="nb">require</span> <span class="s1">'oj'</span>
<span class="no">Oj</span><span class="p">.</span><span class="nf">optimize_rails</span>
<span class="no">Oj</span><span class="p">.</span><span class="nf">mimic_JSON</span>

<span class="nb">puts</span> <span class="no">ActiveSupport</span><span class="o">::</span><span class="no">JSON</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="c1"># =&gt; "2024-12-16T16:00:51.790+01:00"</span></code></pre></figure>

<p>This one is a bit of a corner case caused by load order, but I had to waste a lot of time fighting with it in the past.
<a href="https://github.com/ohler55/oj/pull/936">And until very recently, it changed the behavior way more than that</a>.</p>

<h3 id="quite-unstable">Quite Unstable</h3>

<p>Another big reason I don’t recommend <code class="language-plaintext highlighter-rouge">oj</code> is that from my experience of running it at scale, it has been one of the most prominent sources of
Ruby crashes for us, only second to <code class="language-plaintext highlighter-rouge">grpc</code>.</p>

<p>I and my teammates had to submit quite several patches for weird crashes we ran into, which in itself isn’t a red flag,
as we did as much for many other native gems, but <code class="language-plaintext highlighter-rouge">oj</code> is <em>very</em> actively developed, so we’d often run into new crashes and never
felt like the gem was fixed.</p>

<p>Writing a native gem isn’t inherently hard, but it does require some substantial understanding of how the Ruby VM works, especially its GC,
to not cause crashes or worse, memory corruption.
And while working on these patches for <code class="language-plaintext highlighter-rouge">Oj</code>, we’ve seen quite a few dirty hacks in the codebase that made us worried about trusting it.
Just to give an example (that has been thankfully fixed since), <a href="https://github.com/ohler55/oj/blob/8a1773dded9da5365f51c8c70026c5a98650f76d/ext/oj/fast.c#L1105-L1109"><code class="language-plaintext highlighter-rouge">oj</code> used to disable GC in some cases to workaround a bug</a>,
which in addition to being worrying, also causes a major GC cycle to be triggered when GC is re-enabled later.
This is the sort of code that makes for great results on micro-benchmarks, but tank performance in actual production code.</p>

<p>That’s why a couple of years back I decided to remove Oj from Shopify’s monolith, and that’s when I discovered all the subtle differences
between <code class="language-plaintext highlighter-rouge">Oj.mimic_JSON</code> and the real <code class="language-plaintext highlighter-rouge">json</code>.</p>

<h2 id="ground-work">Ground Work</h2>

<p>So my motivation was to hopefully make <code class="language-plaintext highlighter-rouge">ruby/json</code> perform about as well as <code class="language-plaintext highlighter-rouge">oj</code> on both real-world and micro-benchmark so that users
would no longer feel the need to monkey patch <code class="language-plaintext highlighter-rouge">json</code> for speed reasons. If they still feel like they need one of the more advanced <code class="language-plaintext highlighter-rouge">oj</code> APIs
that’s fine, but <code class="language-plaintext highlighter-rouge">Oj.mimic_JSON</code> should no longer feel appealing.</p>

<p>So <a href="https://github.com/ruby/json/pull/606">the very first step was to setup a suite of benchmarks</a>, comprising both micro-benchmarks and more meaty,
real-world benchmarks.
Thankfully, <a href="https://github.com/jhawthorn/rapidjson-ruby/">John Hawthorn’s rapidjson-ruby gem</a> had such a benchmark suite, which I stole as a basis with some minor additions.</p>

<p>With that, all I needed was a decent C profiler. There are several options, but my favorite is <a href="https://github.com/mstange/samply">samply</a>,
which has the nice property of outputting Firefox Profiler compatible reports that are easy to share.</p>

<h2 id="avoid-redundant-checks">Avoid Redundant Checks</h2>

<p>I then started profiling the <code class="language-plaintext highlighter-rouge">JSON.dump</code> benchmark with the <code class="language-plaintext highlighter-rouge">twitter.json</code> payload:</p>

<p><img src="/assets/articles/json-1/is-valid-utf8.png" alt="" /></p>

<p><a href="https://share.firefox.dev/3VHqFUO">Full profile</a></p>

<p>You need to know Ruby internals a bit to understand it all, but almost immediately something that surprised me was <code class="language-plaintext highlighter-rouge">9%</code> of the time
spent in JSON’s own <code class="language-plaintext highlighter-rouge">isLegalUTF8</code>, and also <code class="language-plaintext highlighter-rouge">1.9%</code> in <code class="language-plaintext highlighter-rouge">rb_enc_str_asciionly_p</code>, which is the <code class="language-plaintext highlighter-rouge">C</code> API version of <code class="language-plaintext highlighter-rouge">String#ascii_only?</code>.</p>

<p>The reason this is surprising is that Ruby string have some internal property called a <code class="language-plaintext highlighter-rouge">coderange</code>. For most string operations, Ruby does need to
known if it’s properly encoded, and for some operations, it can take shortcuts if the string only contains ASCII.</p>

<p>Since scanning a string to validate its encoding is somewhat costly, it keeps that property around so a string is only scanned once as long as it’s not mutated.</p>

<p>A coderange can be one of 4 values:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ENC_CODERANGE_UNKNOWN</code>: the string wasn’t scanned yet.</li>
  <li><code class="language-plaintext highlighter-rouge">ENC_CODERANGE_VALID</code>: the string encoding is valid.</li>
  <li><code class="language-plaintext highlighter-rouge">ENC_CODERANGE_7BIT</code>: the string encoding is valid and only contains ASCII characters.</li>
  <li><code class="language-plaintext highlighter-rouge">ENC_CODERANGE_INVALID</code>: the string encoding is invalid.</li>
</ul>

<p>And some functions like <code class="language-plaintext highlighter-rouge">rb_enc_str_asciionly_p</code> are called, what they do is that if the coderange is unknown, they scan the string to compute it.
After that, it’s a very cheap integer comparison against <code class="language-plaintext highlighter-rouge">ENC_CODERANGE_7BIT</code>.</p>

<p>So <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON_ASCII</code> had this weird thing where it would call <code class="language-plaintext highlighter-rouge">rb_enc_str_asciionly_p</code> at the very beginning, but then later it would
manually scan the string to see if it contains valid UTF-8, doing redundant work already performed by <code class="language-plaintext highlighter-rouge">rb_enc_str_asciionly_p</code>.</p>

<p>All this UTF-8 scanning could simply be replaced by a comparison of the string already computed coderange:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">int</span> <span class="n">ascii_only</span> <span class="o">=</span> <span class="n">rb_enc_str_asciionly_p</span><span class="p">(</span><span class="n">string</span><span class="p">);</span>

<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">ascii_only</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_ENCODING_GET_INLINED</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">!=</span> <span class="n">rb_utf8_encindex</span><span class="p">()</span> <span class="o">||</span>
        <span class="n">RB_ENC_CODERANGE</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">!=</span> <span class="n">RUBY_ENC_CODERANGE_VALID</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">rb_raise</span><span class="p">(</span><span class="n">rb_path2class</span><span class="p">(</span><span class="s">"JSON::GeneratorError"</span><span class="p">),</span>
                <span class="s">"source sequence is illegal/malformed utf-8"</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>Since C extensions code can be a bit cryptic when you’re not familiar with it, the Ruby version of that is simply:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">unless</span> <span class="n">string</span><span class="p">.</span><span class="nf">ascii_only?</span>
  <span class="k">if</span> <span class="n">string</span><span class="p">.</span><span class="nf">encoding</span> <span class="o">!=</span> <span class="no">Encoding</span><span class="o">::</span><span class="no">UTF_8</span> <span class="o">||</span> <span class="o">!</span><span class="n">string</span><span class="p">.</span><span class="nf">valid_encoding?</span>
    <span class="k">raise</span> <span class="no">JSON</span><span class="o">::</span><span class="no">GeneratorError</span><span class="p">,</span> <span class="s2">"source sequence is illegal/malformed utf-8"</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>Here both <code class="language-plaintext highlighter-rouge">#ascii_only?</code> and <code class="language-plaintext highlighter-rouge">#valid_encoding?</code> rely on the cached coderange, so the string would be scanned at most once, while previously
it could be scanned twice.</p>

<p>Unfortunately, that optimization didn’t perform as well as I initially expected:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   105.000 i/100ms
Calculating -------------------------------------
               after      1.113k (± 0.8%) i/s  (898.26 μs/i) -      5.670k in   5.093474s

Comparison:
              before:     1077.3 i/s
               after:     1113.3 i/s - 1.03x  faster
</code></pre></div></div>

<p>Given that <code class="language-plaintext highlighter-rouge">isLegalUTF8</code> was reported as being <code class="language-plaintext highlighter-rouge">9%</code> of the overall runtime, you’d expect that skipping it would speed up the code by <code class="language-plaintext highlighter-rouge">9%</code>,
but it’s not that simple. A large part of the time that used to be spent in <code class="language-plaintext highlighter-rouge">isLegalUTF8</code> instead went to <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>. While I’m not 100% sure,
the likely reason is that the larger part of these 9% was spent loading the strings content from RAM into the CPU cache, and not processing it.
Since we still go over these bytes later on, they still do the actually costly part of fetching the memory.</p>

<p>Still, a 3% improvement was nice to see.</p>

<h2 id="check-the-cheaper-more-likely-condition-first">Check the Cheaper, More Likely Condition First</h2>

<p>In parallel to the previous patch, another function I looked at was <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code>, reported as <code class="language-plaintext highlighter-rouge">5.7%</code> of total runtime.</p>

<p><img src="/assets/articles/json-1/is-valid-utf8.png" alt="" /></p>

<p><a href="https://share.firefox.dev/3VHqFUO">Full profile</a></p>

<p>Looking at the profiler heat map of that function, I noticed that most of the time is spent checking if the buffer was already allocated or not:</p>

<p><img src="/assets/articles/json-1/fbuffer_inc_capa_heatmap.png" alt="" /></p>

<p>But this function is called every time we’re trying to write anything to the buffer and after the first call, the buffer is always already allocated.
So that’s a lot of wasted effort for a condition that doesn’t match 99% of the time.</p>

<p>Also, that condition is a bit redundant with the <code class="language-plaintext highlighter-rouge">if (required &gt; fb-&gt;capa)</code> one, as if the buffer wasn’t allocated yet, <code class="language-plaintext highlighter-rouge">fb-&gt;capa</code> would be <code class="language-plaintext highlighter-rouge">0</code>,
hence, there’s no point checking it first, we should check it after we establish that the buffer capacity needs to be increased.</p>

<p>Another thing to know about modern CPUs is that <a href="https://en.wikipedia.org/wiki/Superscalar_processor">they’re “superscalar”</a>, meaning they don’t actually
perform instruction one by one, but concurrently, and when faced with a branch, they take an educated guess at which branch is more likely to be taken
and start executing that one immediately.</p>

<p>Based on that, it would be advantageous to instruct the CPU that both the <code class="language-plaintext highlighter-rouge">if (required &gt; fb-&gt;capa)</code> and the <code class="language-plaintext highlighter-rouge">if (!fb-&gt;ptr)</code> conditions are very
unlikely to match.</p>

<p>To do that, compilers have various constructs, but Ruby helpfully exposes a macro to support most compilers with the same syntax: <code class="language-plaintext highlighter-rouge">RB_LIKELY</code> and <code class="language-plaintext highlighter-rouge">RB_UNLIKELY</code>.</p>

<p>Combining all these, led me to rewrite that function as:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">fbuffer_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">requested</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">required</span><span class="p">;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">);</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">required</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">;</span> <span class="n">requested</span> <span class="o">&gt;</span> <span class="n">required</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">;</span> <span class="n">required</span> <span class="o">&lt;&lt;=</span> <span class="mi">1</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">required</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">REALLOC_N</span><span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">required</span><span class="p">);</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">required</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>With this new version, we first check for the most common case, which is when the buffer still has enough capacity, and we instruct the CPU that
it’s the most likely case. Also, the function is now marked as <code class="language-plaintext highlighter-rouge">inline</code>, to suggest to the compiler not to go through the cost of calling a function,
but to directly embed that logic in the caller. As a result, the vast majority of the time, the work necessary to ensure the buffer is large enough
is just a subtraction and a comparison, very much negligible on modern CPUs.</p>

<p>That change led to a 15% improvement.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   121.000 i/100ms
Calculating -------------------------------------
               after      1.225k (± 0.8%) i/s  (816.54 μs/i) -      6.171k in   5.039186s

Comparison:
              before:     1068.6 i/s
               after:     1224.7 i/s - 1.15x  faster
</code></pre></div></div>

<p>And if you think about it, it’s not that specific to C, you can apply the same general idea to Ruby code as well, by checking the cheapest and most
likely conditions first.</p>

<h2 id="reducing-setup-cost">Reducing Setup Cost</h2>

<p>I also wasn’t alone in optimizing <code class="language-plaintext highlighter-rouge">ruby/json</code>, <a href="https://github.com/mame">Yusuke Endoh aka Mame</a>, a fellow Ruby committer also had <a href="https://github.com/ruby/json/pull/562">an old open PR with
numerous optimizations</a>. Many of these reduced the “setup” cost of generating JSON.</p>

<p>What I describe as setup cost, is all the busy work that needs to be done before you can get to do the work you want.
In the case of JSON generation, it includes parsing the arguments, allocating the generator and associated structures, etc.</p>

<p><code class="language-plaintext highlighter-rouge">ruby/json</code> setup cost was quite higher than the alternative, and it’s because of this it always looked bad on micro-benchmarks.
For instance <code class="language-plaintext highlighter-rouge">JSON.generate</code> has 3 options to allow to generate “pretty” JSON:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">({</span><span class="ss">foo: </span><span class="p">[</span><span class="mi">1</span><span class="p">]},</span> <span class="ss">array_nl: </span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="ss">object_nl: </span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="ss">indent: </span><span class="s2">"  "</span><span class="p">,</span> <span class="ss">space: </span><span class="s2">" "</span><span class="p">)</span>
<span class="p">{</span>
  <span class="s2">"foo"</span><span class="p">:</span> <span class="p">[</span>
    <span class="mi">1</span>
  <span class="p">]</span>
<span class="p">}</span></code></pre></figure>

<p>Before Mame’s changes, the provided strings would be used to precompute delimiters into dedicated buffers.
A Ruby equivalent of the code would be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="vi">@array_delim</span> <span class="o">=</span> <span class="s2">",</span><span class="si">#{</span><span class="n">opts</span><span class="p">[</span><span class="ss">:array_nl</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
  <span class="vi">@object_delim</span> <span class="o">=</span> <span class="s2">",</span><span class="si">#{</span><span class="n">opts</span><span class="p">[</span><span class="ss">:object_nl</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
  <span class="vi">@object_delim2</span> <span class="o">=</span> <span class="s2">":</span><span class="si">#{</span><span class="n">opts</span><span class="p">[</span><span class="ss">:space</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span></code></pre></figure>

<p>The idea makes sense, you precompute some string segments so you can append a single longer segment instead of two smaller ones.</p>

<p>But in practice this ended up much slower, both because this precompute doesn’t really save much work, but also because most of the time these options aren’t used.
So <a href="https://github.com/mame/json/compare/e125072130229e54a651f7b11d7d5a782ae7fb65...4c984b20176e3989aec5c0c148dba92a2bb89fd7">by essentially reverting this optimization</a>,
Mame reduced the setup cost significantly. On larger benchmarks, the difference isn’t big, but on micro-benchmarks, it’s quite massive:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small hash (65 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   308.914k i/100ms
Calculating -------------------------------------
               after      3.199M (± 1.1%) i/s  (312.57 ns/i) -     16.064M in   5.021536s

Comparison:
              before:  2112189.3 i/s
               after:  3199311.0 i/s - 1.51x  faster
</code></pre></div></div>

<h2 id="avoid-chasing-pointers">Avoid Chasing Pointers</h2>

<p>Another notable optimization in Mame’s pull request was to eliminate one call to <code class="language-plaintext highlighter-rouge">rb_enc_get</code>.</p>

<p>In many places, JSON needs to check that strings are UTF-8 compatible, and was doing it this way:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">int</span> <span class="nf">enc_utf8_compatible_p</span><span class="p">(</span><span class="n">rb_encoding</span> <span class="o">*</span><span class="n">enc</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">enc</span> <span class="o">==</span> <span class="n">rb_usascii_encoding</span><span class="p">())</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">enc</span> <span class="o">==</span> <span class="n">rb_utf8_encoding</span><span class="p">())</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// ...</span>

<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">enc_utf8_compatible_p</span><span class="p">(</span><span class="n">rb_enc_get</span><span class="p">(</span><span class="n">obj</span><span class="p">)))</span> <span class="p">{</span>
    <span class="c1">// try to convert the string</span>
<span class="p">}</span></code></pre></figure>

<p>At first sight, this might seem quite straightforward. But <code class="language-plaintext highlighter-rouge">rb_enc_get</code> is quite slow. Here’s most of its implementation:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">int</span>
<span class="nf">rb_enc_get_index</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">tmp</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">SPECIAL_CONST_P</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">SYMBOL_P</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">rb_sym2str</span><span class="p">(</span><span class="n">obj</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">switch</span> <span class="p">(</span><span class="n">BUILTIN_TYPE</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
      <span class="k">case</span> <span class="n">T_STRING</span><span class="p">:</span>
      <span class="k">case</span> <span class="n">T_SYMBOL</span><span class="p">:</span>
      <span class="k">case</span> <span class="n">T_REGEXP</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">enc_get_index_str</span><span class="p">(</span><span class="n">obj</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="k">case</span> <span class="n">T_FILE</span><span class="p">:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_funcallv</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">rb_intern</span><span class="p">(</span><span class="s">"internal_encoding"</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_funcallv</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">rb_intern</span><span class="p">(</span><span class="s">"external_encoding"</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">is_obj_encoding</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">enc_check_encoding</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="k">case</span> <span class="n">T_DATA</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">is_data_encoding</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">enc_check_encoding</span><span class="p">(</span><span class="n">obj</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">break</span><span class="p">;</span>
      <span class="nl">default:</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">i</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">rb_encoding</span><span class="o">*</span>
<span class="nf">rb_enc_get</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">rb_enc_from_index</span><span class="p">(</span><span class="n">rb_enc_get_index</span><span class="p">(</span><span class="n">obj</span><span class="p">));</span>
<span class="p">}</span></code></pre></figure>

<p>As you can see, it’s a higher-level API implemented in a fairly defensive way, it performs a lot of type checks
to ensure it won’t cause a crash and to be able to deal with different types of objects.
All these conditionals don’t look like much, but as mentioned before, modern CPUs are very fast at computing things but pay a high price for conditionals unless they’re correctly predicted.</p>

<p>Then the thing to know is that conceptually, Ruby strings have a reference to their encoding, e.g.:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="s2">"Hello World"</span><span class="p">.</span><span class="nf">encoding</span> <span class="c1"># =&gt; Encoding::UTF_8</span></code></pre></figure>

<p>So conceptually, they have a reference to another object, which naively should be a full-on 64-bit pointer. But since there’s only a (not so) small number of possible encodings,
instead of wasting a full 8 bytes to keep that reference, the Ruby VM instead stores a much smaller 7-bit number in a bitmap inside each String, which is called the <code class="language-plaintext highlighter-rouge">encoding_index</code>
or <code class="language-plaintext highlighter-rouge">enc_idx</code> for short.
That’s an offer you can use to then look up the actual encoding in a global array inside the virtual machine.
In low-level code that’s what we tend to call “pointer chasing” as in we have an address of memory, and go fetch its content from RAM.
If that RAM was recently loaded and is already in the CPU cache, it’s relatively fast, but if it isn’t, the CPU has to wait quite a long time for the data to be fetched.</p>

<p>If you are mostly working with higher-level languages, that probably doesn’t sound like much, but with low-level programming, fetching
memory from RAM is a bit like performing a SQL query for a Rails application, it’s way slower than doing a computation on already fetched data,
so similarly, that’s something you try hard not to do in hot spots.</p>

<p>In this case, there are several shortcuts <code class="language-plaintext highlighter-rouge">json</code> could take.</p>

<p>First <code class="language-plaintext highlighter-rouge">json</code> already knows it is dealing with a String, as such it doesn’t need to go through all the checks in <code class="language-plaintext highlighter-rouge">rb_enc_get_index</code> and can directly
use the lower level and much faster <code class="language-plaintext highlighter-rouge">RB_ENCODING_GET</code>.</p>

<p>Then, since all it cares about is whether the String is encoded in either ASCII or UTF-8, it doesn’t need the real <code class="language-plaintext highlighter-rouge">rb_encoding *</code> pointer, and
can directly check the returned index, skipping the need to load data from RAM.</p>

<p>So here’s how Mame rewrote that code:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">int</span> <span class="nf">enc_utf8_compatible_p</span><span class="p">(</span><span class="kt">int</span> <span class="n">enc_idx</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">enc_idx</span> <span class="o">==</span> <span class="n">usascii_encindex</span><span class="p">)</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">enc_idx</span> <span class="o">==</span> <span class="n">utf8_encindex</span><span class="p">)</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// ...</span>

<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">enc_utf8_compatible_p</span><span class="p">(</span><span class="n">RB_ENCODING_GET</span><span class="p">(</span><span class="n">obj</span><span class="p">)))</span> <span class="p">{</span>
    <span class="c1">// try to convert the string</span>
<span class="p">}</span></code></pre></figure>

<p>Notice how it is now comparing encoding indexes instead of encoding pointers.</p>

<p>That very small change improved the <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark by another <code class="language-plaintext highlighter-rouge">8%</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   126.000 i/100ms
Calculating -------------------------------------
               after      1.253k (± 1.5%) i/s  (797.91 μs/i) -      6.300k in   5.028081s

Comparison:
              before:     1159.6 i/s
               after:     1253.3 i/s - 1.08x  faster
</code></pre></div></div>

<h2 id="lookup-tables">Lookup Tables</h2>

<p>Yet another patch in Mame’s PR was to use <a href="https://lemire.me/blog/2024/10/14/table-lookups-are-efficient/">one of my favorite performance tricks, what’s called a “lookup table”</a>.</p>

<p>Dumping a string into JSON can be quite costly because for each character there are multiple checks to do first to know if the character
can simply be copied or if it needs to be escaped. The naive way looks like this (implemented in Ruby for better readability):</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">buffer</span> <span class="o">=</span> <span class="o">+</span><span class="s2">""</span>
<span class="n">string</span><span class="p">.</span><span class="nf">each_char</span> <span class="k">do</span> <span class="o">|</span><span class="n">char</span><span class="o">|</span>
  <span class="k">if</span> <span class="n">char</span><span class="p">.</span><span class="nf">ord</span> <span class="o">&lt;</span> <span class="mh">0x20</span> <span class="c1"># ASCII control character</span>
    <span class="k">case</span> <span class="n">char</span>
    <span class="k">when</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\\</span><span class="s2">n"</span>
    <span class="k">when</span> <span class="s2">"</span><span class="se">\r</span><span class="s2">"</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\\</span><span class="s2">r"</span>
    <span class="k">when</span> <span class="s2">"</span><span class="se">\t</span><span class="s2">"</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\\</span><span class="s2">t"</span>
    <span class="k">when</span> <span class="s2">"</span><span class="se">\f</span><span class="s2">"</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\\</span><span class="s2">f"</span>
    <span class="k">when</span> <span class="s2">"</span><span class="se">\b</span><span class="s2">"</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\\</span><span class="s2">b"</span>
    <span class="k">else</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s2">"</span><span class="se">\u</span><span class="s2">00</span><span class="si">#{</span><span class="n">char</span><span class="p">.</span><span class="nf">ord</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">end</span>
  <span class="k">else</span>
    <span class="k">case</span> <span class="n">char</span>
    <span class="k">when</span> <span class="s1">'"'</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s1">'\\"'</span>
    <span class="k">when</span> <span class="s1">'\\'</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s1">'\\\\'</span>
    <span class="k">else</span>
      <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">char</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>As you can see, it’s a lot of conditional, even in the fast path, we need to check for <code class="language-plaintext highlighter-rouge">c &lt; 0x20</code> and then for <code class="language-plaintext highlighter-rouge">"</code> and <code class="language-plaintext highlighter-rouge">\</code> characters.</p>

<p>The idea of lookup tables is that you precompute a static array with that algorithm so that instead of doing multiple comparisons per character, all you do is read a boolean at a dynamic offset.
In Ruby that would look like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">JSON_ESCAPE_TABLE</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="kp">false</span><span class="p">)</span>
<span class="mh">0x20</span><span class="p">.</span><span class="nf">times</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
  <span class="no">JSON_ESCAPE_TABLE</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kp">true</span>
<span class="k">end</span>
<span class="no">JSON_ESCAPE_TABLE</span><span class="p">[</span><span class="s1">'"'</span><span class="p">]</span> <span class="o">=</span> <span class="kp">true</span>
<span class="no">JSON_ESCAPE_TABLE</span><span class="p">[</span><span class="s1">'\\'</span><span class="p">]</span> <span class="o">=</span> <span class="kp">true</span>

<span class="n">buffer</span> <span class="o">=</span> <span class="o">+</span><span class="s2">""</span>
<span class="n">string</span><span class="p">.</span><span class="nf">each_char</span> <span class="k">do</span> <span class="o">|</span><span class="n">char</span><span class="o">|</span>
  <span class="k">if</span> <span class="no">JSON_ESCAPE_TABLE</span><span class="p">[</span><span class="n">char</span><span class="p">]</span>
    <span class="c1"># do the slow thing</span>
  <span class="k">else</span>
    <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">char</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>This uses a bit more static memory, but that’s negligible and makes the loop much faster.</p>

<p>With this, and based on the assumption that most strings don’t contain any character that needs to be escaped, Mame added a precondition to first cheaply check if we’re on the fast path,
and if we are, directly copy the entire string in the buffer all at once, so something like:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">buffer</span> <span class="o">=</span> <span class="o">+</span><span class="s2">""</span>
<span class="k">if</span> <span class="n">string</span><span class="p">.</span><span class="nf">each_char</span><span class="p">.</span><span class="nf">none?</span> <span class="p">{</span> <span class="o">|</span><span class="n">c</span><span class="o">|</span> <span class="no">JSON_ESCAPE_TABLE</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="p">}</span>
  <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">string</span>
<span class="k">else</span>
  <span class="c1"># do the slow char by char escaping</span>
<span class="k">end</span></code></pre></figure>

<p>You can see <a href="https://github.com/ruby/json/pull/562/commits/a81ec4770af4a2f20a9dc06d0295cf5b93a7af91">Mame’s patch</a>, it’s a bit more cryptic because in C, but you should be able to
see the same pattern as described here, and that alone made a massive 30% gain on the <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   164.000 i/100ms
Calculating -------------------------------------
               after      1.630k (± 2.3%) i/s  (613.43 μs/i) -      8.200k in   5.032935s

Comparison:
              before:     1258.1 i/s
               after:     1630.2 i/s - 1.30x  faster
</code></pre></div></div>

<h2 id="to-be-continued">To Be Continued</h2>

<p>I have way more optimizations than these ones to talk about, but I feel like it’s already a pretty packed blog post.</p>

<p>So I’ll stop here and work on some followup soon, hopefully I won’t lose my motivation to write :).</p>

<p>Edit: Looks like I didn’t, <a href="/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html">part two is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[I was recently made maintainer of the json gem, and aside from fixing some old bugs, I focused quite a bit on its performance, so that it is now the fastest JSON parser and generator for Ruby on most benchmarks.]]></summary></entry></feed>