<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://byroot.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://byroot.github.io/" rel="alternate" type="text/html" /><updated>2025-01-30T07:41:15+00:00</updated><id>https://byroot.github.io/feed.xml</id><title type="html">byroot’s blog</title><subtitle>Various ramblings.</subtitle><entry><title type="html">So You Want To Remove The GVL?</title><link href="https://byroot.github.io/ruby/performance/2025/01/29/so-you-want-to-remove-the-gvl.html" rel="alternate" type="text/html" title="So You Want To Remove The GVL?" /><published>2025-01-29T09:47:51+00:00</published><updated>2025-01-29T09:47:51+00:00</updated><id>https://byroot.github.io/ruby/performance/2025/01/29/so-you-want-to-remove-the-gvl</id><content type="html" xml:base="https://byroot.github.io/ruby/performance/2025/01/29/so-you-want-to-remove-the-gvl.html"><![CDATA[<p>I want to write a post about <a href="https://rubygems.org/gems/pitchfork">Pitchfork</a>, explaining where it comes from, why it
is like it is, and how I see its future.
But before I can get to that, I think I need to share my mental model on a few things, in this case, Ruby’s GVL.</p>

<p>For quite a long time, it has been said that Rails applications are mostly IO-bound, hence Ruby’s GVL isn’t that big of
a deal and that has influenced the design of some cornerstone pieces of Ruby infrastructure like Puma and Sidekiq.
As <a href="/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html">I explained in a previous post, I don’t think it’s quite true for most Rails applications</a>.
Regardless, <a href="/ruby/performance/2025/01/25/why-does-everyone-hate-fork.html">the existence of the GVL still requires these threaded systems to use <code class="language-plaintext highlighter-rouge">fork(2)</code></a> in order to exploit all the cores of a server: one process per core.
To avoid all this, some people have been calling for the GVL to simply be removed.</p>

<p>But is it that simple?</p>

<h2 id="gvl-and-thread-safety">GVL and Thread Safety</h2>

<p>If you read posts about the GVL, you may have heard that it’s not there to protect your code from race conditions, but
to protect the Ruby VM from your code.
Put another way, GVL or not, your code can be subject to race conditions, and this is absolutely true.</p>

<p><strong>But that doesn’t mean the GVL isn’t an important component of the thread safety of the Ruby code in your applications</strong>.
Let’s use a simple code sample to illustrate:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">QUOTED_COLUMN_NAMES</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">def</span> <span class="nf">quote_column_name</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="no">QUOTED_COLUMN_NAMES</span><span class="p">[</span><span class="nb">name</span><span class="p">]</span> <span class="o">||=</span> <span class="n">quote</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Would you say this code is thread-safe? Or not?</p>

<p>Well, if you answered “It’s thread-safe”, you’re not quite correct.
But if you answered “It’s not thread safe”, you’re not quite correct either.</p>

<p>The actual answer is: “It depends”.</p>

<p>First, it depends on how strict of a definition of thread-safe you are thinking of,
then it depends on whether that <code class="language-plaintext highlighter-rouge">quote</code> method is idempotent and finally, it depends on which implementation of Ruby you are using.</p>

<p>Let me explain.</p>

<p>First <code class="language-plaintext highlighter-rouge">||=</code> is syntax sugar that is hiding a bit how this code actually works, so let’s desugar it:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">QUOTED_COLUMN_NAMES</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">def</span> <span class="nf">quote_column_name</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="n">quoted</span> <span class="o">=</span> <span class="no">QUOTED_COLUMN_NAMES</span><span class="p">[</span><span class="nb">name</span><span class="p">]</span>

  <span class="c1"># Ruby could switch threads here</span>

  <span class="k">if</span> <span class="n">quoted</span>
    <span class="n">quoted</span>
  <span class="k">else</span>
    <span class="no">QUOTED_COLUMN_NAMES</span><span class="p">[</span><span class="nb">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">quote</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>In this form it’s easier to see that <code class="language-plaintext highlighter-rouge">||=</code> isn’t a single operation but multiple, so even on MRI<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, with a GVL, it’s
technically possible that Ruby would preempt a thread after evaluating <code class="language-plaintext highlighter-rouge">quoted = ...</code>, and resume another thread that will
enter the same method with the same argument.</p>

<p>In other words, this code is subject to race conditions, even with a GVL.
To be even more precise, it’s subject to a <em>check-then-act</em> race condition.</p>

<p>If it’s subject to race conditions, you can logically deduce that it’s not thread-safe.
But here again, it depends.
If <code class="language-plaintext highlighter-rouge">quote(name)</code> is idempotent, then yes there’s technically a race-condition, but it has no real negative impact.
The <code class="language-plaintext highlighter-rouge">name</code> will be quoted twice instead of once, and one of the resulting strings will be discarded, who cares?
That is why in my opinion the above code is effectively thread-safe regardless.</p>

<p>And we can verify this experimentally by using a few threads:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">QUOTED_COLUMN_NAMES</span> <span class="o">=</span> <span class="mi">20</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">to_h</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="p">}</span>

<span class="k">def</span> <span class="nf">quote_column_name</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="no">QUOTED_COLUMN_NAMES</span><span class="p">[</span><span class="nb">name</span><span class="p">]</span> <span class="o">||=</span> <span class="s2">"`</span><span class="si">#{</span><span class="nb">name</span><span class="p">.</span><span class="nf">to_s</span><span class="p">.</span><span class="nf">gsub</span><span class="p">(</span><span class="s1">'`'</span><span class="p">,</span> <span class="s1">'``'</span><span class="p">)</span><span class="si">}</span><span class="s2">`"</span><span class="p">.</span><span class="nf">freeze</span>
<span class="k">end</span>

<span class="n">threads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">map</span> <span class="k">do</span>
  <span class="no">Thread</span><span class="p">.</span><span class="nf">new</span> <span class="k">do</span>
    <span class="mi">10_000</span><span class="p">.</span><span class="nf">times</span> <span class="k">do</span>
      <span class="k">if</span> <span class="n">quote_column_name</span><span class="p">(</span><span class="s2">"foo"</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">"`foo`"</span>
        <span class="k">raise</span> <span class="s2">"There was a bug"</span>
      <span class="k">end</span>
      <span class="no">QUOTED_COLUMN_NAMES</span><span class="p">.</span><span class="nf">delete</span><span class="p">(</span><span class="s2">"foo"</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="n">threads</span><span class="p">.</span><span class="nf">each</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:join</span><span class="p">)</span>
</code></pre></div></div>

<p>If you run this script with MRI, it will work fine, it won’t crash, and <code class="language-plaintext highlighter-rouge">quote_column_name</code> will always return what
you expect.</p>

<p>However, if you try to run it with either TruffleRuby or JRuby, which are alternative
implementations of Ruby that don’t have a GVL, you’ll get <a href="https://gist.github.com/byroot/1470a8fc71c2712a1f3ae875a9a40710">about 300 lines of errors</a>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ruby <span class="nt">-v</span> /tmp/quoted.rb 
truffleruby 24.1.2, like ruby 3.2.4, Oracle GraalVM Native <span class="o">[</span>arm64-darwin20]
java.lang.RuntimeException: Ruby Thread <span class="nb">id</span><span class="o">=</span>51 from /tmp/quoted.rb:20 terminated with internal error:
    at org.truffleruby.core.thread.ThreadManager.printInternalError<span class="o">(</span>ThreadManager.java:316<span class="o">)</span>
    ... 20 more
Caused by: java.lang.NullPointerException
    at org.truffleruby.core.hash.library.PackedHashStoreLibrary.getHashed<span class="o">(</span>PackedHashStoreLibrary.java:78<span class="o">)</span>
    ... 120 more
java.lang.RuntimeException: Ruby Thread <span class="nb">id</span><span class="o">=</span>52 from /tmp/quoted.rb:20 terminated with internal error:
    at org.truffleruby.core.thread.ThreadManager.printInternalError<span class="o">(</span>ThreadManager.java:316<span class="o">)</span>
    ... 20 more
... etc
</code></pre></div></div>

<p>The error isn’t always exactly the same, and sometimes it seems worse than others.
But in general, it crashes deep inside the TruffleRuby or JRuby interpreters because the concurrent access to the same
hash causes them to hit a <code class="language-plaintext highlighter-rouge">NullPointerException</code>.</p>

<p>So we can say this code is thread-safe on the reference implementation of Ruby, but not on all implementations of Ruby.</p>

<p>The reason it is that way is that on MRI, the thread scheduler can only switch the running thread when executing pure
Ruby code.
Whenever you call into a builtin method that is implemented in C, you are implicitly protected by the GVL.
Hence all methods implemented in C are essentially “atomic” unless they explicitly release the GVL.
But generally speaking, only IO methods will release it.</p>

<p>That’s why the real version of this code, that <a href="https://github.com/rails/rails/blob/0643592211dec558f93e57451a34393941144c8e/activerecord/lib/active_record/connection_adapters/sqlite3/quoting.rb#L9">I took from Active Record</a>,
doesn’t use a <code class="language-plaintext highlighter-rouge">Hash</code>, but a <code class="language-plaintext highlighter-rouge">Concurrent::Map</code>.
On MRI that class is pretty much just an alias for <code class="language-plaintext highlighter-rouge">Hash</code>, but on JRuby and TruffleRuby it’s defined as a hash table
with a mutex.
Officially Rails doesn’t support TruffleRuby or JRuby, but in practice, we tend to accommodate them with this sort of
small changes.</p>

<h2 id="just-remove-it-already">Just Remove It Already</h2>

<p>That’s why there’s “removing the GVL” and “removing the GVL”.</p>

<p>The <em>simple</em> way would be to do what TruffleRuby and JRuby do: nothing. Or close to nothing.</p>

<p>Since these alternative implementations are based on the Java Virtual Machine, which is memory-safe, they delegate to
the JVM runtime the hard job of failing but not hard crashing in such cases.
Given MRI is implemented in C, which is famously not memory-safe, just removing the GVL would cause the virtual machine
to run into a segmentation fault (or worse) when your code triggers this sort of race condition, so it wouldn’t be as simple.</p>

<p>Ruby would need to do something similar to what the JVM does, having some sort of atomic counter on every object that
could be subject to race conditions. Whenever you access an object you increment it and check it is set to <code class="language-plaintext highlighter-rouge">1</code> to ensure
nobody else is currently using it.</p>

<p>This in itself is quite a challenging task, as it means going over all the methods implemented in C (in Ruby itself but
also popular C extensions), to insert all these atomic increments and decrements.</p>

<p>It would also require some extra space in most Ruby objects for that new counter, likely 4 or 8 bytes, because atomic
operations aren’t easily done on smaller integer types. Unless of course there’s some smart trick I’m not privy of.</p>

<p>It would also result in a slow-down of the virtual machine, as all these atomic increments and decrements likely would
have a noticeable overhead, because atomic operations mean that the CPU has to ensure all cores see the operation at
the same time, so it essentially locks that part of the CPU cache.
I won’t try to guess how much that overhead would be in practice, but it certainly isn’t free.</p>

<p>And then the result would be that a lot of existing pure Ruby code, that used to be effectively thread safe, would no longer be.
So beyond the work ruby-core would have to do, Ruby users would also likely need to debug a bunch of thread safety issues
in their code, gems, etc.</p>

<p>That’s why despite the impressive efforts of JRuby and TruffleRuby teams to be as compatible as possible with MRI,
the absence of a GVL, which is a feature, makes it so that most non-trivial codebases likely need at least some debugging
before they can run properly on either of them. It’s not necessarily a ton of effort, it depends, but it’s more work
than your average yearly Ruby upgrade.</p>

<h2 id="replace-it-by-something">Replace It By Something</h2>

<p>But that’s not the only way to remove the GVL, another way that is often envisioned is to replace the one global lock,
by a myriad of small locks, one per every mutable object.</p>

<p>In terms of work needed, it’s fairly similar to the previous approach, you’d need to go over all the C code and insert
explicitly lock and unlock statements whenever you touch a mutable object.
It would also require some space on every object, likely a bit more than just a counter though.</p>

<p>With such approach, C extensions would still likely need some work, but pure Ruby code would remain fully compatible.</p>

<p>If you’ve heard about the semi-recent effort to remove Python’s GIL (that’s what they call their GVL), that’s the approach
they’re using. So let’s look at the sort of changes they made, starting with <a href="https://github.com/python/cpython/blob/180ee43bde99b8ce4c4f1d5237ab191e26118061/Include/object.h#L109-L162">their base object layout that is defined
in <code class="language-plaintext highlighter-rouge">object.h</code></a></p>

<p>It has lots of ceremonial code, so here’s a stripped-down and simplified version:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/* Nothing is actually declared to be a PyObject, but every pointer to
 * a Python object can be cast to a PyObject*.  This is inheritance built by hand.
 */</span>
<span class="cp">#ifndef Py_GIL_DISABLED
</span><span class="k">struct</span> <span class="n">_object</span> <span class="p">{</span>
    <span class="n">Py_ssize_t</span> <span class="n">ob_refcnt</span>
    <span class="n">PyTypeObject</span> <span class="o">*</span><span class="n">ob_type</span><span class="p">;</span>
<span class="p">};</span>
<span class="cp">#else
</span><span class="c1">// Objects that are not owned by any thread use a thread id (tid) of zero.</span>
<span class="c1">// This includes both immortal objects and objects whose reference count</span>
<span class="c1">// fields have been merged.</span>
<span class="cp">#define _Py_UNOWNED_TID             0
</span>
<span class="k">struct</span> <span class="n">_object</span> <span class="p">{</span>
    <span class="c1">// ob_tid stores the thread id (or zero). It is also used by the GC and the</span>
    <span class="c1">// trashcan mechanism as a linked list pointer and by the GC to store the</span>
    <span class="c1">// computed "gc_refs" refcount.</span>
    <span class="kt">uintptr_t</span> <span class="n">ob_tid</span><span class="p">;</span>
    <span class="kt">uint16_t</span> <span class="n">ob_flags</span><span class="p">;</span>
    <span class="n">PyMutex</span> <span class="n">ob_mutex</span><span class="p">;</span>           <span class="c1">// per-object lock</span>
    <span class="kt">uint8_t</span> <span class="n">ob_gc_bits</span><span class="p">;</span>         <span class="c1">// gc-related state</span>
    <span class="kt">uint32_t</span> <span class="n">ob_ref_local</span><span class="p">;</span>      <span class="c1">// local reference count</span>
    <span class="n">Py_ssize_t</span> <span class="n">ob_ref_shared</span><span class="p">;</span>   <span class="c1">// shared (atomic) reference count</span>
    <span class="n">PyTypeObject</span> <span class="o">*</span><span class="n">ob_type</span><span class="p">;</span>
<span class="p">};</span>
<span class="cp">#endif
</span></code></pre></div></div>

<p>There’s quite a lot in there, so let me describe it all. My entire explanation will assume a 64-bit architecture, to make things simpler.</p>

<p>Also note that while I used to be a Pythonista, that was 15 years ago, and nowadays I’m just spectating Python’s
development from afar. All this to say, I’ll do my best to correctly describe what they are doing, but it’s entirely
possible I get some of it wrong.</p>

<p>Anyway, when the GIL isn’t disabled as part of compilation, every single Python object starts with a header of <code class="language-plaintext highlighter-rouge">16B</code>,
the first <code class="language-plaintext highlighter-rouge">8B</code> called <code class="language-plaintext highlighter-rouge">ob_refcnt</code> is used for reference counting as the name implies, but actually only <code class="language-plaintext highlighter-rouge">4B</code> is used as a
counter, the other <code class="language-plaintext highlighter-rouge">4B</code> is used as a bitmap to set flags on the object, just like in Ruby.
Then the remaining <code class="language-plaintext highlighter-rouge">8B</code> is simply a pointer to the object’s class.</p>

<p>For comparison, Ruby’s object header, called <code class="language-plaintext highlighter-rouge">struct RBasic</code> is also <code class="language-plaintext highlighter-rouge">16B</code>. Similarly, it has one pointer to the class,
and the other <code class="language-plaintext highlighter-rouge">8B</code> is used as a big bitmap that stores many different things.</p>

<p>However, when the GIL is disabled during compilation, the object header is now <code class="language-plaintext highlighter-rouge">32B</code>, double the size.
It starts with an <code class="language-plaintext highlighter-rouge">8B</code> <code class="language-plaintext highlighter-rouge">ob_tid</code>, for thread ID, which stores which thread owns that particular object.
Then <code class="language-plaintext highlighter-rouge">ob_flags</code> is explicitly laid out, but has been reduced to <code class="language-plaintext highlighter-rouge">2B</code> instead of <code class="language-plaintext highlighter-rouge">4B</code>, to make space for a <code class="language-plaintext highlighter-rouge">1B</code> <code class="language-plaintext highlighter-rouge">ob_mutex</code>,
and another <code class="language-plaintext highlighter-rouge">1B</code> for some GC state I don’t know much about.</p>

<p>The <code class="language-plaintext highlighter-rouge">4B</code> <code class="language-plaintext highlighter-rouge">ob_refcnt</code> field is still there, but this time named <code class="language-plaintext highlighter-rouge">ob_ref_local</code>, and there is another <code class="language-plaintext highlighter-rouge">8B</code> <code class="language-plaintext highlighter-rouge">ob_ref_shared</code>,
and finally, the pointer to the object class.</p>

<p>Just with the change in the object layout, you can already have a sense of the extra complexity, as well as the memory
overhead. Sixteen extra bytes per object isn’t negligible.</p>

<p>Now, as you may have guessed from the <code class="language-plaintext highlighter-rouge">refcnt</code> field, Python’s memory is mainly managed via reference counting.
They also have a mark and sweep collector, but it’s only there to deal with circular references.
In that way, it’s quite different from Ruby, but looking at what they had to do to make this thread safe is interesting
regardless.</p>

<p>Let’s look at <a href="https://github.com/python/cpython/blob/180ee43bde99b8ce4c4f1d5237ab191e26118061/Include/refcount.h#L245-L294"><code class="language-plaintext highlighter-rouge">Py_INCREF</code>, defined in <code class="language-plaintext highlighter-rouge">refcount.h</code></a>.
Here again, it’s full of <code class="language-plaintext highlighter-rouge">ifdef</code> for various architecture and such, so here’s a stripped-down version, with only the code
executed when the GIL is active, and some debug code removed:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define _Py_IMMORTAL_MINIMUM_REFCNT ((Py_ssize_t)(1L &lt;&lt; 30))
</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">Py_ALWAYS_INLINE</span> <span class="kt">int</span> <span class="nf">_Py_IsImmortal</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">op</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_refcnt</span> <span class="o">&gt;=</span> <span class="n">_Py_IMMORTAL_MINIMUM_REFCNT</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">Py_ALWAYS_INLINE</span> <span class="kt">void</span> <span class="nf">Py_INCREF</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">op</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">_Py_IsImmortal</span><span class="p">(</span><span class="n">op</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_refcnt</span><span class="o">++</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>It’s extremely simple, even if you are unfamiliar with C you should be able to read it. But basically, it checks
if the refcount is set to a magical value that marks immortal objects, and if it isn’t immortal, it simply does a regular,
non-atomic, hence very cheap, increment of the counter.</p>

<p>A sidenote on immortal objects, it’s <a href="https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf">a very cool concept introduced by Instagram engineers</a>
which I’ve been meaning to introduce in Ruby too. It’s well worth a read if you are interested in things like Copy-on-Write
and memory savings.</p>

<p>Now let’s look at that same <code class="language-plaintext highlighter-rouge">Py_INCREF</code> function, with the GIL removed:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#define _Py_IMMORTAL_REFCNT_LOCAL UINT32_MAX
# define _Py_REF_SHARED_SHIFT        2
</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">Py_ALWAYS_INLINE</span> <span class="kt">int</span> <span class="nf">_Py_IsImmortal</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">op</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_Py_atomic_load_uint32_relaxed</span><span class="p">(</span><span class="o">&amp;</span><span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_ref_local</span><span class="p">)</span> <span class="o">==</span>
            <span class="n">_Py_IMMORTAL_REFCNT_LOCAL</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">Py_ALWAYS_INLINE</span> <span class="kt">int</span>
<span class="nf">_Py_IsOwnedByCurrentThread</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">ob</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">ob</span><span class="o">-&gt;</span><span class="n">ob_tid</span> <span class="o">==</span> <span class="n">_Py_ThreadId</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">Py_ALWAYS_INLINE</span> <span class="kt">void</span> <span class="nf">Py_INCREF</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">op</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">uint32_t</span> <span class="n">local</span> <span class="o">=</span> <span class="n">_Py_atomic_load_uint32_relaxed</span><span class="p">(</span><span class="o">&amp;</span><span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_ref_local</span><span class="p">);</span>
    <span class="kt">uint32_t</span> <span class="n">new_local</span> <span class="o">=</span> <span class="n">local</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">new_local</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// local is equal to _Py_IMMORTAL_REFCNT_LOCAL: do nothing</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">_Py_IsOwnedByCurrentThread</span><span class="p">(</span><span class="n">op</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">_Py_atomic_store_uint32_relaxed</span><span class="p">(</span><span class="o">&amp;</span><span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_ref_local</span><span class="p">,</span> <span class="n">new_local</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="n">_Py_atomic_add_ssize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">op</span><span class="o">-&gt;</span><span class="n">ob_ref_shared</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">_Py_REF_SHARED_SHIFT</span><span class="p">));</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This is now way more involved.
First the <code class="language-plaintext highlighter-rouge">ob_ref_local</code> needs to be loaded atomically, which as mentioned previously is more costly than loading it
normally as it requires CPU cache synchronization.
Then we still have the check for immortal objects, nothing new.</p>

<p>The interesting part is the final <code class="language-plaintext highlighter-rouge">if</code>, as there are two different cases, the case where the object is owned by the
current thread and the case where it isn’t. Hence the first step is to compare the <code class="language-plaintext highlighter-rouge">ob_tid</code> with <code class="language-plaintext highlighter-rouge">_Py_ThreadId()</code>.
That function is way too big to include here, but you can check <a href="https://github.com/python/cpython/blob/180ee43bde99b8ce4c4f1d5237ab191e26118061/Include/object.h#L183-L246">its implementation in <code class="language-plaintext highlighter-rouge">object.h</code></a>,
on most platform it’s essentially free because the thread ID is always stored in a CPU register.</p>

<p>When the object is owned by the current thread, Python can get away with a non-atomic increment followed
by an atomic store.
Whereas in the opposite case, the entire increment has to be atomic, which is way more expensive as
it involves <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap</a> operations.
Meaning that in case of a race condition, the CPU will retry the incrementation until it happens without a race condition.</p>

<p>In pseudo-Ruby it could look like this:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">atomic_compare_and_swap</span><span class="p">(</span><span class="n">was</span><span class="p">,</span> <span class="n">now</span><span class="p">)</span>
  <span class="c1"># assume this method is a single atomic CPU operation</span>
  <span class="k">if</span> <span class="vi">@memory</span> <span class="o">==</span> <span class="n">was</span>
    <span class="vi">@memory</span> <span class="o">=</span> <span class="n">now</span>
    <span class="k">return</span> <span class="kp">true</span>
  <span class="k">else</span>
    <span class="k">return</span> <span class="kp">false</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">def</span> <span class="nf">atomic_increment</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>
  <span class="kp">loop</span> <span class="k">do</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">atomic_load</span><span class="p">(</span><span class="vi">@memory</span><span class="p">)</span>
    <span class="k">break</span> <span class="k">if</span> <span class="n">atomic_compare_and_swap</span><span class="p">(</span><span class="n">value</span> <span class="o">+</span> <span class="n">add</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>So you can see how what used to be a very mundane operation, that is a major Python hotspot,
became something noticeably more complex.
Ruby doesn’t use reference counting, so this particular case wouldn’t immediately translate to Ruby if there was an
attempt to remove the GVL, but Ruby still has a bunch of similar routines that are very frequently called and would
be similarly impacted.</p>

<p>For instance, because Ruby’s GC is generational and incremental, whenever a new reference is created between two objects,
say <code class="language-plaintext highlighter-rouge">A</code> towards <code class="language-plaintext highlighter-rouge">B</code>, Ruby might need to mark <code class="language-plaintext highlighter-rouge">A</code> as needing to be rescanned, and it is done by flipping one bit in a bitmap.
That’s one example of something that would need to be changed to use atomic operations.</p>

<p>But we still haven’t got to talk about the actual locking.
When I first heard about Python’s renewed attempt to remove their GIL, I expected they’d leverage the existing reference counting API to shove the locking in it, but clearly, they didn’t.
I’m not certain why, but I suppose the semantics don’t fully match.</p>

<p>Instead, they had to do what I mentioned earlier, go over all the methods implemented in C to add explicit lock and unlock
calls. To illustrate, we can look at the <code class="language-plaintext highlighter-rouge">list.clear()</code> method, which is the Python equivalent to <code class="language-plaintext highlighter-rouge">Array#clear</code>.</p>

<p>Prior to the GIL removal effort, it looked like this:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span>
<span class="nf">PyList_Clear</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">self</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PyList_Check</span><span class="p">(</span><span class="n">self</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">PyErr_BadInternalCall</span><span class="p">();</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">list_clear</span><span class="p">((</span><span class="n">PyListObject</span><span class="o">*</span><span class="p">)</span><span class="n">self</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>It looks simpler than it actually is because most of the complexity is in the <code class="language-plaintext highlighter-rouge">list_clear</code> routine, but regardless,
it’s fairly straightforward.</p>

<p>Quite a while after the project started, <a href="https://github.com/python/cpython/issues/127536">Python developers noticed they forgot to add some locks to <code class="language-plaintext highlighter-rouge">list.clear</code> and
a few other methods</a>, so they changed it for:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span>
<span class="nf">PyList_Clear</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">self</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PyList_Check</span><span class="p">(</span><span class="n">self</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">PyErr_BadInternalCall</span><span class="p">();</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Py_BEGIN_CRITICAL_SECTION</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">list_clear</span><span class="p">((</span><span class="n">PyListObject</span><span class="o">*</span><span class="p">)</span><span class="n">self</span><span class="p">);</span>
    <span class="n">Py_END_CRITICAL_SECTION</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Not that much worse, they managed to encapsulate it all in two macros that are just noops when Python is built with the GIL enabled.</p>

<p>I’m not going to explain everything happening in <code class="language-plaintext highlighter-rouge">Py_BEGIN_CRITICAL_SECTION</code>, some of it flies over my head anyway, but long story short it ends up in <code class="language-plaintext highlighter-rouge">_PyCriticalSection_BeginMutex</code>, which has a fast path and a slow path:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span>
<span class="nf">_PyCriticalSection_BeginMutex</span><span class="p">(</span><span class="n">PyCriticalSection</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="n">PyMutex</span> <span class="o">*</span><span class="n">m</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">PyMutex_LockFast</span><span class="p">(</span><span class="n">m</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">PyThreadState</span> <span class="o">*</span><span class="n">tstate</span> <span class="o">=</span> <span class="n">_PyThreadState_GET</span><span class="p">();</span>
        <span class="n">c</span><span class="o">-&gt;</span><span class="n">_cs_mutex</span> <span class="o">=</span> <span class="n">m</span><span class="p">;</span>
        <span class="n">c</span><span class="o">-&gt;</span><span class="n">_cs_prev</span> <span class="o">=</span> <span class="n">tstate</span><span class="o">-&gt;</span><span class="n">critical_section</span><span class="p">;</span>
        <span class="n">tstate</span><span class="o">-&gt;</span><span class="n">critical_section</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uintptr_t</span><span class="p">)</span><span class="n">c</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="n">_PyCriticalSection_BeginSlow</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">m</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>What the fast path does, is that it assumes the object’s <code class="language-plaintext highlighter-rouge">ob_mutex</code> field is set to <code class="language-plaintext highlighter-rouge">0</code>, and tries
to set it to <code class="language-plaintext highlighter-rouge">1</code> with an atomic compare and swap:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">//_Py_UNLOCKED is defined as 0 and _Py_LOCKED as 1 in Include/cpython/lock.h</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="kt">int</span>
<span class="nf">PyMutex_LockFast</span><span class="p">(</span><span class="n">PyMutex</span> <span class="o">*</span><span class="n">m</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">uint8_t</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">_Py_UNLOCKED</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">lock_bits</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">m</span><span class="o">-&gt;</span><span class="n">_bits</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">_Py_atomic_compare_exchange_uint8</span><span class="p">(</span><span class="n">lock_bits</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">expected</span><span class="p">,</span> <span class="n">_Py_LOCKED</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>If that works, it knows the object was unlocked so it can just to a little bit of book keeping.</p>

<p>If that doesn’t work, however, it enters the slow path, and there it starts to become quite complicated but to describe it quickly, it first uses a spin-lock with 40 iterations. So in a way, it does the same compare and swap logic 40 times in a raw with the hope that it might work eventually.
And if that still doesn’t work, it then “parks” the thread and will wait for a signal to resume.
If you are interested in knowing more you can look at <a href="https://github.com/python/cpython/blob/7dd0a7e52ee832559b89d5ccba732c8e91260df8/Python/lock.c#L50-L135"><code class="language-plaintext highlighter-rouge">_PyMutex_LockTimed</code> in <code class="language-plaintext highlighter-rouge">Python/lock.c</code></a>
and follow the code from there. Ultimately the mutex code isn’t that interesting for our current topic,
because the assumption is that most objects are only ever accessed by a single thread, so the fast path is what matters
the most.</p>

<p>But beyond the cost of that fast path, what is also important is how to integrate the lock and unlock statements
in an existing codebase. If you forget one <code class="language-plaintext highlighter-rouge">lock()</code>, you might cause a VM crash, and if you forget one <code class="language-plaintext highlighter-rouge">unlock()</code>, you
might cause a VM dead-lock, which is arguably even worse.</p>

<p>So let’s go back to that <code class="language-plaintext highlighter-rouge">list.clear()</code> example:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span>
<span class="nf">PyList_Clear</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">self</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PyList_Check</span><span class="p">(</span><span class="n">self</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">PyErr_BadInternalCall</span><span class="p">();</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Py_BEGIN_CRITICAL_SECTION</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">list_clear</span><span class="p">((</span><span class="n">PyListObject</span><span class="o">*</span><span class="p">)</span><span class="n">self</span><span class="p">);</span>
    <span class="n">Py_END_CRITICAL_SECTION</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>You may have noticed how Python does error checking. When a bad precondition is found, it generates an exception
with a <code class="language-plaintext highlighter-rouge">PyErr_*</code> function and returns <code class="language-plaintext highlighter-rouge">-1</code>. That’s because <code class="language-plaintext highlighter-rouge">list.clear()</code> always returns <code class="language-plaintext highlighter-rouge">None</code> (Python’s <code class="language-plaintext highlighter-rouge">nil</code>),
so the return type of its C implementation is just an <code class="language-plaintext highlighter-rouge">int</code>.
For a method that returns a Ruby object, on an error condition it would return a <code class="language-plaintext highlighter-rouge">NULL</code> pointer.</p>

<p>For instance <code class="language-plaintext highlighter-rouge">list.__getitem__</code>, which is Python’s equivalent to <code class="language-plaintext highlighter-rouge">Array#fetch</code> is defined as:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PyObject</span> <span class="o">*</span>
<span class="nf">PyList_GetItem</span><span class="p">(</span><span class="n">PyObject</span> <span class="o">*</span><span class="n">op</span><span class="p">,</span> <span class="n">Py_ssize_t</span> <span class="n">i</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">PyList_Check</span><span class="p">(</span><span class="n">op</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">PyErr_BadInternalCall</span><span class="p">();</span>
        <span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">valid_index</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">Py_SIZE</span><span class="p">(</span><span class="n">op</span><span class="p">)))</span> <span class="p">{</span>
        <span class="n">_Py_DECLARE_STR</span><span class="p">(</span><span class="n">list_err</span><span class="p">,</span> <span class="s">"list index out of range"</span><span class="p">);</span>
        <span class="n">PyErr_SetObject</span><span class="p">(</span><span class="n">PyExc_IndexError</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">_Py_STR</span><span class="p">(</span><span class="n">list_err</span><span class="p">));</span>
        <span class="k">return</span> <span class="nb">NULL</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">PyListObject</span> <span class="o">*</span><span class="p">)</span><span class="n">op</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ob_item</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div></div>

<p>You can see that error if you try accessing a Python list with an out-of-bound index:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="p">[]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span>
<span class="nc">Traceback </span><span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="sh">"</span><span class="s">&lt;stdin&gt;</span><span class="sh">"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">1</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="nb">IndexError</span><span class="p">:</span> <span class="nb">list</span> <span class="n">index</span> <span class="n">out</span> <span class="n">of</span> <span class="nb">range</span>
</code></pre></div></div>

<p>You can recognize the same <code class="language-plaintext highlighter-rouge">IndexError</code> and the same <code class="language-plaintext highlighter-rouge">list index out of range</code> message.</p>

<p>So in both cases, when the Python methods implemented in C need to raise an exception, they build the exception object, store it in some thread local state, and then return a specific value to let the interpreter know that an exception happened.
When the interpreter notices the return value of the function is one of these special values, it starts unwinding the stack.
In a way, Python exceptions are syntactic sugar for the classic <code class="language-plaintext highlighter-rouge">if (error) { return error }</code> pattern.</p>

<p>Now let’s look at Ruby’s <code class="language-plaintext highlighter-rouge">Array#fetch</code>, and see if you notice any difference in how the out-of-bound case is handled:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="n">VALUE</span>
<span class="nf">rb_ary_fetch</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">argv</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">ary</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snip...</span>
    <span class="kt">long</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">NUM2LONG</span><span class="p">(</span><span class="n">pos</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="o">||</span> <span class="n">RARRAY_LEN</span><span class="p">(</span><span class="n">ary</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">idx</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">block_given</span><span class="p">)</span> <span class="k">return</span> <span class="n">rb_yield</span><span class="p">(</span><span class="n">pos</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">rb_raise</span><span class="p">(</span><span class="n">rb_eIndexError</span><span class="p">,</span> <span class="s">"index %ld outside of..."</span><span class="p">,</span> <span class="cm">/* snip... */</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">ifnone</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">RARRAY_AREF</span><span class="p">(</span><span class="n">ary</span><span class="p">,</span> <span class="n">idx</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Did you notice how there is no explicit <code class="language-plaintext highlighter-rouge">return</code> after <code class="language-plaintext highlighter-rouge">rb_raise</code>?</p>

<p>That’s because Ruby exceptions are very different from Python exceptions, as they rely on <a href="https://man7.org/linux/man-pages/man3/setjmp.3.html"><code class="language-plaintext highlighter-rouge">setjmp(3)</code></a>
and <a href="https://man7.org/linux/man-pages/man3/longjmp.3p.html"><code class="language-plaintext highlighter-rouge">longjmp(3)</code></a>.</p>

<p>Without going into too much detail, these two functions essentially allow you to make some sort of “savepoint” of the stack
and jump back to it. When they are used, it’s a bit like a non-local <code class="language-plaintext highlighter-rouge">goto</code>, you directly jump back to a parent function
and all the intermediate functions never return.</p>

<p>As a consequence, a Ruby equivalent of <code class="language-plaintext highlighter-rouge">Py_BEGIN_CRITICAL_SECTION</code> would need to call <code class="language-plaintext highlighter-rouge">setjmp</code>, and push the associated
checkpoint on the execution context (essentially the current fiber) using <a href="https://github.com/ruby/ruby/blob/4a06ef98bfd480a3d724b16c2d7da071e373a69c/eval_intern.h#L98-L110">the <code class="language-plaintext highlighter-rouge">EC_PUSH_TAG</code> macro</a>,
so essentially every core method would now need a <code class="language-plaintext highlighter-rouge">rescue</code> clause, and that’s not free.
It’s doable, but likely more costly than <code class="language-plaintext highlighter-rouge">Py_BEGIN_CRITICAL_SECTION</code>.</p>

<h2 id="shall-we">Shall We?</h2>

<p>But we were so preoccupied with whether or not we could remove the GVL, we didn’t stop to think if we should.</p>

<p>In the case of Python, from my understanding, the driving force behind the effort to remove the GIL is mostly the machine learning community, in big part, because feeding graphic cards efficiently requires a fairly high level of
parallelism, and <code class="language-plaintext highlighter-rouge">fork(2)</code> isn’t very suitable for it.</p>

<p>But, again from my understanding, the Python Web community, such as Django users, seem to be content with <code class="language-plaintext highlighter-rouge">fork(2)</code>,
even though Python is at a major disadvantage over Ruby in terms of Copy-on-Write effectiveness, because as we saw previously, its reference counting implementation means most objects are constantly written to, so CoW pages are very quickly invalidated.</p>

<p>On the other hand, Ruby’s mark-and-sweep GC is much more Copy-On-Write friendly, as almost all the GC tracking data
isn’t stored in the objects themselves but inside external bitmaps.
Hence, one of the main arguments for GVL free threading, which is to reduce memory usage, is much less important in the
case of Ruby.</p>

<p>Given that Ruby (for better or for worse) is predominantly used for the Web use case, it can at least partially explain why the pressure to remove the GVL isn’t as strong as it has been with Python.
Similarly, Node.js and PHP don’t have free threading either, but as far as I know their respective communities
aren’t complaining much about it, unless I missed it.</p>

<p>Also if Ruby were to adopt some form of free threading, it would probably need to add some form of lock in all objects,
and would frequently mutate it, likely severely reducing Copy-on-Write efficiency.
So it wouldn’t be purely an additive feature.</p>

<p>Similarly, one of the main blocker for removing Python’s GIL has always been the negative impact on single-thread performance.
When you are dealing with easily parallelizable algorithms, even if single-thread performance is degraded, you can
probably come out on top by using more parallelism.
But if the sort of thing you use Python for isn’t easily parallelizable, free-threading may not be particularly appealing to you.</p>

<p>Historically, Guido van Rossum’s stance on removing the GIL was that he’d welcome it as long as it had no impact on
single-thread performance, hence why it never happened.
Now that Guido is no longer Python’s benevolent dictator, it seems that the Python steering council is willing to accept
some regression on single-thread performance, but it isn’t yet clear how much it will actually be.
There are some numbers flying around, but mostly from synthetic benchmarks and such.
Personally, I’d be interested to see the impact on Web applications before I’d be enthusiastic about such change happening to Ruby.
It is also important to note that <a href="https://peps.python.org/pep-0703/">the removal has been accepted but with some proviso</a>,
so it isn’t yet done and it’s not impossible that they might decide to backtrack at one point.</p>

<p>Another thing to consider is that the performance impact on Ruby might be worse than for Python,
because the objects that need the extra overhead are the mutable ones, and contrary to Python, in Ruby that includes strings.
Think of how many string operations the average web application is doing.</p>

<p>On the other side, one argument I can think of in favor of removing the GVL though, would be YJIT.
Given the native code YJIT generates, and the associated metadata it keeps are scoped to the process, no longer
relying on <code class="language-plaintext highlighter-rouge">fork(2)</code> for parallelism would save quite a lot of memory, just by sharing all this memory, that being said,
removing the GVL would also make YJIT’s life much harder, so it may just as much hinder its progress.</p>

<p>Another argument in favor of free threading is that forked processes can’t easily share connections.
So when you start scaling Rails application to a large number of CPU cores, you end up with a lot more connections
to your datastore than with stacks that have free threading, and this can be a big bottleneck, particularly with
some databases with costly connections like PostgreSQL.
Currently, this is largely solved by using external connection poolers, like PgBouncer or ProxySQL, which I understand
aren’t perfect. It’s one more moving piece that can go wrong, but I think it’s much less trouble than free threading.</p>

<p>And finally, I’d like to note that the GVL isn’t the whole picture.
If the goal is to replace <code class="language-plaintext highlighter-rouge">fork(2)</code> by free-threading, even once the GVL is removed, we might still not quite be
there because Ruby’s GC is “stop the world”, so with much more code execution happening in a single process,
hence much more allocations, we may find out that it would become the new contention point.
So personally, I’d rather aim for a fully concurrent GC before wishing the GVL removed.</p>

<h2 id="so-it-is-urgent-to-do-nothing">So It Is Urgent To Do Nothing?</h2>

<p>At this point, some of you may feel like I’m trying to gaslight people into thinking that the GVL is never a problem,
but that’s not exactly my opinion.</p>

<p>I do absolutely think the GVL is currently causing some very real problems in real world applications, namely contention.
But this is very different from wanting the GVL removed and I beleive the situation could be noticeably improved in other ways.</p>

<p>If you’ve read <a href="/ruby/performance/2025/01/23/io-instrumentation.html">my short article on how to properly measure IO time in Ruby</a>,
you may be familiar with the GVL contention problem, but let me include the same test script here:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"bundler/inline"</span>

<span class="n">gemfile</span> <span class="k">do</span>
  <span class="n">gem</span> <span class="s2">"bigdecimal"</span> <span class="c1"># for trilogy</span>
  <span class="n">gem</span> <span class="s2">"trilogy"</span>
  <span class="n">gem</span> <span class="s2">"gvltools"</span>
<span class="k">end</span>

<span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">enable</span>

<span class="k">def</span> <span class="nf">measure_time</span>
  <span class="n">realtime_start</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">clock_gettime</span><span class="p">(</span><span class="no">Process</span><span class="o">::</span><span class="no">CLOCK_MONOTONIC</span><span class="p">,</span> <span class="ss">:float_millisecond</span><span class="p">)</span>
  <span class="n">gvl_time_start</span> <span class="o">=</span> <span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">monotonic_time</span>
  <span class="k">yield</span>

  <span class="n">realtime</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">clock_gettime</span><span class="p">(</span><span class="no">Process</span><span class="o">::</span><span class="no">CLOCK_MONOTONIC</span><span class="p">,</span> <span class="ss">:float_millisecond</span><span class="p">)</span> <span class="o">-</span> <span class="n">realtime_start</span>
  <span class="n">gvl_time</span> <span class="o">=</span> <span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">monotonic_time</span> <span class="o">-</span> <span class="n">gvl_time_start</span>
  <span class="n">gvl_time_ms</span> <span class="o">=</span> <span class="n">gvl_time</span> <span class="o">/</span> <span class="mf">1_000_000.0</span>
  <span class="n">io_time</span> <span class="o">=</span> <span class="n">realtime</span> <span class="o">-</span> <span class="n">gvl_time_ms</span>
  <span class="nb">puts</span> <span class="s2">"io: </span><span class="si">#{</span><span class="n">io_time</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">ms, gvl_wait: </span><span class="si">#{</span><span class="n">gvl_time_ms</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">ms"</span>
<span class="k">end</span>

<span class="n">trilogy</span> <span class="o">=</span> <span class="no">Trilogy</span><span class="p">.</span><span class="nf">new</span>

<span class="c1"># Measure a first time with just the main thread</span>
<span class="n">measure_time</span> <span class="k">do</span>
  <span class="n">trilogy</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s2">"SELECT 1"</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">def</span> <span class="nf">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="p">)</span>
  <span class="k">return</span>  <span class="n">n</span>  <span class="k">if</span> <span class="p">(</span> <span class="mi">0</span><span class="o">..</span><span class="mi">1</span> <span class="p">).</span><span class="nf">include?</span> <span class="n">n</span>
  <span class="p">(</span> <span class="n">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">+</span> <span class="n">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">)</span>
<span class="k">end</span>

<span class="c1"># Spawn 5 CPU-heavy threads</span>
<span class="n">threads</span> <span class="o">=</span> <span class="mi">5</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">map</span> <span class="k">do</span>
  <span class="no">Thread</span><span class="p">.</span><span class="nf">new</span> <span class="k">do</span>
    <span class="kp">loop</span> <span class="k">do</span>
      <span class="n">fibonacci</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="c1"># Measure again with the background threads</span>
<span class="n">measure_time</span> <span class="k">do</span>
  <span class="n">trilogy</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s2">"SELECT 1"</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>If you run it, you should get something like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>realtime: 0.22ms, gvl_wait: 0.0ms, io: 0.2ms
realtime: 549.29ms, gvl_wait: 549.22ms, io: 0.1ms
</code></pre></div></div>

<p>This script demonstrates how GVL contention can cause havoc on your application latency.
And even if you use a single-threaded server like Unicorn or Pitchfork, it doesn’t mean the applications only use
a single thread.
It’s incredibly common to have various background threads to perform some service tasks, such as monitoring.
One example of that is <a href="https://github.com/Shopify/statsd-instrument/blob/6fd8c49d50803bbccfcc11b195f9e334a6e835e9/lib/statsd/instrument/batched_sink.rb#L163">the <code class="language-plaintext highlighter-rouge">statsd-instrument</code> gem</a>.
When you emit a metric, it’s collected in memory, and then a background thread takes care of serializing and sending these metrics
in batch. It’s supposed to be largely IO work, hence shouldn’t have too much impact on the main threads, but in practice,
it can happen that these sorts of background threads hold the GVL for much longer than you’d like.</p>

<p>So while my demo script is extreme, you can absolutely experience some level of GVL contention in production,
regardless of the server you use.</p>

<p>But I don’t think trying to remove the GVL is necessarily the best way to tame that problem, as it would take years of
tears and sweat before you’d reap any benefits.</p>

<p>Prior to something like 2006, multi-core CPUs were basically non-existent, and yet, you were perfectly able to multi-task
on your computer in a relatively smooth way, crunching numbers in Excel while playing some music in Winamp, and this without any parallelism.</p>

<p>That’s because even Windows 95 had a somewhat decent thread scheduler, but Ruby still doesn’t.
What Ruby does when a thread is ready to execute and has to wait for the GVL, is that it puts it in a FIFO queue,
and whenever the running thread releases the GVL, either because it did some IO or because it ran for its allocated 100ms,
Ruby’s thread scheduler pops the next one.</p>

<p>There is no notion of priority or anything. A semi-decent scheduler should be able to notice that a thread is mostly IO and that interrupting the current thread to schedule the IO-heavy thread faster is likely worth it.</p>

<p>So before trying to remove the GVL, it would be worth trying to implement a proper thread scheduler.
Credit goes to <a href="https://github.com/jhawthorn/">John Hawthorn</a> for that idea.</p>

<p>In the meantime, <a href="https://github.com/tenderlove">Aaron Patterson</a> shipped <a href="https://bugs.ruby-lang.org/issues/20861">a change in Ruby 3.4 to allow reducing the
100ms quantum via an environment variable</a>. It doesn’t solve everything, but
it can probably already help in some cases, so it’s a start.</p>

<p>Another idea John shared in one of our conversations<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, would be to allow more CPU operations with the GVL released.
Currently, most database clients only really release the GVL around the IO, think of it like it:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">query</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
  <span class="n">response</span> <span class="o">=</span> <span class="kp">nil</span>
  <span class="n">request</span> <span class="o">=</span> <span class="n">build_network_packet</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>

  <span class="n">release_gvl</span> <span class="k">do</span>
    <span class="n">socket</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">socket</span><span class="p">.</span><span class="nf">read</span>
  <span class="k">end</span>

  <span class="n">parse_db_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>For simple queries that return a non-trivial amount of data, it is likely that you are actually spending much more time
building the Ruby objects with the GVL acquired, than waiting on the DB response with the GVL released.</p>

<p>This is because very very few of the Ruby C API can be used with the GVL released, notably, anything that allocates
and object, or could potentially raise an exception MUST acquire the GVL.</p>

<p>If this constraint was removed, such that you could create basic Ruby objects such as String, Array, and Hashes with
the GVL released, it would likely allow the GVL to be released much longer and significantly reduce contention.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m personally not really in favor of removing the GVL, I don’t think the tradeoff is quite worth it, at least not yet,
nor do I think it would be as much of a game-changer as some may imagine.</p>

<p>If it didn’t have any impact on the classic (mostly) single-threaded performance, I wouldn’t mind it,
but it is almost guaranteed to degrade single-threaded performance significantly, hence this feels a bit like
“a bird in the hand is worth two in the bush” kind of proposition.</p>

<p>Instead, I believe there are some much easier and smaller changes we could make to Ruby that would improve the situation
on a much shorter timeline and with much less effort both for Ruby-core and for Ruby users.</p>

<p>But of course that is just the perspective of a single Ruby user with mostly my own use case in mind,
and ultimately this is for Matz to decide, based on what he thinks the community wants and needs.</p>

<p>For now, Matz doesn’t want to remove the GVL and He instead accepted the Ractor proposal<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>. 
Perhaps his opinion may change one day, we’ll see.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>MRI: Matz’s Ruby Interpreter, the reference implementation of Ruby, sometimes referred to as CRuby. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>If you didn’t notice, John is incredibly clever. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>Ractors which I also wanted to discuss in this post, but it’s already too long, so maybe another time. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ruby" /><category term="performance" /><summary type="html"><![CDATA[I want to write a post about Pitchfork, explaining where it comes from, why it is like it is, and how I see its future. But before I can get to that, I think I need to share my mental model on a few things, in this case, Ruby’s GVL.]]></summary></entry><entry><title type="html">Why Does Everyone Hate fork(2)?</title><link href="https://byroot.github.io/ruby/performance/2025/01/25/why-does-everyone-hate-fork.html" rel="alternate" type="text/html" title="Why Does Everyone Hate fork(2)?" /><published>2025-01-25T09:47:51+00:00</published><updated>2025-01-25T09:47:51+00:00</updated><id>https://byroot.github.io/ruby/performance/2025/01/25/why-does-everyone-hate-fork</id><content type="html" xml:base="https://byroot.github.io/ruby/performance/2025/01/25/why-does-everyone-hate-fork.html"><![CDATA[<p>I want to write a post about <a href="https://rubygems.org/gems/pitchfork">Pitchfork</a>, explaining where it comes from, why it
is like it is, and how I see its future.
But before I can get to that, I think I need to explain a few things, namely why in many circles <code class="language-plaintext highlighter-rouge">fork</code> is seen as a
relic of the past, if not outright the devil’s creation.
And yet, it’s ubiquitous in the Ruby ecosystem.</p>

<p>Note that if you have some system programming experience, you probably won’t learn much here.</p>

<p>If you’ve ever deployed a Ruby application to production, it is almost certain you’ve interacted with
<a href="https://man7.org/linux/man-pages/man2/fork.2.html"><code class="language-plaintext highlighter-rouge">fork(2)</code></a> whether you realize it or not.
Have you configured Puma’s <code class="language-plaintext highlighter-rouge">worker</code> setting? Well, Puma uses <code class="language-plaintext highlighter-rouge">fork(2)</code> to spawn these workers, more accurately the Ruby
<a href="https://docs.ruby-lang.org/en/3.4/Process.html#method-c-fork"><code class="language-plaintext highlighter-rouge">Process.fork</code></a> method, which is the Ruby API for
the underlying <code class="language-plaintext highlighter-rouge">fork(2)</code> syscall.</p>

<p>And even if you’re not a Rubyist, if you’ve used PHP, Nginx, Apache HTTPd, Redis, and many others you’ve used a system
that is heavily relient on <code class="language-plaintext highlighter-rouge">fork(2)</code>, if not entirely architectured around it.</p>

<p>Yet, <a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/04/fork-hotos19.pdf">many people would argue that <code class="language-plaintext highlighter-rouge">fork(2)</code> is evil and shouldn’t be used</a>.
Personally I kinda both agree and disagree with that point of view, and I’ll try to explain why.</p>

<h2 id="a-bit-of-history">A Bit Of History</h2>

<p>According to Wikipedia, the first occurrence of the fork concept dates all the way back to 1962 by the same guy who
coined <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a>, and was later introduced in the first versions of UNIX.</p>

<p>Initially, it was meant as a primitive to create a new process. You’d call <code class="language-plaintext highlighter-rouge">fork(2)</code> to make a copy of the current process
and from there would mutate that new process into what you want it to be, quickly ending up with an <code class="language-plaintext highlighter-rouge">exec(2)</code>.
You can still do this today in Ruby:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="n">child_pid</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">fork</span><span class="p">)</span>
  <span class="c1"># We're in the parent process, and we know the child process ID.</span>
  <span class="c1"># We can wait for the child to exit or send signals etc.</span>
  <span class="no">Process</span><span class="p">.</span><span class="nf">wait</span><span class="p">(</span><span class="n">child_pid</span><span class="p">)</span>
<span class="k">else</span>
  <span class="c1"># We're in the child process.</span>
  <span class="c1"># We can change the current user and other attributes.</span>
  <span class="no">Process</span><span class="p">.</span><span class="nf">uid</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="c1"># And then we can replace the current program with another.</span>
  <span class="no">Process</span><span class="p">.</span><span class="nf">exec</span><span class="p">(</span><span class="s2">"echo"</span><span class="p">,</span> <span class="s2">"hello"</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>In a way that design was quite elegant. You have a handful of simple primitives you can compose together to get
exactly the behavior you need, instead of one huge function that takes a myriad of arguments.</p>

<p>But it is also very inefficient, as entirely duplicating a process to create a new one is generally overkill.
In the example above, if you imagine that our parent program has gigabytes of addressable memory, it’s a huge waste
to copy all of that just to throw it all out almost immediately to replace it with an extremely small program like <code class="language-plaintext highlighter-rouge">/bin/echo</code>.</p>

<p>Of course, modern operating systems don’t actually copy all that, and instead use <a href="https://en.wikipedia.org/wiki/Copy-on-write#In_virtual_memory_management">Copy-on-Write</a>,
but that’s still very costly, and can easily take hundreds of milliseconds if the parent process is big.</p>

<p>That’s why this historical usage of <code class="language-plaintext highlighter-rouge">fork(2)</code> to spawn other programs is mostly considered deprecated today, and most
newer software will use more modern APIs such as <code class="language-plaintext highlighter-rouge">posix_spawn(3)</code> or <code class="language-plaintext highlighter-rouge">vfork(2)+exec(2)</code>.</p>

<p>But that’s not the only use of <code class="language-plaintext highlighter-rouge">fork(2)</code>. I have no idea if this was envisioned right from the start, or if it just became
a thing, but all the software I listed in the introduction uses <code class="language-plaintext highlighter-rouge">fork(2)</code> without ever following it with an <code class="language-plaintext highlighter-rouge">exec(2)</code> call.</p>

<h2 id="fork-as-a-parallelism-primitive">Fork as a Parallelism Primitive</h2>

<p>Again, I wasn’t even born in the early seventies, so I’m not too sure when this practice really started but at some
point <code class="language-plaintext highlighter-rouge">fork(2)</code> started being used as a parallelism primitive, particularly for servers.</p>

<p>Let’s say you want to implement a simple “echo” server from scratch, in Ruby it might look like this:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'socket'</span>

<span class="n">server</span> <span class="o">=</span> <span class="no">TCPServer</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="s1">'localhost'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">)</span>

<span class="k">while</span> <span class="n">socket</span> <span class="o">=</span> <span class="n">server</span><span class="p">.</span><span class="nf">accept</span>
  <span class="k">while</span> <span class="n">line</span> <span class="o">=</span> <span class="n">socket</span><span class="p">.</span><span class="nf">gets</span>
    <span class="n">socket</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
  <span class="k">end</span>
  <span class="n">socket</span><span class="p">.</span><span class="nf">close</span>
<span class="k">end</span>
</code></pre></div></div>

<p>This script first opens a listening socket on port <code class="language-plaintext highlighter-rouge">8000</code>, then blocks on the <code class="language-plaintext highlighter-rouge">accept(2)</code> syscall to wait for a client
to connect. When that method returns, it gives us a bidirectional socket, from which we can read, in this case with <code class="language-plaintext highlighter-rouge">#gets</code>,
and also write back to the client.</p>

<p>While this is using modern Ruby, that’s very similar to how various servers would be written back then, but overly simplified.</p>

<p>If you want to play with it, you can use <code class="language-plaintext highlighter-rouge">telnet localhost 8000</code> and start writing things.</p>

<p>But there’s one big issue with that server: it only supports a single concurrent user.
If you try to have two <code class="language-plaintext highlighter-rouge">telnet</code> sessions active, you’ll see the second one can’t connect.</p>

<p>So what people started doing, was to leverage <code class="language-plaintext highlighter-rouge">fork(2)</code> to be able to support more users:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s1">'socket'</span>

<span class="n">server</span> <span class="o">=</span> <span class="no">TCPServer</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="s1">'localhost'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">)</span>
<span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="n">socket</span> <span class="o">=</span> <span class="n">server</span><span class="p">.</span><span class="nf">accept</span>
  <span class="c1"># prune exited children</span>
  <span class="n">children</span><span class="p">.</span><span class="nf">reject!</span> <span class="p">{</span> <span class="o">|</span><span class="n">pid</span><span class="o">|</span> <span class="no">Process</span><span class="p">.</span><span class="nf">wait</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="no">Process</span><span class="o">::</span><span class="no">WNOHANG</span><span class="p">)}</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">child_pid</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">fork</span><span class="p">)</span>
    <span class="n">children</span> <span class="o">&lt;&lt;</span> <span class="n">child_pid</span>
    <span class="n">socket</span><span class="p">.</span><span class="nf">close</span>
  <span class="k">else</span>
    <span class="k">while</span> <span class="n">line</span> <span class="o">=</span> <span class="n">socket</span><span class="p">.</span><span class="nf">gets</span>
      <span class="n">socket</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="n">socket</span><span class="p">.</span><span class="nf">close</span>
    <span class="no">Process</span><span class="p">.</span><span class="nf">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>The logic is the same as before, but now once <code class="language-plaintext highlighter-rouge">accept(2)</code> returns us a socket, instead of blocking on it,
we <code class="language-plaintext highlighter-rouge">fork(2)</code> a new child process, and let that child do the blocking operations until the client closes the connection.</p>

<p>If you are an astute reader (or simply already knowledgeable about <code class="language-plaintext highlighter-rouge">fork(2)</code> semantics), you may have noticed that after
the call to <code class="language-plaintext highlighter-rouge">fork</code>, both the parent and the new children have access to the socket. That is because, in UNIX, sockets are
“files”, hence represented by a “file descriptor”, and part of the <code class="language-plaintext highlighter-rouge">fork(2)</code> semantic is that all file descriptors are
also inherited.</p>

<p>That’s why it is important that the parent close the socket, otherwise, it will stay open forever in the parent process<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>,
And this is one of the first reasons why many people hate <code class="language-plaintext highlighter-rouge">fork(2)</code>.</p>

<h2 id="a-double-edged-sword">A Double-Edged Sword</h2>

<p>As showcased above, the fact that child processes inherit all open file descriptors allows to implement some very useful things,
but it can also cause catastrophic bugs if you forget to close a file descriptor you didn’t mean to share.</p>

<p>For instance, if you are forking a process that has an active connection to a SQL database, and you keep using that
connection in both processes, weird things will happen:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"bundler/inline"</span>
<span class="n">gemfile</span> <span class="k">do</span>
  <span class="n">gem</span> <span class="s2">"trilogy"</span>
  <span class="n">gem</span> <span class="s2">"bigdecimal"</span> <span class="c1"># for trilogy</span>
<span class="k">end</span>

<span class="n">client</span> <span class="o">=</span> <span class="no">Trilogy</span><span class="p">.</span><span class="nf">new</span>
<span class="n">client</span><span class="p">.</span><span class="nf">ping</span>

<span class="k">if</span> <span class="n">child_pid</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">fork</span>
  <span class="nb">sleep</span> <span class="mf">0.1</span> <span class="c1"># Give some time to the child</span>

  <span class="mi">5</span><span class="p">.</span><span class="nf">times</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="nb">p</span> <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s2">"SELECT </span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">).</span><span class="nf">first</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">end</span>
  <span class="no">Process</span><span class="p">.</span><span class="nf">kill</span><span class="p">(</span><span class="ss">:KILL</span><span class="p">,</span> <span class="n">child_pid</span><span class="p">)</span>
  <span class="no">Process</span><span class="p">.</span><span class="nf">wait</span><span class="p">(</span><span class="n">child_pid</span><span class="p">)</span>
<span class="k">else</span>
  <span class="kp">loop</span> <span class="k">do</span>
    <span class="n">client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s1">'SELECT "oops"'</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Here the script establishes a connection to MySQL, using the <code class="language-plaintext highlighter-rouge">trilogy</code> client, then forks a child
that queries <code class="language-plaintext highlighter-rouge">SELECT "oops"</code> indefinitely in a loop. Once the child is spawned, the parent issues 5 queries,
each one supposed to return a single number from 0 to 4, and print their result.</p>

<p>If you run this script, you’ll get a somewhat random output, similar to this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"oops"
1
"oops"
"oops"
3
</code></pre></div></div>

<p>What’s happening here is that both processes are writing inside the same socket. For the MySQL server, it’s not a big
deal because our queries are small, so they’re somewhat “atomically” written into the socket if we were to issue larger
queries, two queries might end up interleaved, which would cause the server to close the connection with some form of
protocol error.</p>

<p>But for the client, it’s really bad. Because the responses of both processes are sent back in the same socket, and
each client is issuing <code class="language-plaintext highlighter-rouge">read(2)</code> and might be getting the response to the query it just issued, but the response of
another unrelated query issued by the other process.</p>

<p>When two processes try to <code class="language-plaintext highlighter-rouge">read(2)</code> on the same socket, they each get part of the data, but you don’t have proper control
over which process gets what, and it’s unrealistic to try to synchronize the two processes so they each get the response
they expect.</p>

<p>With this in mind, you can imagine how much of a hassle it can be to properly close all the sockets and other open files
of an application before you call <code class="language-plaintext highlighter-rouge">fork(2)</code>. Perhaps you can be diligent in your own code, but you likely are using some
libraries that may not expect <code class="language-plaintext highlighter-rouge">fork(2)</code> to be called and don’t allow you to close their file descriptors.</p>

<p>For the <code class="language-plaintext highlighter-rouge">fork+exec</code> use case, there’s a nice feature that makes this much easier, you can mark a file descriptor as needing
to be closed when <code class="language-plaintext highlighter-rouge">exec</code> is called, and the operating system takes care of that for you, <code class="language-plaintext highlighter-rouge">O_CLOEXEC</code> (for close on exec),
which in Ruby is conveniently exposed as a method on the <code class="language-plaintext highlighter-rouge">IO</code> class:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="no">STDIN</span><span class="p">.</span><span class="nf">close_on_exec</span> <span class="o">=</span> <span class="kp">true</span>
</code></pre></div></div>

<p>But there’s no such flag for the <code class="language-plaintext highlighter-rouge">fork</code> system call when it’s not followed by an <code class="language-plaintext highlighter-rouge">exec</code>. Or more accurately
there is one, <code class="language-plaintext highlighter-rouge">O_CLOFORK</code>, which has existed on a few UNIX systems, mostly IBM ones, and <a href="https://austingroupbugs.net/view.php?id=1318">was added to the POSIX spec in 2020</a>.
But it isn’t widely supported today, most importantly Linux doesn’t support it.
<a href="https://lore.kernel.org/all/1304749754.2821.712.camel@edumazet-laptop/T/#m2a7dbb0f0f6106b3d9ecc8c485a683ea6b2e02ee">Someone submitted a patch to add it to Linux in 2011</a>,
but it seems there wasn’t much appetite for it, and <a href="https://lore.kernel.org/lkml/20200525081626.GA16796@amd/T/#m4ef81228aba3f9524329f83a124d0322ed53f834">someone else made another attempt in 2020</a>,
but it encountered some strong opposition, which is a shame, because it would be tremendously useful.</p>

<p>Instead, what most code that wants to be fork-safe does, it either trying to detect a fork happened by continuously checking
the current process ID:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">query</span>
  <span class="k">if</span> <span class="no">Process</span><span class="p">.</span><span class="nf">pid</span> <span class="o">!=</span> <span class="vi">@old_pid</span>
    <span class="vi">@connection</span><span class="p">.</span><span class="nf">close</span>
    <span class="vi">@connection</span> <span class="o">=</span> <span class="kp">nil</span>
    <span class="vi">@old_pid</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">pid</span>
  <span class="k">end</span>

  <span class="vi">@connection</span> <span class="o">||=</span> <span class="n">connect</span>
  <span class="vi">@connection</span><span class="p">.</span><span class="nf">query</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Or alternatively rely on some <code class="language-plaintext highlighter-rouge">at_fork</code> callback, in C land usually it is <a href="https://man7.org/linux/man-pages/man3/pthread_atfork.3.html"><code class="language-plaintext highlighter-rouge">pthread_atfork</code></a>,
and <a href="https://bugs.ruby-lang.org/issues/17795">since Ruby since 3.1, you can decorate <code class="language-plaintext highlighter-rouge">Process._fork</code></a> (note the <code class="language-plaintext highlighter-rouge">_</code>):</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">module</span> <span class="nn">MyLibraryAtFork</span>
  <span class="k">def</span> <span class="nf">_fork</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="k">super</span>
    <span class="k">if</span> <span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="c1"># in child</span>
    <span class="k">else</span>
      <span class="c1"># in parent</span>
      <span class="no">MyLibrary</span><span class="p">.</span><span class="nf">close_all_ios</span>
    <span class="k">end</span>
    <span class="n">pid</span>
  <span class="k">end</span>
<span class="k">end</span>
<span class="no">Process</span><span class="p">.</span><span class="nf">singleton_class</span><span class="p">.</span><span class="nf">prepend</span><span class="p">(</span><span class="no">MyLibraryAtFork</span><span class="p">)</span>
</code></pre></div></div>

<p>Since <code class="language-plaintext highlighter-rouge">fork(2)</code> is quite ubiquitous in Ruby, many popular libraries that deal with sockets, such as Active Record, or
the <code class="language-plaintext highlighter-rouge">redis</code> gem, do their best to take care of this transparently, so you don’t have to think about it.
Hence in most Ruby programs it just works.</p>

<p>But with native languages, it can be quite tedious and that’s one of the reasons why many people absolutely hate <code class="language-plaintext highlighter-rouge">fork(2)</code>.
Any code that makes use of files or sockets might be utterly broken after <code class="language-plaintext highlighter-rouge">fork(2)</code> has been called, unless special attention
was paid to fork safety, which is rarely the case.</p>

<h2 id="some-of-your-threads-may-die">Some of Your Threads May Die</h2>

<p>Going back to our small echo server, you may wonder why one would use <code class="language-plaintext highlighter-rouge">fork(2)</code> instead of a thread here.
Again, I wasn’t there at the time, but my understanding is that threads became a thing much later (late eighties?),
and even once they existed, they took quite a while to be standardized and ironed out, hence usable across platforms.</p>

<p>There is also probably an argument that multi-processing with <code class="language-plaintext highlighter-rouge">fork(2)</code> is easier to reason about. Each process has its
own memory space, so you don’t have to concern yourself as much with race conditions and other thread pitfalls, so I can
see why even when threads became an option, some may have preferred to stick with <code class="language-plaintext highlighter-rouge">fork(2)</code>.</p>

<p>But since threads became a thing long after <code class="language-plaintext highlighter-rouge">fork(2)</code>, it seems that the people in charge of implementing and
standardizing them ran into a bit of a pickle, and didn’t find a way to make them both play well together.</p>

<p>Here’s what <a href="https://pubs.opengroup.org/onlinepubs/009696799/functions/fork.html">the POSIX standard fork entry</a> says about that:</p>

<blockquote>
  <p>A process shall be created with a single thread.
If a multi-threaded process calls fork(), the new process shall contain a replica of the calling thread and its entire
address space, possibly including the states of mutexes and other resources.
Consequently, to avoid errors, the child process may only execute async-signal-safe operations until such time as one
of the exec functions is called.</p>
</blockquote>

<p>In other words, the standard acknowledges that the classic <code class="language-plaintext highlighter-rouge">fork+exec</code> dance can be done from a multi-threaded process,
but kind of wash its hands about the use of <code class="language-plaintext highlighter-rouge">fork</code> not followed by <code class="language-plaintext highlighter-rouge">exec</code>. They recommend only using async-signal-safe
operations, which is really just a very small subset of things. So really, according to the standard, if you call
<code class="language-plaintext highlighter-rouge">fork(2)</code> after some threads have been spawned, without the intention to call <code class="language-plaintext highlighter-rouge">exec</code> quickly, then here be dragons.</p>

<p>The reason is that only the thread which called <code class="language-plaintext highlighter-rouge">fork(2)</code> remains alive in the children, all the other threads
are present but dead. If another thread had locked a mutex or something like that, it would stay locked forever,
which might lead to a deadlock if a new thread tries to acquire it.</p>

<p>The standard also includes a rationale section about why it is this way, which is a bit long but interesting:</p>

<blockquote>
  <p>The general problem with making fork() work in a multi-threaded world is what to do with all of the threads.
There are two alternatives. 
One is to copy all of the threads into the new process.
This causes the programmer or implementation to deal with threads that are suspended on system calls or that might be
about to execute system calls that should not be executed in the new process.
The other alternative is to copy only the thread that calls fork().
This creates the difficulty that the state of process-local resources is usually held in process memory.
If a thread that is not calling fork() holds a resource, that resource is never released in the child process because
the thread whose job it is to release the resource does not exist in the child process.</p>

  <p>When a programmer is writing a multi-threaded program, […]
<strong>The fork() function is thus used only to run new programs</strong>, and the effects of calling functions that require certain
resources between the call to fork() and the call to an exec function are undefined.</p>

  <p>The addition of the forkall() function to the standard was considered and rejected.</p>
</blockquote>

<p>So they did consider the possibility of having another version of <code class="language-plaintext highlighter-rouge">fork(2)</code>, called <code class="language-plaintext highlighter-rouge">forkall()</code> which would also have
copied other threads, but they couldn’t come up with a clear semantic on what happens in some cases.</p>

<p>Instead, they gave users a way to have a callback invoked around <code class="language-plaintext highlighter-rouge">fork</code> to restore state, for instance, re-initialize mutexes.
However, if you go look at <a href="https://man7.org/linux/man-pages/man3/pthread_atfork.3.html">that callback man page <code class="language-plaintext highlighter-rouge">pthread_atfork(3)</code></a>,
you can read:</p>

<blockquote>
  <p>The original intention of pthread_atfork() was to allow the child process to be returned to a consistent state. […]
In practice, this task is generally too difficult to be practicable.</p>
</blockquote>

<p>So while <code class="language-plaintext highlighter-rouge">pthread_atfork</code> is still there and you can use it, the standard acknowledges that it is very hard to use correctly.</p>

<p>That’s why many system programmers will tell you to never mix <code class="language-plaintext highlighter-rouge">fork(2)</code> with multi-threaded programs, or at least never
to call <code class="language-plaintext highlighter-rouge">fork(2)</code> ever after a thread was spawned, because then, all bets are off. Hence, you somewhat had to choose your
camp, and it seems threads clearly won.</p>

<p>But that’s for C or C++ programmers.</p>

<p>In the case of today’s Ruby programmers, however, the reason to use <code class="language-plaintext highlighter-rouge">fork(2)</code> over threads, is that it’s the only way
to get true parallelism <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> on MRI, the default and most commonly used implementation of Ruby.
Because of the infamous GVL, Ruby threads only really allow to parallelize IO operations,
and can’t parallelize Ruby code execution, hence pretty much all Ruby application servers integrate with <code class="language-plaintext highlighter-rouge">fork(2)</code> in
some way so they can exploit more than a single CPU core.</p>

<p>Luckily, some of the pitfalls of mixing threads with <code class="language-plaintext highlighter-rouge">fork(2)</code> are alleviated by Ruby.
For instance, Ruby mutexes are automatically released when their owner dies, due to how they are implemented.
In pseudo Ruby code they’d look like this:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Mutex</span>
  <span class="k">def</span> <span class="nf">lock</span>
    <span class="k">if</span> <span class="vi">@owner</span> <span class="o">==</span> <span class="no">Fiber</span><span class="p">.</span><span class="nf">current</span>
      <span class="k">raise</span> <span class="no">ThreadError</span><span class="p">,</span> <span class="s2">"deadlock; recursive locking"</span>
    <span class="k">end</span>

    <span class="k">while</span> <span class="vi">@owner</span><span class="o">&amp;</span><span class="p">.</span><span class="nf">alive?</span>
      <span class="nb">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">end</span>

    <span class="vi">@owner</span> <span class="o">=</span> <span class="no">Fiber</span><span class="p">.</span><span class="nf">current</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Of course in reality they’re not sleeping in a loop to wait, they use a much more efficient way to block, but it’s to
give you the general idea.
The important point is that Ruby mutexes keep a reference to the fiber (hence thread) that acquired the lock,
and automatically ignore it if it’s dead.
Hence upon fork, all mutexes held by the background thread are immediately released, which avoids most
deadlock scenarios.</p>

<p>It’s not perfect of course, if a thread died while holding a mutex, it’s very possible that it left the resource that was protected
by the mutex in an inconsistent state, in practice however I’ve never experienced something like that, granted it’s likely
because the existence of the GVL somewhat reduces the need for mutexes.</p>

<p>Now, Ruby threads aren’t fully exempt from these pitfalls, because ultimately on MRI, Ruby threads are backed by native threads,
so you can end up with a nasty deadlock after forking if another thread released the GVL and called a C API that locks a mutex.</p>

<p>While I never got hard proof of it, I suspect this was happening to some Ruby users because from my understanding,
glibc’s <a href="https://man7.org/linux/man-pages/man3/getaddrinfo.3.html"><code class="language-plaintext highlighter-rouge">getaddrinfo(3)</code></a>,
which Ruby uses to resolve host names, does use a global mutex, and Ruby calls it with the GVL released, allowing for a
fork to happen concurrently.</p>

<p>To prevent this, <a href="https://bugs.ruby-lang.org/issues/20590">I added another lock inside MRI</a>, to prevent <code class="language-plaintext highlighter-rouge">Process.fork</code>
from happening while a <code class="language-plaintext highlighter-rouge">getaddrinfo(3)</code> call is ongoing.
This is far from perfect, but given how much Ruby relies on <code class="language-plaintext highlighter-rouge">Process.fork</code>, that seemed like a sensible thing to do.</p>

<p>It’s also not rare for Ruby programs that rely on fork to run into crashes on macOS, because numerous macOS system APIs
do implicitly spawn threads or lock mutexes, and <a href="https://github.com/rails/rails/issues/38560">macOS chose to consistenty crash when it happens</a>.</p>

<p>So even with pure Ruby code, you occasionally run into <code class="language-plaintext highlighter-rouge">fork(2)</code>’s pitfalls, you can’t just use it willy-nilly.</p>

<h2 id="conclusion">Conclusion</h2>

<p>So to answer the question in the title, the reason <code class="language-plaintext highlighter-rouge">fork(2)</code> is hated is because it doesn’t compose well, particularly
in native code.
If you wish to use it, you have to be extremely careful about the code you are writing and linking to.
Whenever you use a library you have to make sure it won’t spawn some threads, or hold onto file descriptors,
and given the choice between <code class="language-plaintext highlighter-rouge">fork(2)</code> and threads, most systems programmers will choose threads. They have their own
pitfalls, but they compose better, and it is likely that you are calling into APIs that are using threads under the
hoods, so the choice is somewhat already made for you.</p>

<p>But the situation isn’t nearly as bad for Ruby code, as it makes it much easier to write fork-safe code, and the Ruby
philosophy makes it so libraries like Active Record take it upon themselves to deal with these gnarly details for you.
So problems mostly come up when you want to bind to some native libraries that spawn threads, like <code class="language-plaintext highlighter-rouge">grpc</code> or <code class="language-plaintext highlighter-rouge">libvips</code>,
as they generally don’t expect <code class="language-plaintext highlighter-rouge">fork(2)</code> to happen and aren’t generally kin in accepting it as a constraint.</p>

<p>Especially since fork is mostly used at the end of the application initialization, even libraries
that are technically not fork-safe, will work because they generally initialize their threads and file descriptors
lazily upon the first request.</p>

<p>Anyway, even if you still think <code class="language-plaintext highlighter-rouge">fork(2)</code> is evil, until Ruby offers another usable primitive for true parallelism
(which should be the subject of the next post), it will remain a necessary evil.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>Technically, Ruby will automatically close it once the object is garbage collected, but you get the idea. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Yes, there are also Ractors to some extent, but that will be the subject of the next post. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ruby" /><category term="performance" /><summary type="html"><![CDATA[I want to write a post about Pitchfork, explaining where it comes from, why it is like it is, and how I see its future. But before I can get to that, I think I need to explain a few things, namely why in many circles fork is seen as a relic of the past, if not outright the devil’s creation. And yet, it’s ubiquitous in the Ruby ecosystem.]]></summary></entry><entry><title type="html">Instrumenting Thread Stalling in Ruby Applications</title><link href="https://byroot.github.io/ruby/performance/2025/01/23/io-instrumentation.html" rel="alternate" type="text/html" title="Instrumenting Thread Stalling in Ruby Applications" /><published>2025-01-23T13:50:51+00:00</published><updated>2025-01-23T13:50:51+00:00</updated><id>https://byroot.github.io/ruby/performance/2025/01/23/io-instrumentation</id><content type="html" xml:base="https://byroot.github.io/ruby/performance/2025/01/23/io-instrumentation.html"><![CDATA[<p>In <a href="https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html">my previous post about how IO-bound Rails applications really are</a>,
I pointed at a common pitfall, how CPU starvation can look like slow IOs.</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="no">Time</span><span class="p">.</span><span class="nf">now</span>
<span class="n">database_connection</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="s2">"SELECT ..."</span><span class="p">)</span>
<span class="n">query_duration</span> <span class="o">=</span> <span class="p">(</span><span class="no">Time</span><span class="p">.</span><span class="nf">now</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1000.0</span>
<span class="nb">puts</span> <span class="s2">"Query took: </span><span class="si">#{</span><span class="n">query_duration</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">ms"</span>
</code></pre></div></div>

<p>In the above example, the instrumentation tells you how long it took for the database to answer your query, but may
also include the time needed for the Ruby thread to re-acquire the GVL, or perhaps the Ruby GC to run, or even the
operating system’s scheduler to resume the process.</p>

<p>Thankfully, in recent years Ruby added some new APIs that help measure these things.</p>

<h2 id="gctotal_time">GC.total_time</h2>

<p>Database queries and other IOs can often result in lots of allocations. For instance, if you select 100 database rows,
with a dozen columns each, you can probably expect a thousand or more allocations and any of these might trigger a GC
run inside the code block you are timing.</p>

<p>As such it can be a good idea to keep an eye on how much time Ruby is spending in GC. To help with that, <a href="https://bugs.ruby-lang.org/issues/10917#note-4">back in 2021
I resurrected an old feature request on the Ruby bug tracker</a> and
convinced <a href="https://github.com/ruby/ruby/pull/4757">Koichi Sadasa to implement the new <code class="language-plaintext highlighter-rouge">GC.total_time</code> API</a>.</p>

<p>This accessor is a monotonic counter, that represents the number of nanoseconds spent in the GC. So to tell how much
time a particular block of code spent in GC, you can do a simple subtraction:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">time_in_gc</span>
  <span class="n">before</span> <span class="o">=</span> <span class="no">GC</span><span class="p">.</span><span class="nf">total_time</span>
  <span class="k">yield</span>
  <span class="n">diff_ms</span> <span class="o">=</span> <span class="p">(</span><span class="no">GC</span><span class="p">.</span><span class="nf">total_time</span> <span class="o">-</span> <span class="n">before</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1_000_000.0</span>

  <span class="nb">puts</span> <span class="s2">"gc_time: </span><span class="si">#{</span><span class="n">diff_ms</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">ms"</span>
<span class="k">end</span>

<span class="n">time_in_gc</span> <span class="k">do</span>
  <span class="mi">2_000_000</span><span class="p">.</span><span class="nf">times</span> <span class="p">{</span> <span class="no">Object</span><span class="p">.</span><span class="nf">new</span> <span class="p">}</span>
<span class="k">end</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gc_time: 24.18ms
</code></pre></div></div>

<p>Now of course, if you are running a multi-threaded application, you can’t just subtract the time spent in GC from the
measured IO time, because another thread might be responsible for it. But it’s still a good idea to instrument it
and display it next to the IO duration.</p>

<p>That’s why starting from Rails 7.2, <a href="https://github.com/rails/rails/pull/51770">I added this measurement into Rails instrumentation API</a>.
Every <code class="language-plaintext highlighter-rouge">ActiveSupport::Notifications</code> event now has an associated <code class="language-plaintext highlighter-rouge">gc_time</code>, and Rails request logs include the overall time spent in GC.</p>

<h2 id="gvl-instrumentation-api">GVL Instrumentation API</h2>

<p>Even more common than GC, is GVL contention. If you configured your application to use too many threads, it can cause
long delays for a thread to resume after finishing some IOs.</p>

<p>That’s why <a href="https://bugs.ruby-lang.org/issues/18339">in Ruby 3.2 I added a new C API to allow instrumenting the GVL</a>.</p>

<p>This is quite a low-level API, and you need a C extension to integrate with it, but I wrote
<a href="https://github.com/Shopify/gvltools"><code class="language-plaintext highlighter-rouge">gvltools</code></a> for that, and John Hawthorn wrote the
<a href="https://github.com/jhawthorn/gvl_timing"><code class="language-plaintext highlighter-rouge">gvl_timing</code> gem</a>, and there’s
also <a href="https://github.com/ivoanjo/gvl-tracing"><code class="language-plaintext highlighter-rouge">gvl-tracing</code></a> from Ivo Anjo.</p>

<p>Here’s how <code class="language-plaintext highlighter-rouge">gvltools</code> can be used to distinguish actual IO time from GVL wait time:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">require</span> <span class="s2">"bundler/inline"</span>

<span class="n">gemfile</span> <span class="k">do</span>
  <span class="n">gem</span> <span class="s2">"bigdecimal"</span> <span class="c1"># for trilogy</span>
  <span class="n">gem</span> <span class="s2">"trilogy"</span>
  <span class="n">gem</span> <span class="s2">"gvltools"</span>
<span class="k">end</span>

<span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">enable</span>

<span class="k">def</span> <span class="nf">measure_time</span>
  <span class="n">realtime_start</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">clock_gettime</span><span class="p">(</span><span class="no">Process</span><span class="o">::</span><span class="no">CLOCK_MONOTONIC</span><span class="p">,</span> <span class="ss">:float_millisecond</span><span class="p">)</span>
  <span class="n">gvl_time_start</span> <span class="o">=</span> <span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">monotonic_time</span>
  <span class="k">yield</span>

  <span class="n">realtime</span> <span class="o">=</span> <span class="no">Process</span><span class="p">.</span><span class="nf">clock_gettime</span><span class="p">(</span><span class="no">Process</span><span class="o">::</span><span class="no">CLOCK_MONOTONIC</span><span class="p">,</span> <span class="ss">:float_millisecond</span><span class="p">)</span> <span class="o">-</span> <span class="n">realtime_start</span>
  <span class="n">gvl_time</span> <span class="o">=</span> <span class="no">GVLTools</span><span class="o">::</span><span class="no">LocalTimer</span><span class="p">.</span><span class="nf">monotonic_time</span> <span class="o">-</span> <span class="n">gvl_time_start</span>
  <span class="n">gvl_time_ms</span> <span class="o">=</span> <span class="n">gvl_time</span> <span class="o">/</span> <span class="mf">1_000_000.0</span>
  <span class="n">io_time</span> <span class="o">=</span> <span class="n">realtime</span> <span class="o">-</span> <span class="n">gvl_time_ms</span>
  <span class="nb">puts</span> <span class="s2">"io: </span><span class="si">#{</span><span class="n">io_time</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">ms, gvl_wait: </span><span class="si">#{</span><span class="n">gvl_time_ms</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">ms"</span>
<span class="k">end</span>

<span class="n">trilogy</span> <span class="o">=</span> <span class="no">Trilogy</span><span class="p">.</span><span class="nf">new</span>

<span class="c1"># Measure a first time with just the main thread</span>
<span class="n">measure_time</span> <span class="k">do</span>
  <span class="n">trilogy</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s2">"SELECT 1"</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">def</span> <span class="nf">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="p">)</span>
  <span class="k">return</span>  <span class="n">n</span>  <span class="k">if</span> <span class="p">(</span> <span class="mi">0</span><span class="o">..</span><span class="mi">1</span> <span class="p">).</span><span class="nf">include?</span> <span class="n">n</span>
  <span class="p">(</span> <span class="n">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">+</span> <span class="n">fibonacci</span><span class="p">(</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">)</span>
<span class="k">end</span>

<span class="c1"># Spawn 5 CPU-heavy threads</span>
<span class="n">threads</span> <span class="o">=</span> <span class="mi">5</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">map</span> <span class="k">do</span>
  <span class="no">Thread</span><span class="p">.</span><span class="nf">new</span> <span class="k">do</span>
    <span class="kp">loop</span> <span class="k">do</span>
      <span class="n">fibonacci</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="c1"># Measure again with the background threads</span>
<span class="n">measure_time</span> <span class="k">do</span>
  <span class="n">trilogy</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="s2">"SELECT 1"</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>If you run this example, you can see that on the first measurement, the GVL wait time is pretty much zero,
but on the second, it adds a massive half-a-second overhead:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>realtime: 0.22ms, gvl_wait: 0.0ms, io: 0.2ms
realtime: 549.29ms, gvl_wait: 549.22ms, io: 0.1ms
</code></pre></div></div>

<p>The downside of this API however, is that it adds some overhead to Ruby’s thread scheduler. I never really managed to
come up with a precise figure of how much overhead, perhaps it’s negligible, but until then, it’s a bit hard to justify
integrating it as a Rails default.</p>

<p>That being said, recently <a href="https://github.com/speedshop/gvl_metrics_middleware/tree/main">Yuki Nishijima from Speedshop open-sourced a middleware</a>
to hook this new instrumentation API into various APM services, so it might progressively see broader usage.</p>

<h2 id="operating-system-scheduler">Operating System Scheduler</h2>

<p>The one remaining thing that could cause IO operations to appear longer than they really are is the operating scheduler.
Unless you are running your application on dedicated hardware, and spawn no more than one Ruby process per core, then
it can happen that the operating system doesn’t immediately resume a process after it is done blocking on some IO.</p>

<p>I’m unfortunately not aware of a really good way to measure this.</p>

<p>The best I’ve found is <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/schedstat</code> on Linux:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cat /proc/1/schedstat</span>
40933713 1717706 178
</code></pre></div></div>

<p>The second number in that list is the amount of nanosecond the given process spent in the “runqueue”, in other words,
waiting to be assigned a CPU core so it can resume work.</p>

<p>But reading <code class="language-plaintext highlighter-rouge">/proc</code> around every IO would be a bit heavy-handed, so it’s not something I’ve ever integrated into an
application monitoring. Instead, we monitor it more globally on a per-machine basis as an indication that we’re running
too many processes in our containers.</p>

<h2 id="conclusion">Conclusion</h2>

<p>So while it’s very hard to measure exactly how long a particular IO operation took, there are a few general metrics
that can help you have a better pitcture of how much “thread stalling” your application is experiencing.</p>

<p>Also, I don’t keep a close eye on the various application performance monitoring services out there, but my hope when
adding these new APIs was that they would eventually integrate it in their offering. Not sure if some did already.</p>]]></content><author><name></name></author><category term="ruby" /><category term="performance" /><summary type="html"><![CDATA[Recent Ruby releases added some nice tools to better instrument applications]]></summary></entry><entry><title type="html">The Mythical IO-Bound Rails App</title><link href="https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html" rel="alternate" type="text/html" title="The Mythical IO-Bound Rails App" /><published>2025-01-23T10:17:51+00:00</published><updated>2025-01-23T10:17:51+00:00</updated><id>https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app</id><content type="html" xml:base="https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html"><![CDATA[<p>I want to write a post about <a href="https://rubygems.org/gems/pitchfork">Pitchfork</a>, explaining where it comes from, why it
is like it is, and how I see its future.
But before I can get to that, I think I need to explain a few things.</p>

<p>When the topic of Rails performance comes up, it is commonplace to hear that the database is the bottleneck,
so Rails applications are <a href="https://en.wikipedia.org/wiki/I/O_bound">IO-bound</a> anyway, hence Ruby performance doesn’t
matter that much, and all you need is a healthy dose of concurrency to make your service scale.</p>

<p>But how true is this in general?</p>

<h2 id="conflating-scale-and-performance">Conflating scale and performance</h2>

<p>First, it is true that when scaling a Rails application, the first major bottleneck you will encounter will generally
be the database.</p>

<p>Rails, like the overwhelming majority of modern web frameworks, is stateless, hence it is trivial to scale it
horizontally to handle as much load as you want.
As long as you can keep adding server capacity, Rails will keep scaling. It might not be the cheapest stack to scale,
but it will scale as well as any other stateless web framework.
To handle 10x more traffic, you need roughly 10x more server capacity, that’s simple and not what teams who need to
scale a Rails application will struggle with.</p>

<p>Relational databases, however, are much harder to scale. By default, you can’t scale them horizontally unless you
implement data sharding in some way, and depending on your
data model, it can sometimes be very challenging, so generally relational databases are initially scaled vertically,
meaning migrating to increasingly more powerful servers.
Vertical scaling allows you to scale pretty far, much farther than most Rails users will ever need, but the cost
increase won’t be linear, and if you are successful enough, it won’t be viable anymore and you’ll have to shard or use
another type of data store.</p>

<p>That’s what the database being the bottleneck means. Not that querying the database is slow, nor that it is the most significant factor in overall service latency, but that it’s the part of your infrastructure you’ll have to care about
the most when your service witnesses increasingly more usage.</p>

<p>That’s what a lot of public discourse gets wrong, they conflate scale and performance, or more precisely, throughput and latency.</p>

<p>Being able to scale means maintaining some level of service while serving more users with close-to-linear costs.
It doesn’t mean being particularly fast, cheap, or efficient, it simply means being able to grow without hitting a
bottleneck, and without costing you exponentially more money.</p>

<p>As such, the database being the bottleneck is true, but it doesn’t imply that the application is spending the majority
of its time waiting on IO.</p>

<h2 id="most-rails-performance-issues-are-database-issues">Most Rails performance issues are database issues</h2>

<p>Another fact that is often stated to explain how Rails applications are IO-bound,
is that the most common performance issues with Rails applications are missing database indexes, N+1 queries and other
data access issues.</p>

<p>From my personal observations, that definitely rings true, but these are bugs, not a given property of the system.
They’re supposed to be identified and fixed, as such, it doesn’t really make sense to design your infrastructure to
accomodate that characteristic.</p>

<p>When properly indexed, and assuming the database isn’t overloaded, the vast majority of queries, especially the mundane
lookups by primary key, take less than a couple of milliseconds, often just a fraction of a millisecond.
If the application does any substantial amount of transformations on that data to render it in HTML or JSON, it will
without a doubt spend as much or more time executing Ruby code than waiting for IOs.</p>

<h2 id="evidence-yjit-effectiveness">Evidence: YJIT effectiveness</h2>

<p>Now of course, every application is different, and I can only really speak with confidence about the ones I’ve worked on.</p>

<p>However, over the last couple of years, many people reported how YJIT reduced their application latency by 15 to 30%.
Like Discourse seeing a <a href="https://blog.discourse.org/2023/05/running-ruby-3-2s-yjit-in-production-at-discourse/">15.8-19.6% speedup with JIT 3.2</a>,
<a href="https://lobste.rs/s/m9ivcf/we_turned_lobste_rs_into_rails_benchmark#c_fkud5w">Lobsters seeing a 26% speedup</a>,
<a href="https://xcancel.com/dhh/status/1711422643256303867">Basecamp and Hey seeing a 26% speedup</a>
or <a href="https://railsatscale.com/2025-01-10-yjit-3-4-even-faster-and-more-memory-efficient/">Shopify’s Storefront Renderer app seeing a 17% speedup</a>.</p>

<p>If these applications were really spending the overwhelming majority of their time waiting on IO, it would be impossible
for YJIT to perform this well overall.</p>

<p>Even on very JIT-friendly benchmarks with no IO at all, YJIT <em>only</em> speeds up Ruby by 2 or 3x.
On more realistic benchmarks like <code class="language-plaintext highlighter-rouge">lobsters</code>, it’s more around 1.7x.
Based on this, we can assume with fairly good confidence that all these applications are certainly not spending 80%
of their time waiting on IO.</p>

<p>To me, that’s enough to consider that most Rails applications aren’t IO-bound.
Some applications out there most definitely are IO-bound, and I spoke with a few people maintaining such applications.
But just like flying fishes, they exist, yet they don’t constitute the majority of the genus.</p>

<h2 id="cpu-starvation-looks-like-io-to-most-eyes">CPU starvation looks like IO to most eyes</h2>

<p>One thing that can cause people to overestimate how much IO their app is doing is that, in most cases, CPU starvation
will look like Ruby is waiting on IO.</p>

<p>If you look at how the overwhelming majority of IO durations are measured, including in Rails logs and in all the
most popular application performance managers, it’s generally done in a very simple, obvious way:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="no">Time</span><span class="p">.</span><span class="nf">now</span>
<span class="n">database_connection</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="s2">"SELECT ..."</span><span class="p">)</span>
<span class="n">query_duration</span> <span class="o">=</span> <span class="p">(</span><span class="no">Time</span><span class="p">.</span><span class="nf">now</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1000.0</span>
<span class="nb">puts</span> <span class="s2">"Query took: </span><span class="si">#{</span><span class="n">query_duration</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">ms"</span>
</code></pre></div></div>

<p>Logically, if this code logs: <code class="language-plaintext highlighter-rouge">Query took: 20.0ms</code>, you might legitimately think it took 20 milliseconds to perform
the SQL query, but that’s not necessarily true.</p>

<p>It actually means that performing the query <strong>and</strong> getting the thread scheduled again took 20 milliseconds, and you
cannot possibly tell how much each part took individually (Edit: At John Duff’s request, I wrote <a href="/ruby/performance/2025/01/23/io-instrumentation.html">a very quick guide
on how you can tell if your application is experiencing some form of CPU starvation</a>).</p>

<p>So for all you know, the query might have been performed in under a millisecond, and all the remaining time was spent
waiting to acquire the GVL, running GC, or waiting for the operating system scheduler to resume your process.</p>

<p>Knowing which is which is crucial:</p>

<ul>
  <li>If all this time was spent performing the query, it suggests that your application is IO-heavy and that you may be
able to use more concurrency (processes, threads, or fibers) to get some extra throughput.</li>
  <li>If all this time was spent waiting on the scheduler, then you might want to do the absolute opposite and use
less concurrency to reduce latency.</li>
</ul>

<p>This issue can often lead people to believe their application is more IO-heavy than it really is, and it’s
particularly vicious because it’s a self-fulfilling prophecy.
If you assume your application is IO-bound, given that it is commonplace to hear so, you’ll logically run it in
production with a threaded or async server using a decent amount of concurrency,
and production logs will confirm your assumption by showing large amounts of time waiting on IO.</p>

<p>This problem is even more common on shared hosting platforms because they don’t always guarantee that you can use
the “virtual CPU” at 100%. On these platforms, your application has to share the physical CPU cores with other
applications, and depending on what these other applications are doing and how busy they are, you may be able to use
substantially more or substantially less than the one “virtual CPU” you are paying for.</p>

<p>This issue is not unique to Ruby, whenever you have a workload that mixes IO and CPU work, you have to arbitrate
between allowing more concurrency and risk degrading latency, or reducing concurrency to ensure a low latency but
decrease utilization.
The more heterogeneous your workload is, as typical in a monolith, the harder it is to find the best compromise.
That’s one of the benefits of micro-services, getting more homogenous workloads, making it easier to achieve
higher server utilization without impacting latency too much.</p>

<p>However, given that the default implementation of Ruby has a GVL, this problem is even more pronounced.
Instead of all threads on the server having to share all CPU cores, you end up with multiple small buckets of threads
that each have to share one CPU, hence you can end up with threads that can’t be resumed even though there are some
free cores or the server.</p>

<p>The thing to keep in mind is that, as a general rule that doesn’t only apply to Ruby, CPU-bound and IO-bound work
loads don’t mix well, and should ideally be handled by distinct systems.
For small projects, you can likely tolerate the latency impact of collocating all your workloads in a one-size-fits-all
system, but as you scale you will increasingly need to segregate IO-intensive workloads from CPU-intensive ones.</p>

<h2 id="job-queues-are-different">Job Queues Are Different</h2>

<p>One important thing to note is that what I’m saying above is only aimed at the web server part of Rails applications.
Most apps also use a background job runner, Sidekiq being the most popular, and background jobs often take care of
lots of slow IO operations, such as sending e-mails, performing API calls, etc.</p>

<p>As such job runners are generally much more IO intensive, and latency is generally a bit less important for them,
so they usually can get away with higher concurrency than web servers.</p>

<p>But even then, it’s common for users to crank their job runner concurrency too high and cause all IOs to appear much slower.
A good example of that is how <a href="https://github.com/redis/hiredis-rb/issues/74">Sidekiq’s maintainer asked me to implement a way to measure the round trip delay in C
so that it’s not skewed by GVL contention</a>.</p>

<h2 id="why-does-it-matter">Why does it matter?</h2>

<p>At that point, you might wonder why it matters how much time Rails applications spend waiting on IO.</p>

<p>For the average Rails user, it is important to know this, because it is what defines which execution model is best
suited to deploy their application:</p>

<ul>
  <li>If an application is truly IO-bound, as in spending more than 95% of its time waiting for IO, then using an
asynchronous execution model is likely what will get you the best results.</li>
  <li>If an application isn’t fully IO-bound, but still is quite IO-heavy, then using a threaded server, with a
reasonable number of threads per process, is probably what will get you the best tradeoff between latency and
throughput.</li>
  <li>If an application doesn’t spend significantly more than half its time on IO, then it might be preferable to use a
purely process-based solution.</li>
</ul>

<p>What the ratio of IO to CPU is likely to be like in an average Rails app is also what drove <a href="https://github.com/rails/rails/issues/50450">Rails to change the
default generated Puma configuration from 5 threads to only 3</a>.</p>

<p>But also for the Ruby community at large, I think it’s important not to disregard Ruby’s performance under the pretext
that it doesn’t matter since it’s all about the database anyway.
This isn’t to say that Ruby is slow, it is without a doubt more than fast enough for writing web applications that
provide a good user experience.</p>

<p>But it is also possible to write Ruby code in a way that doesn’t perform well at all, be it for the sake of usability
or just because it’s fun to use meta-programing or that no one took the time to use a profiler to see if it is possible
to do the same thing more efficiently.</p>

<p>As someone who spends a considerable amount of time looking at production profiles of Rails applications, I can say
with confidence, there are a number of things in Rails and other commonly used gems that could be significantly faster,
but can’t because their public API prevents any further optimization.</p>

<p>As Ruby developers, we naturally have the tendency to put developer happiness first, which is great, but we should also
make sure not to disregard performance. Usability and performance don’t have to be mutually exclusive.
APIs can be both very convenient and performant, but both have to be considered right from the start for it to happen.
Once a public API has been defined and is widely used, there’s only so much you can do to make it perform faster
unless you are willing to deprecate it in favor of a more performant one, but the community appetite for deprecations
and breaking change is no longer what it used to be.</p>]]></content><author><name></name></author><category term="ruby" /><category term="performance" /><summary type="html"><![CDATA[When the topic of Rails performance comes up, it is commonplace to hear that the database is the bottleneck, so Rails applications are IO-bound anyway, hence Ruby performance doesn't matter that much, and all you need is a healthy dose of concurrency to make your service scale. But how true is this in general?]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 7</title><link href="https://byroot.github.io/ruby/json/2025/01/14/optimizing-ruby-json-part-7.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 7" /><published>2025-01-14T21:28:51+00:00</published><updated>2025-01-14T21:28:51+00:00</updated><id>https://byroot.github.io/ruby/json/2025/01/14/optimizing-ruby-json-part-7</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2025/01/14/optimizing-ruby-json-part-7.html"><![CDATA[<p>In <a href="/ruby/json/2025/01/12/optimizing-ruby-json-part-6.html">the previous post</a>, we started covering some parser optimizations.
There’s just a handful more to cover until we reached what’s the state of the currently released version of <code class="language-plaintext highlighter-rouge">ruby/json</code>.</p>

<h2 id="batch-apis">Batch APIs</h2>

<p>But as always, let’s start with a flame graph of <code class="language-plaintext highlighter-rouge">twitter.json</code>, to see what was left to optimize:</p>

<p><img src="/assets/articles/json-7/flamegraph-twitter.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4gRJXjb">Full profile</a>.</p>

<p>Something that was bothering me in that profile, was the whopping <code class="language-plaintext highlighter-rouge">26.6%</code> of time spent in <code class="language-plaintext highlighter-rouge">rb_hash_aset</code>,
which is the C API for <code class="language-plaintext highlighter-rouge">Hash#[]=</code>.</p>

<p>It wasn’t really surprising to me though. I’m sure you’ve heard about some super fast JSON parsers like <code class="language-plaintext highlighter-rouge">simdjson</code>, <code class="language-plaintext highlighter-rouge">rapidJSON</code> etc,
Some of you may have wondered why I didn’t just do a binding of one of these to make <code class="language-plaintext highlighter-rouge">ruby/json</code> faster.
Aside from many technical and legal restrictions, a big reason is that actually parsing JSON isn’t that much of a bottleneck,
even the fairly naive Ragel parser in <code class="language-plaintext highlighter-rouge">ruby/json</code> isn’t that slow (It could be way better though, but more on that later).</p>

<p>No, the really expansive part is building the Ruby objects tree, as evidenced by the time spent in <code class="language-plaintext highlighter-rouge">rb_hash_aset</code> on that
flame graph, but also in <code class="language-plaintext highlighter-rouge">rb_ary_push</code> on benchmarks that use a lot of arrays. So a custom parser can potentially end up faster
overall by being better tailored to make efficient use of Ruby APIs, such as how we do unescaping inside Ruby strings to avoid
extra copies and cache string keys.</p>

<p>But let’s focus on that part of the flame graph to see why <code class="language-plaintext highlighter-rouge">rb_hash_aset</code> is slow, and what we could do about it:</p>

<p><img src="/assets/articles/json-7/flamegraph-hash-aset.png" alt="" /></p>

<p>I want to draw your attention to two things in this flame graph.</p>

<p>The first is <code class="language-plaintext highlighter-rouge">ar_force_convert_table</code> on the left. You may have noticed that many functions in the graphs are prefixed with
<code class="language-plaintext highlighter-rouge">st_</code> or <code class="language-plaintext highlighter-rouge">rb_st</code> and a few with <code class="language-plaintext highlighter-rouge">ar_</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">st_</code> ones are referring to <a href="https://github.com/ruby/ruby/blob/23fc0fc22d0f066938387f3397fb8ee9358744e5/st.c"><code class="language-plaintext highlighter-rouge">st.c</code>, Ruby’s internal Hash Table implementation</a>.
What the <code class="language-plaintext highlighter-rouge">st</code> name stands for however I don’t know. <code class="language-plaintext highlighter-rouge">st.c</code> is a relatively well-optimized hash table that evolved over the years,
which is to be expected given how much Ruby relies on hash tables, even a modest performance gain in that data structure can have a
big impact overall. You can read its preamble if you want more details.</p>

<p>As for <code class="language-plaintext highlighter-rouge">ar_</code>, which I believe stands for “array”, refers to an optimization Ruby hashes do under the hood.
Hash tables are great, and offer a good access performance when the dataset is large, but when it’s very small they use quite a
lot of memory and aren’t really any better than a linear search. And Ruby code uses a lot of very small hash tables.</p>

<p>So Ruby hashes have an internal limit, <a href="https://github.com/ruby/ruby/blob/23fc0fc22d0f066938387f3397fb8ee9358744e5/internal/hash.h#L17C9-L17C32"><code class="language-plaintext highlighter-rouge">RHASH_AR_TABLE_MAX_SIZE</code></a>,
which on 64-bit platforms is <code class="language-plaintext highlighter-rouge">8</code>. Any Ruby Hash that contains <code class="language-plaintext highlighter-rouge">8</code> or fewer entries is actually lying to you, and is just an array
in a trenchcoat. That’s what <code class="language-plaintext highlighter-rouge">ar_table</code> is, a simple array of key and value pairs being used as an associative array.
And yes, its algorithmic complexity is technically <code class="language-plaintext highlighter-rouge">O(n)</code>, but with such a small <code class="language-plaintext highlighter-rouge">n</code>, it often is faster than doing all the hashing.</p>

<p>And if you add enough items in a Hash backed by an <code class="language-plaintext highlighter-rouge">ar_table</code>, it will be converted automatically to a <code class="language-plaintext highlighter-rouge">st_table</code>. That’s what
the <code class="language-plaintext highlighter-rouge">ar_force_convert_table</code> function does.</p>

<p>You can somewhat see this using one of my favorite APIs, <code class="language-plaintext highlighter-rouge">ObjectSpace.dump</code>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">require</span> <span class="s2">"objspace"</span>
<span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">ObjectSpace</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="mi">8</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">to_h</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="p">})</span>
<span class="p">{</span><span class="s2">"address"</span><span class="ss">:"0xf3d8"</span><span class="p">,</span> <span class="s2">"type"</span><span class="ss">:"HASH"</span><span class="p">,</span> <span class="s2">"slot_size"</span><span class="p">:</span><span class="mi">160</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="s2">"memsize"</span><span class="p">:</span><span class="mi">160</span><span class="p">,</span> <span class="o">...</span><span class="p">}</span></code></pre></figure>

<p>This tells us a Hash with 8 keys fits neatly in a 160B object slot. Each object reference is 8B, 2 references per entry,
<code class="language-plaintext highlighter-rouge">16 * 8 =&gt; 128</code>, so with a few extra metadata and perhaps a bit of wasted space, it checks out.</p>

<p>But if we do the same with a Hash with <code class="language-plaintext highlighter-rouge">9</code> items, the result is very different:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">ObjectSpace</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="mi">9</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">to_h</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="p">})</span>
<span class="p">{</span><span class="s2">"address"</span><span class="ss">:"0x1230"</span><span class="p">,</span> <span class="s2">"type"</span><span class="ss">:"HASH"</span><span class="p">,</span> <span class="s2">"slot_size"</span><span class="p">:</span><span class="mi">160</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="s2">"memsize"</span><span class="p">:</span><span class="mi">544</span><span class="p">,</span> <span class="o">...</span><span class="p">}</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">544B</code>, that’s a big jump, but not so surprising. Hash tables almost by definition need to be somewhat large to not collide too much.</p>

<p>The other function on the flame graph I’d like to point out is <code class="language-plaintext highlighter-rouge">rebuild_table_if_necessary</code>, which stems from the same concern,
when you append to a Hash table, and it starts to get a bit too full, you have to increase its size, and contrary to an array,
it’s not just a matter of calling <code class="language-plaintext highlighter-rouge">realloc</code>, you have to essentially allocate a larger table, and then re-insert all the pairs
which means hashing the keys again, and that’s costly.</p>

<p>The problem though, is that exactly what we’re doing. When we encounter the start of a JSON object (<code class="language-plaintext highlighter-rouge">{</code>), we allocate a Ruby
Hash with <code class="language-plaintext highlighter-rouge">rb_hash_new</code>, and then every time we’re done parsing a key-value pair, we call <code class="language-plaintext highlighter-rouge">rb_hash_aset</code> to append to the hash.</p>

<p>So if a JSON document contains an object with 30 keys, we first allocate an <code class="language-plaintext highlighter-rouge">ar_table</code> with a capacity of <code class="language-plaintext highlighter-rouge">8</code> pairs, get it rebuilt
as a <code class="language-plaintext highlighter-rouge">st_table</code> that can hold <code class="language-plaintext highlighter-rouge">16</code> entries, and finally a third time with <code class="language-plaintext highlighter-rouge">32</code> entries. Meaning we’re hashing every key 3 times,
and wasting time in <code class="language-plaintext highlighter-rouge">malloc</code> and <code class="language-plaintext highlighter-rouge">free</code>.</p>

<p>When parsing a format like <code class="language-plaintext highlighter-rouge">msgpack</code>, or Ruby’s Marshal, the byte that signals the start of a Hash is followed by the expected
size of the Hash, allowing you to pre-allocate it with the right size, which helps a lot.
But JSON doesn’t have that, we have no choice but to parse as we go, and we’ll only know how big the Hash is once we’re done
parsing it.</p>

<p>The problem is the same with large arrays, they start embedded, and then double in size every time they run out of space, it’s just
not quite as bad because at least we don’t hash to re-hash the keys.</p>

<p>But looking at the flame graph above, we can see that all this resizing is a majority of the time spent in <code class="language-plaintext highlighter-rouge">rb_hash_aset</code>, and
<code class="language-plaintext highlighter-rouge">rb_hash_aset</code> over a quarter of the overall time, so there was really a big opportunity here.</p>

<p>If it’s a bad idea to directly append to a Hash before we know how large it will be, why don’t we just wait to be done parsing it
before we build it? Basic.</p>

<p>But that means we need to store its content somewhere else in the meantime, and the ideal structure for that is a stack, which 
is just a fancy name for an array.</p>

<p>You can look at <a href="https://github.com/ruby/json/pull/678">the full patch in C</a>, but I’ll try to explain the key concept with some
Ruby code here.</p>

<p>Before the parsing code was something like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse_object</span>
  <span class="nb">hash</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">until</span> <span class="n">object_done?</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">parse_object_key</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">parse_json</span>
    <span class="nb">hash</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
  <span class="k">end</span>
  <span class="nb">hash</span>
<span class="k">end</span></code></pre></figure>

<p>We simply parse until we find the object terminator, and until then we append to the Hash whenever we get a complete pair,
and each parsing function simply returns the parsed object.</p>

<p>After the change it now looks more something like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse_object</span><span class="p">(</span><span class="n">stack</span><span class="p">)</span>
  <span class="n">previous_size</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">size</span>
  <span class="k">until</span> <span class="n">object_done?</span>
    <span class="n">stack</span> <span class="o">&lt;&lt;</span> <span class="n">parse_object_key</span>
    <span class="n">stack</span> <span class="o">&lt;&lt;</span> <span class="n">parse_json</span>
  <span class="k">end</span>
  <span class="nb">hash</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="n">stack</span><span class="p">.</span><span class="nf">size</span> <span class="o">-</span> <span class="n">previous_size</span><span class="p">).</span><span class="nf">to_h</span>
  <span class="n">stack</span> <span class="o">&lt;&lt;</span> <span class="nb">hash</span>
  <span class="nb">hash</span>
<span class="k">end</span></code></pre></figure>

<p>Every parse function now receives an array to use as the parsing stack, whatever they parse, they push on the stack.
The <code class="language-plaintext highlighter-rouge">parse_object</code> function is no exception, it first records how large the stack is, then it parses keys and values
and push them both on the stack.
Once the end of the object is found, all the pairs are popped from the back of the stack, and a hash is immediately created with
the right size, ensuring each key is only hashed once.</p>

<p>In C, it looks like this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">    <span class="kt">long</span> <span class="n">count</span> <span class="o">=</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">stack</span><span class="o">-&gt;</span><span class="n">head</span> <span class="o">-</span> <span class="n">stack_head</span><span class="p">;</span>

    <span class="n">VALUE</span> <span class="n">hash</span><span class="p">;</span>
<span class="cp">#ifdef HAVE_RB_HASH_NEW_CAPA
</span>    <span class="n">hash</span> <span class="o">=</span> <span class="n">rb_hash_new_capa</span><span class="p">(</span><span class="n">count</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">);</span>
<span class="cp">#else
</span>    <span class="n">hash</span> <span class="o">=</span> <span class="n">rb_hash_new</span><span class="p">();</span>
<span class="cp">#endif
</span>    <span class="n">rb_hash_bulk_insert</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">rvalue_stack_peek</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">stack</span><span class="p">,</span> <span class="n">count</span><span class="p">),</span> <span class="n">hash</span><span class="p">);</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">hash</span><span class="p">;</span>
    <span class="n">rvalue_stack_pop</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">stack</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span></code></pre></figure>

<p>You should be able to recognize the pattern, we create a hash of the right size using the <code class="language-plaintext highlighter-rouge">rb_hash_new_capa</code> API,
which unfortunately we have to test for its existence because unfortunately <a href="https://bugs.ruby-lang.org/issues/18683">I only exposed it to C extensions a few years ago</a>.
Then we insert all pairs at once with <code class="language-plaintext highlighter-rouge">rb_hash_bulk_insert</code>.</p>

<p>And that’s it, with just that change, the <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark was sped up by <code class="language-plaintext highlighter-rouge">22%</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    90.000 i/100ms
Calculating -------------------------------------
               after    897.170 (± 0.4%) i/s    (1.11 ms/i) -      4.500k in   5.015857s

Comparison:
              before:      737.1 i/s
               after:      897.2 i/s - 1.22x  faster
</code></pre></div></div>

<h2 id="avoid-double-scanning">Avoid Double Scanning</h2>

<p>After the value stack patch was so effective, <code class="language-plaintext highlighter-rouge">json_string_unescape</code> was back to being the biggest bottleneck at <code class="language-plaintext highlighter-rouge">22%</code> of total runtime:</p>

<p><img src="/assets/articles/json-7/flamegraph-str-unescape.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4hfnvjD">Full profile</a>.</p>

<p>I had recently optimized it by optimistically assuming most strings don’t contain any escape character, but something still<br />
bothered me. The Ragel parser calls our <code class="language-plaintext highlighter-rouge">JSON_parse_string</code> callback with both the start and end pointer of the string, to do
that it has to scan the string, so it’s a bit silly that the first thing we immediately do right after that is to scan it all over
again.</p>

<p>It would be way better if while it is looking for the end of the string, the Ragel parser would record if it had seen any
backslash, and if not, we’d save on re-scanning it again.</p>

<p>Here’s how the JSON strings grammar was defined:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="o">%%</span><span class="p">{</span>
    <span class="n">machine</span> <span class="n">JSON_string</span><span class="p">;</span>
    <span class="n">include</span> <span class="n">JSON_common</span><span class="p">;</span>

    <span class="n">write</span> <span class="n">data</span><span class="p">;</span>

    <span class="n">action</span> <span class="n">parse_string</span> <span class="p">{</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">json_string_unescape</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">||</span> <span class="n">json</span><span class="o">-&gt;</span> <span class="n">freeze</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">&amp;&amp;</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">symbolize_names</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="o">*</span><span class="n">result</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fhold</span><span class="p">;</span>
            <span class="n">fbreak</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">fexec</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">action</span> <span class="n">exit</span> <span class="p">{</span> <span class="n">fhold</span><span class="p">;</span> <span class="n">fbreak</span><span class="p">;</span> <span class="p">}</span>

    <span class="n">main</span> <span class="o">:=</span> <span class="sc">'"'</span> <span class="p">((</span><span class="o">^</span><span class="p">([</span><span class="err">\</span><span class="s">"</span><span class="se">\\</span><span class="s">] | 0..0x1f) | '</span><span class="se">\\</span><span class="s">'[</span><span class="se">\"\\</span><span class="s">/bfnrt] | '</span><span class="se">\\</span><span class="s">u'[0-9a-fA-F]{4} | '</span><span class="se">\\</span><span class="s">'^([</span><span class="se">\"\\</span><span class="s">/bfnrtu]|0..0x1f))* %parse_string) '"</span><span class="err">'</span> <span class="err">@</span><span class="n">exit</span><span class="p">;</span>
<span class="p">}</span><span class="o">%%</span></code></pre></figure>

<p>If you don’t understand it, don’t worry, me neither.</p>

<p>That’s where I kinda need to confess that I don’t have a proper computer science education, more some sort of very applied
software engineering curriculum, and not a particularly good one, so terms like “formal grammar” and parser generators like Ragel
et al kind of fly over my head, hence I’m kinda struggling to improve the core parsing parts. And I also can’t rely on
my usual tricks to work with things I don’t fully grasp because Ragel outputs absolutely disgusting code with lots of <code class="language-plaintext highlighter-rouge">goto</code>,
which makes it super hard to learn by experimentation.</p>

<p>Yet, even with my limited understanding, I can say something is really off here.
We can see on the last line that we’re basically instructing Ragel about all the possible escape sequences inside a JSON string,
which to me doesn’t make much sense. All we need the parser to do for us is to know enough to find the end of the string, 
tell us it ran into the end of the stream without finding it, or if it ran into an invalid character (e.g. a newline).</p>

<p>It absolutely doesn’t need to validate that <code class="language-plaintext highlighter-rouge">\u</code> is followed by 4 hexadecimal characters, we can do that during unescaping.</p>

<p>But anyway, this is for strings with escape sequences, and we don’t have that many of those, I had to figure out a way
to have a fast path for simple strings, and after a few hours of struggling and begging some properly educated people for help
I managed to get this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="o">%%</span><span class="p">{</span>
    <span class="n">machine</span> <span class="n">JSON_string</span><span class="p">;</span>
    <span class="n">include</span> <span class="n">JSON_common</span><span class="p">;</span>

    <span class="n">write</span> <span class="n">data</span><span class="p">;</span>

    <span class="n">action</span> <span class="n">parse_complex_string</span> <span class="p">{</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">json_string_unescape</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">||</span> <span class="n">json</span><span class="o">-&gt;</span> <span class="n">freeze</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">&amp;&amp;</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">symbolize_names</span><span class="p">);</span>
        <span class="n">fexec</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">fhold</span><span class="p">;</span>
        <span class="n">fbreak</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">action</span> <span class="n">parse_simple_string</span> <span class="p">{</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">json_string_fastpath</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">||</span> <span class="n">json</span><span class="o">-&gt;</span> <span class="n">freeze</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">parsing_name</span> <span class="o">&amp;&amp;</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">symbolize_names</span><span class="p">);</span>
        <span class="n">fexec</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">fhold</span><span class="p">;</span>
        <span class="n">fbreak</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">double_quote</span> <span class="o">=</span> <span class="sc">'"'</span><span class="p">;</span>
    <span class="n">escape</span> <span class="o">=</span> <span class="sc">'\\'</span><span class="p">;</span>
    <span class="n">control</span> <span class="o">=</span> <span class="mi">0</span><span class="p">..</span><span class="mh">0x1f</span><span class="p">;</span>
    <span class="n">simple</span> <span class="o">=</span> <span class="n">any</span> <span class="o">-</span> <span class="n">escape</span> <span class="o">-</span> <span class="n">double_quote</span> <span class="o">-</span> <span class="n">control</span><span class="p">;</span>

    <span class="n">main</span> <span class="o">:=</span> <span class="n">double_quote</span> <span class="p">(</span>
         <span class="p">(</span><span class="n">simple</span><span class="o">*</span><span class="p">)(</span>
            <span class="p">(</span><span class="n">double_quote</span><span class="p">)</span> <span class="err">@</span><span class="n">parse_simple_string</span> <span class="o">|</span>
            <span class="p">((</span><span class="o">^</span><span class="p">([</span><span class="err">\</span><span class="s">"</span><span class="se">\\</span><span class="s">] | control) | escape[</span><span class="se">\"\\</span><span class="s">/bfnrt] | '</span><span class="se">\\</span><span class="s">u'[0-9a-fA-F]{4} | escape^([</span><span class="se">\"\\</span><span class="s">/bfnrtu]|0..0x1f))* double_quote) @parse_complex_string</span><span class="err">
</span><span class="s">         )</span><span class="err">
</span><span class="s">    );</span><span class="err">
</span><span class="s">}%%</span></code></pre></figure>

<p>The idea is simple, start by only looking for a double quote not preceded by any backslash, that’s the optimistic path, and if it
matches we enter <code class="language-plaintext highlighter-rouge">parse_simple_string</code>. If it doesn’t, we fall back to the previous pattern and end up in <code class="language-plaintext highlighter-rouge">parse_complex_string</code>.</p>

<p>The fast path is a much simpler function:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">json_string_fastpath</span><span class="p">(</span><span class="n">JSON_Parser</span> <span class="o">*</span><span class="n">json</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">string</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">stringEnd</span><span class="p">,</span> <span class="n">bool</span> <span class="n">is_name</span><span class="p">,</span> <span class="n">bool</span> <span class="n">intern</span><span class="p">,</span> <span class="n">bool</span> <span class="n">symbolize</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">size_t</span> <span class="n">bufferSize</span> <span class="o">=</span> <span class="n">stringEnd</span> <span class="o">-</span> <span class="n">string</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">is_name</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">VALUE</span> <span class="n">cached_key</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">symbolize</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">cached_key</span> <span class="o">=</span> <span class="n">rsymbol_cache_fetch</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">name_cache</span><span class="p">,</span> <span class="n">string</span><span class="p">,</span> <span class="n">bufferSize</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">cached_key</span> <span class="o">=</span> <span class="n">rstring_cache_fetch</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">name_cache</span><span class="p">,</span> <span class="n">string</span><span class="p">,</span> <span class="n">bufferSize</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">RB_LIKELY</span><span class="p">(</span><span class="n">cached_key</span><span class="p">))</span> <span class="p">{</span>
            <span class="k">return</span> <span class="n">cached_key</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">build_string</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="n">stringEnd</span><span class="p">,</span> <span class="n">intern</span><span class="p">,</span> <span class="n">symbolize</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>Nothing particularly fancy. Unfortunately the impact on <code class="language-plaintext highlighter-rouge">twitter.json</code> wasn’t that big:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    91.000 i/100ms
Calculating -------------------------------------
               after    913.740 (± 0.3%) i/s    (1.09 ms/i) -      4.641k in   5.079191s

Comparison:
              before:      886.9 i/s
               after:      913.7 i/s - 1.03x  faster
</code></pre></div></div>

<p>I was a bit disappointed, but still, I progressed a bit in my understanding of Ragel and knew there was
lots of fishy things in <code class="language-plaintext highlighter-rouge">ruby/json</code>’s Ragel parser, so that would be useful.</p>

<h2 id="avoid-useless-copies">Avoid Useless Copies</h2>

<p>After that disappointment, I needed a bit of a break, so I went back to a function where I knew I could get better
results on, integer parsing.</p>

<p>I didn’t have a micro-benchmark dedicated to integers, but the small array one would do:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_parsing</span> <span class="s2">"small nested array"</span><span class="p">,</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]]</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span></code></pre></figure>

<p>So 10 arrays, with 5 integers each, quite simple.</p>

<p>And you know the drill, it started with some profiling.</p>

<p><img src="/assets/articles/json-7/flamegraph-integer.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4jeyFXA">Full profile</a>.</p>

<p>As <a href="/ruby/json/2025/01/12/optimizing-ruby-json-part-6.html#more-stack-allocation">we mentioned in the previous part</a>,
<code class="language-plaintext highlighter-rouge">rb_cstr2inum</code>, the API Ruby gives us to turn a C string into a Ruby Integer, isn’t very efficient.</p>

<p>First, because it expects a C string, it forces us to first copy the string into a buffer so we can append a <code class="language-plaintext highlighter-rouge">NULL</code> to it,
but also because it has to deal with quite a lot of cases we don’t care about, such as a variable base. For instance <code class="language-plaintext highlighter-rouge">0xff</code> is a
valid number for <code class="language-plaintext highlighter-rouge">rb_cstr2inum</code>, but not for JSON. It also has to support arbitrary long integers, which slows it down, but the
overwhelming majority of the numbers we parse fit in 64 bits.</p>

<p>So we have an opportunity here for another fast path type of function, that would deal with the crux of integer parsing, and
for the rare and complex cases, continue to rely on <code class="language-plaintext highlighter-rouge">rb_cstr2inum</code>.</p>

<p>The implementation is very straightforward, you can see <a href="https://github.com/ruby/json/pull/692">the full patch</a>,
but I’ll detail the key parts:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="n">VALUE</span> <span class="nf">fast_parse_integer</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pe</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">bool</span> <span class="n">negative</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">p</span> <span class="o">==</span> <span class="sc">'-'</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">negative</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
        <span class="n">p</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kt">long</span> <span class="kt">long</span> <span class="n">memo</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">p</span> <span class="o">&lt;</span> <span class="n">pe</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">memo</span> <span class="o">*=</span> <span class="mi">10</span><span class="p">;</span>
        <span class="n">memo</span> <span class="o">+=</span> <span class="o">*</span><span class="n">p</span> <span class="o">-</span> <span class="sc">'0'</span><span class="p">;</span>
        <span class="n">p</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">negative</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">memo</span> <span class="o">=</span> <span class="o">-</span><span class="n">memo</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">LL2NUM</span><span class="p">(</span><span class="n">memo</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>We start by checking if the number is negative, then convert ASCII characters into the corresponding integer one by one.</p>

<p>The limitation, however, is that this can only work for an integer that fits in a native integer type, as such we only enter
this fast path if the number of digits is low enough:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define MAX_FAST_INTEGER_SIZE 18
</span>
<span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">RB_LIKELY</span><span class="p">(</span><span class="n">len</span> <span class="o">&lt;</span> <span class="n">MAX_FAST_INTEGER_SIZE</span><span class="p">))</span> <span class="p">{</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">fast_parse_integer</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">fbuffer_clear</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">,</span> <span class="sc">'\0'</span><span class="p">);</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_cstr2inum</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="o">&amp;</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">),</span> <span class="mi">10</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>Why 18? Because regardless of the CPU architecture, <a href="https://en.wikibooks.org/wiki/C_Programming/limits.h#Member_constants">in C a <code class="language-plaintext highlighter-rouge">long long</code> must support a maximum value of <code class="language-plaintext highlighter-rouge">9,223,372,036,854,775,807</code>
and a minimum value of <code class="language-plaintext highlighter-rouge">−9,223,372,036,854,775,808</code></a>, in other words, it’s always a 64-bit integer.
That’s 19 digits, but there are some 19-digit numbers that don’t fit in a <code class="language-plaintext highlighter-rouge">long long</code>, so 18.</p>

<p>It would be possible to handle slightly bigger numbers by using an <code class="language-plaintext highlighter-rouge">unsigned long long</code>, but I didn’t think it was worth it.</p>

<p>As for the impact on the micro-benchmark, it was pretty good:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing small nested array (121 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   124.666k i/100ms
Calculating -------------------------------------
               after      1.258M (± 2.3%) i/s  (794.63 ns/i) -      6.358M in   5.055135s

Comparison:
              before:   816626.3 i/s
               after:  1258454.3 i/s - 1.54x  faster
</code></pre></div></div>

<p>But that’s a micro-benchmark of course, here’s the effect on more realistic ones:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    92.000 i/100ms
Calculating -------------------------------------
               after    939.320 (± 1.0%) i/s    (1.06 ms/i) -      4.784k in   5.093485s

Comparison:
              before:      875.5 i/s
               after:      939.3 i/s - 1.07x  faster


== Parsing citm_catalog.json (1727030 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    43.000 i/100ms
Calculating -------------------------------------
               after    430.366 (± 0.9%) i/s    (2.32 ms/i) -      2.193k in   5.096015s

Comparison:
              before:      388.8 i/s
               after:      430.4 i/s - 1.11x  faster
</code></pre></div></div>

<h2 id="avoid-duplicated-work">Avoid Duplicated Work</h2>

<p>The final parser optimization that shipped with <code class="language-plaintext highlighter-rouge">json 2.9.0</code>, was submitted by <a href="https://github.com/tenderlove">Aaron Patterson</a>.
I’m not too sure how he got to work on it, perhaps he was attracted by the smell of blood when he saw me cursing
against Ragel in our company Slack, who knows?</p>

<p>The key element of Aaron’s patch is that he changed this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">np</span> <span class="o">=</span> <span class="n">JSON_parse_float</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">fpc</span><span class="p">,</span> <span class="n">pe</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span>
<span class="k">if</span> <span class="p">(</span><span class="n">np</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">fexec</span> <span class="n">np</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">np</span> <span class="o">=</span> <span class="n">JSON_parse_integer</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">fpc</span><span class="p">,</span> <span class="n">pe</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span></code></pre></figure>

<p>Into this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">np</span> <span class="o">=</span> <span class="n">JSON_parse_number</span><span class="p">(</span><span class="n">json</span><span class="p">,</span> <span class="n">fpc</span><span class="p">,</span> <span class="n">pe</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span></code></pre></figure>

<p>If it’s not yet obvious, the previous version of the parser would first try to parse a float, and if it failed to do so,
would try to parse an integer. This is quite wasteful, because all floats start with an integer, so whenever the next value to
parse was an integer, it would first be fully scanned by <code class="language-plaintext highlighter-rouge">JSON_parse_float</code> to figure out it’s not an integer, and then the parser
would backtrack and scan the same bytes again in <code class="language-plaintext highlighter-rouge">JSON_parse_integer</code>.</p>

<p>You can look at <a href="https://github.com/ruby/json/pull/698/">the full patch</a>, which also contains some changes to the grammar and
state machine to make the above change possible, but that really is the core of it.</p>

<p>And you might think it’s indeed more efficient, but probably not that big of a deal in the grand scheme of things, but actually
it did speedup <code class="language-plaintext highlighter-rouge">twitter.json</code> and <code class="language-plaintext highlighter-rouge">citm_catalog.json</code> by a nice <code class="language-plaintext highlighter-rouge">5%</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    95.000 i/100ms
Calculating -------------------------------------
               after    947.551 (± 0.9%) i/s    (1.06 ms/i) -      4.750k in   5.013354s

Comparison:
              before:      904.4 i/s
               after:      947.6 i/s - 1.05x  faster


== Parsing citm_catalog.json (1727030 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    45.000 i/100ms
Calculating -------------------------------------
               after    458.244 (± 0.2%) i/s    (2.18 ms/i) -      2.295k in   5.008296s

Comparison:
              before:      432.7 i/s
               after:      458.2 i/s - 1.06x  faster
</code></pre></div></div>

<h2 id="fin">Fin?</h2>

<p>And that’s it, that was the final optimization performed before I released <code class="language-plaintext highlighter-rouge">json 2.9.0</code>, so I will conclude this series.</p>

<p>If you wonder how fast it now is, here’s a final <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark against the competition:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                json    93.000 i/100ms
                  oj    66.000 i/100ms
          Oj::Parser    80.000 i/100ms
           rapidjson    58.000 i/100ms
Calculating -------------------------------------
                json    928.472 (± 0.3%) i/s    (1.08 ms/i) -      4.650k in   5.008282s
                  oj    666.198 (± 0.8%) i/s    (1.50 ms/i) -      3.366k in   5.052899s
          Oj::Parser    803.031 (± 0.2%) i/s    (1.25 ms/i) -      4.080k in   5.080788s
           rapidjson    584.869 (± 0.2%) i/s    (1.71 ms/i) -      2.958k in   5.057565s

Comparison:
                json:      928.5 i/s
          Oj::Parser:      803.0 i/s - 1.16x  slower
                  oj:      666.2 i/s - 1.39x  slower
           rapidjson:      584.9 i/s - 1.59x  slower
</code></pre></div></div>

<p>That isn’t to say I’m done optimizing, I have quite a few ideas for the future, but I wanted to stabilize the gem prior to the
release of Ruby 3.4.0, and I feel it is now fast enough that there’s no urgency.</p>

<p>But to give you an idea of what may happen in the future, I’d like to drop Ragel and replace it with a simpler recursive descent
parser. The existing one could certainly be improved, but I find it much harder to work with generated parsers than to write them
manually.</p>

<p>I’m also currently pairing with <a href="https://github.com/etiennebarrie">Étienne Barrié</a> on <a href="https://github.com/ruby/json/pull/718">a better API for both the parser and the encoder</a>
which would allow to reduce the setup cost even further, stop relying as much on global state, and would generally be more ergonomic.</p>

<p>I hope you enjoyed this blog series, I’ll try to continue writing, next, I’d like to share some thoughts on <a href="https://github.com/Shopify/pitchfork">Pitchfork</a>,
but I may need to set the stage for it with other posts to explain some key concepts.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, we started covering some parser optimizations. There’s just a handful more to cover until we reached what’s the state of the currently released version of ruby/json.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 6</title><link href="https://byroot.github.io/ruby/json/2025/01/12/optimizing-ruby-json-part-6.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 6" /><published>2025-01-12T16:28:51+00:00</published><updated>2025-01-12T16:28:51+00:00</updated><id>https://byroot.github.io/ruby/json/2025/01/12/optimizing-ruby-json-part-6</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2025/01/12/optimizing-ruby-json-part-6.html"><![CDATA[<p>After wrapping up about the encoder optimizations <a href="/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html">in the previous post</a>,
we can now start talking about the parser side.</p>

<p>It certainly won’t be as long, because the parser didn’t need as much work, but also because some optimizations, particularly
around setup costs were the same as the one applied to the encoder, so I will simply reference them quickly.</p>

<h2 id="efficient-hash-operations">Efficient Hash Operations</h2>

<p>When I took over the gem, there was a pull request by <a href="https://github.com/luke-gru">Luke Gruber</a> that had been sitting there for almost a year,
with <a href="https://github.com/ruby/json/pull/512">multiple parser initialization speedups</a>.</p>

<p><a href="https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html#gccct">I mentioned the first one in part two</a>,
the parser’s <code class="language-plaintext highlighter-rouge">#initialize</code> method was doing hash lookups in a very inefficient way by using <code class="language-plaintext highlighter-rouge">rb_funcall</code> to check if specific keys,
were present:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define option_given_p(opts, key) RTEST(rb_funcall(opts, i_key_p, 1, key))</span></code></pre></figure>

<p>I believe at one point using <code class="language-plaintext highlighter-rouge">rb_funcall</code> may have been necessary because <code class="language-plaintext highlighter-rouge">opts</code>, wasn’t always a real Hash,
but these days were long gone, so Luke was able to replace it with a much more efficient version:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">hash_has_key</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">hash</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">key</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">Qundef</span> <span class="o">==</span> <span class="n">rb_hash_lookup2</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">Qundef</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Qtrue</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">Qfalse</span><span class="p">;</span>
<span class="p">}</span>
<span class="cp">#define option_given_p(opts, key) (RTEST(hash_has_key(opts, key)))</span></code></pre></figure>

<p>It is much much better as it doesn’t have to go through method lookup and all that.
Instead, it uses <code class="language-plaintext highlighter-rouge">rb_hash_lookup2</code>, the C equivalent of <code class="language-plaintext highlighter-rouge">Hash#fetch</code>. If <code class="language-plaintext highlighter-rouge">key</code> exists in the hash, the associated value
is returned. If it doesn’t exist, what we provided as a third argument is returned to us.</p>

<p>And <code class="language-plaintext highlighter-rouge">Qundef</code> is a special Ruby value, similar to <code class="language-plaintext highlighter-rouge">undefined</code> in JavaScript, but only used inside the virtual machine.
Actual Ruby code can’t possibly interact with <code class="language-plaintext highlighter-rouge">Qundef</code>, it would literally cause a VM crash.
As such we know it’s not possible for the hash to contain <code class="language-plaintext highlighter-rouge">Qundef</code> and we can use it as our return value in case of a miss.</p>

<p>So translated in Ruby, it would be something like:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">UNDEF</span> <span class="o">=</span> <span class="no">BasicObject</span><span class="p">.</span><span class="nf">new</span>
<span class="n">private_constant</span> <span class="ss">:UNDEF</span>
<span class="k">def</span> <span class="nf">hash_has_key</span><span class="p">(</span><span class="nb">hash</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">hash</span><span class="p">.</span><span class="nf">fetch</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="no">UNDEF</span><span class="p">)</span> <span class="o">==</span> <span class="no">UNDEF</span>
    <span class="k">return</span> <span class="kp">true</span>
  <span class="k">end</span>
  <span class="kp">false</span>
<span class="k">end</span></code></pre></figure>

<p>At that point, you may have been screaming internally for a few paragraphs, searching for how to submit a pull request on my blog
to fix the typo, but no it’s not a typo, at least not on my part, the pull request indeed had the logic reversed.
I admit I only noticed it while writing this post.</p>

<p>But that’s not a problem, because even aside from that bug, it still was a bit more contrived than necessary.
For some reason, it returns a Ruby boolean (<code class="language-plaintext highlighter-rouge">Qfalse</code> and <code class="language-plaintext highlighter-rouge">Qtrue</code> are global references to Ruby’s <code class="language-plaintext highlighter-rouge">true</code> and <code class="language-plaintext highlighter-rouge">false</code>
immediate objects, defined in <a href="https://github.com/ruby/ruby/blob/335bba0fde0c0407377b6e10050ab6c2ad0d3270/include/ruby/internal/special_consts.h#L86-L120"><code class="language-plaintext highlighter-rouge">special_consts.h</code></a>).</p>

<p>Translated in decimal, it means we’re returning <code class="language-plaintext highlighter-rouge">0</code> when the key doesn’t exist, and <code class="language-plaintext highlighter-rouge">20</code> when it exists.
And then we use the <code class="language-plaintext highlighter-rouge">RTEST</code> macro, to check if the return value is <code class="language-plaintext highlighter-rouge">4</code> (<code class="language-plaintext highlighter-rouge">Qnil</code>), which is impossible, and if that’s the case we
turn that <code class="language-plaintext highlighter-rouge">4</code> into a <code class="language-plaintext highlighter-rouge">0</code>, otherwise we return the original number.</p>

<p>To be fair, modern CPUs and compilers can chew through that sort of overhead, making it barely measurable,
but it just felt wrong not to simplify it further.</p>

<p>Since the PR had to be rebased anyway, I simplified Luke’s version further to turn it into:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define option_given_p(opts, key) (rb_hash_lookup2(opts, key, Qundef) != Qundef)</span></code></pre></figure>

<h2 id="bail-out-early">Bail Out Early</h2>

<p>Another important optimization that was in Luke’s pull request, was inside the code responsible for parsing floating point numbers.</p>

<p><code class="language-plaintext highlighter-rouge">JSON.parse</code> has an option called <code class="language-plaintext highlighter-rouge">decimal_class</code>, which allows decimal numbers to be parsed into something other than <code class="language-plaintext highlighter-rouge">Float</code> objects,
typically into <code class="language-plaintext highlighter-rouge">BigDecimal</code> objects.</p>

<p>The float parsing code looked like this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">char</span> <span class="o">*</span><span class="nf">JSON_parse_float</span><span class="p">(</span><span class="n">JSON_Parser</span> <span class="o">*</span><span class="n">json</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">p</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pe</span><span class="p">,</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snipp...</span>

    <span class="n">VALUE</span> <span class="n">mod</span> <span class="o">=</span> <span class="n">Qnil</span><span class="p">;</span>
    <span class="n">ID</span> <span class="n">method_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">rb_respond_to</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_try_convert</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">;</span>
        <span class="n">method_id</span> <span class="o">=</span> <span class="n">i_try_convert</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">rb_respond_to</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_new</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">;</span>
        <span class="n">method_id</span> <span class="o">=</span> <span class="n">i_new</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">RB_TYPE_P</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">T_CLASS</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">VALUE</span> <span class="n">name</span> <span class="o">=</span> <span class="n">rb_class_name</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">);</span>
        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">name_cstr</span> <span class="o">=</span> <span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">name</span><span class="p">);</span>
        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">last_colon</span> <span class="o">=</span> <span class="n">strrchr</span><span class="p">(</span><span class="n">name_cstr</span><span class="p">,</span> <span class="sc">':'</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">last_colon</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">mod_path_end</span> <span class="o">=</span> <span class="n">last_colon</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
            <span class="n">VALUE</span> <span class="n">mod_path</span> <span class="o">=</span> <span class="n">rb_str_substr</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">mod_path_end</span> <span class="o">-</span> <span class="n">name_cstr</span><span class="p">);</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">rb_path_to_class</span><span class="p">(</span><span class="n">mod_path</span><span class="p">);</span>

            <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">method_name_beg</span> <span class="o">=</span> <span class="n">last_colon</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
            <span class="kt">long</span> <span class="n">before_len</span> <span class="o">=</span> <span class="n">method_name_beg</span> <span class="o">-</span> <span class="n">name_cstr</span><span class="p">;</span>
            <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">-</span> <span class="n">before_len</span><span class="p">;</span>
            <span class="n">VALUE</span> <span class="n">method_name</span> <span class="o">=</span> <span class="n">rb_str_substr</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">before_len</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
            <span class="n">method_id</span> <span class="o">=</span> <span class="n">SYM2ID</span><span class="p">(</span><span class="n">rb_str_intern</span><span class="p">(</span><span class="n">method_name</span><span class="p">));</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">rb_mKernel</span><span class="p">;</span>
            <span class="n">method_id</span> <span class="o">=</span> <span class="n">SYM2ID</span><span class="p">(</span><span class="n">rb_str_intern</span><span class="p">(</span><span class="n">name</span><span class="p">));</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="c1">// Actual float parsing starts here</span>
    <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span><span class="p">;</span>
    <span class="n">fbuffer_clear</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">,</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">memo</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">,</span> <span class="sc">'\0'</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">method_id</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">VALUE</span> <span class="n">text</span> <span class="o">=</span> <span class="n">rb_str_new2</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">));</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_funcallv</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">method_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">text</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">DBL2NUM</span><span class="p">(</span><span class="n">rb_cstr_to_dbl</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">),</span> <span class="mi">1</span><span class="p">));</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>Even if you are unfamiliar with C, with the comment I added you probably noticed that this routine has an insanely costly prelude.
We’re first checking if the <code class="language-plaintext highlighter-rouge">decimal_class</code> option responds to <code class="language-plaintext highlighter-rouge">try_convert</code>, then if it responds to <code class="language-plaintext highlighter-rouge">new</code>, and finally if it’s a <code class="language-plaintext highlighter-rouge">Class</code>
object. If you read part 2 of the series, you might remember that checking if an object responds to a method isn’t cheap.</p>

<p>But providing a custom class to handle decimal numbers is a niche option, certainly not the common case,
hence Luke’s patch rightfully wrapped all this <code class="language-plaintext highlighter-rouge">decimal_class</code> prelude into a cheap:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">jons</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">))</span> <span class="p">{</span>
  <span class="c1">// prelude</span>
<span class="p">}</span></code></pre></figure>

<p>To just bypass it all in the overwhelming majority of cases.</p>

<p>To be honest, the patch could have gone farther, as it really makes no sense for this code to be inside <code class="language-plaintext highlighter-rouge">JSON_parse_float</code>.
The <code class="language-plaintext highlighter-rouge">decimal_class</code> is provided when you instantiate the parser and isn’t ever going to change for the parser lifetime,
hence this argument parsing code should be in the constructor, not in a subroutine that will be called as many times as there are
decimal numbers in the parsed document.</p>

<p>As is often the case, this performance issue happened gradually.</p>

<p>In the early versions of the <code class="language-plaintext highlighter-rouge">json</code> gem, the check performed inside <code class="language-plaintext highlighter-rouge">JSON_parse_float</code> was a simple <code class="language-plaintext highlighter-rouge">nil</code> check:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">))</span> <span class="p">{</span>
  <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_float_new</span><span class="p">(</span><span class="n">rb_cstr_to_dbl</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">),</span> <span class="mi">1</span><span class="p">));</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="n">VALUE</span> <span class="n">text</span><span class="p">;</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">rb_str_new2</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">));</span>
  <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_funcall</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_new</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">text</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>Translated in Ruby it would be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">if</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">nil?</span>
  <span class="vi">@buffer</span><span class="p">.</span><span class="nf">to_f</span>
<span class="k">else</span>
  <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="vi">@buffer</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>So there was nothing to move to the constructor, it was as simple as a conditional as you could get.</p>

<p>But then over time the <code class="language-plaintext highlighter-rouge">BigDecimal</code> gem evolved, and <code class="language-plaintext highlighter-rouge">BigDecimal.new</code> was no longer a good way to instantiate these objects.
So in 2018, <a href="https://github.com/ruby/json/commit/ef2092f4d288ff666bcf10ffa43e58a91c649293">the maintainer of the <code class="language-plaintext highlighter-rouge">bigdecimal</code> gem submitted a patch to the <code class="language-plaintext highlighter-rouge">json</code> gem, to fix the deprecation warnings</a>,
and the check became a bit more complex, but still very reasonable:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">))</span> <span class="p">{</span>
  <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_float_new</span><span class="p">(</span><span class="n">rb_cstr_to_dbl</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">),</span> <span class="mi">1</span><span class="p">));</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="n">VALUE</span> <span class="n">text</span><span class="p">;</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">rb_str_new2</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">));</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">is_bigdecimal_class</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">))</span> <span class="p">{</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_funcall</span><span class="p">(</span><span class="n">Qnil</span><span class="p">,</span> <span class="n">i_BigDecimal</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">text</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_funcall</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_new</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">text</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>Again, in Ruby:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">if</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">nil?</span>
  <span class="vi">@buffer</span><span class="p">.</span><span class="nf">to_f</span>
<span class="k">elsif</span> <span class="vi">@decimal_class</span> <span class="o">==</span> <span class="o">::</span><span class="no">BigDecimal</span>
  <span class="no">BigDecimal</span><span class="p">(</span><span class="vi">@buffer</span><span class="p">)</span>
<span class="k">else</span>
  <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="vi">@buffer</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>Now, when <code class="language-plaintext highlighter-rouge">decimal_class</code> isn’t <code class="language-plaintext highlighter-rouge">nil</code>, we’d also check if it is pointing to the <code class="language-plaintext highlighter-rouge">BigDecimal</code> class specifically.
Here again, really no concern, especially since most of the time we’d fall into the <code class="language-plaintext highlighter-rouge">nil</code> condition.</p>

<p>But then, <a href="https://github.com/ruby/json/commit/ae5ef25af52b2b92d7ecf40feeca09c324c0d777">in 2020, there was yet another iteration on that logic</a>,
to make it more consistent with other parts of Ruby, and that’s where the check became way more expensive, and where the cheap
<code class="language-plaintext highlighter-rouge">nil</code> check that allowed to bail out early most of the time disappeared.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">VALUE</span> <span class="n">mod</span> <span class="o">=</span> <span class="n">Qnil</span><span class="p">;</span>
<span class="n">ID</span> <span class="n">method_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rb_respond_to</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_try_convert</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">;</span>
    <span class="n">method_id</span> <span class="o">=</span> <span class="n">i_try_convert</span><span class="p">;</span>
<span class="p">}</span> <span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">rb_respond_to</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">i_new</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">;</span>
    <span class="n">method_id</span> <span class="o">=</span> <span class="n">i_new</span><span class="p">;</span>
<span class="p">}</span> <span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">RB_TYPE_P</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">,</span> <span class="n">T_CLASS</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">name</span> <span class="o">=</span> <span class="n">rb_class_name</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">decimal_class</span><span class="p">);</span>
    <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">name_cstr</span> <span class="o">=</span> <span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">name</span><span class="p">);</span>
    <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">last_colon</span> <span class="o">=</span> <span class="n">strrchr</span><span class="p">(</span><span class="n">name_cstr</span><span class="p">,</span> <span class="sc">':'</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">last_colon</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">mod_path_end</span> <span class="o">=</span> <span class="n">last_colon</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">VALUE</span> <span class="n">mod_path</span> <span class="o">=</span> <span class="n">rb_str_substr</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">mod_path_end</span> <span class="o">-</span> <span class="n">name_cstr</span><span class="p">);</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">rb_path_to_class</span><span class="p">(</span><span class="n">mod_path</span><span class="p">);</span>

        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">method_name_beg</span> <span class="o">=</span> <span class="n">last_colon</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="kt">long</span> <span class="n">before_len</span> <span class="o">=</span> <span class="n">method_name_beg</span> <span class="o">-</span> <span class="n">name_cstr</span><span class="p">;</span>
        <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">-</span> <span class="n">before_len</span><span class="p">;</span>
        <span class="n">VALUE</span> <span class="n">method_name</span> <span class="o">=</span> <span class="n">rb_str_substr</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">before_len</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
        <span class="n">method_id</span> <span class="o">=</span> <span class="n">SYM2ID</span><span class="p">(</span><span class="n">rb_str_intern</span><span class="p">(</span><span class="n">method_name</span><span class="p">));</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">rb_mKernel</span><span class="p">;</span>
        <span class="n">method_id</span> <span class="o">=</span> <span class="n">SYM2ID</span><span class="p">(</span><span class="n">rb_str_intern</span><span class="p">(</span><span class="n">name</span><span class="p">));</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// snip...</span>

<span class="k">if</span> <span class="p">(</span><span class="n">method_id</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">text</span> <span class="o">=</span> <span class="n">rb_str_new2</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">));</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">rb_funcallv</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">method_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">text</span><span class="p">);</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">DBL2NUM</span><span class="p">(</span><span class="n">rb_cstr_to_dbl</span><span class="p">(</span><span class="n">FBUFFER_PTR</span><span class="p">(</span><span class="n">json</span><span class="o">-&gt;</span><span class="n">fbuffer</span><span class="p">),</span> <span class="mi">1</span><span class="p">));</span>
<span class="p">}</span></code></pre></figure>

<p>Which in Ruby would be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">mod</span> <span class="o">=</span> <span class="nb">method</span> <span class="o">=</span> <span class="kp">nil</span>

<span class="k">if</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:try_convert</span><span class="p">)</span>
  <span class="n">mod</span> <span class="o">=</span> <span class="vi">@decimal_class</span>
  <span class="nb">method</span> <span class="o">=</span> <span class="ss">:try_convert</span>
<span class="k">elsif</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:new</span><span class="p">)</span>
  <span class="n">mod</span> <span class="o">=</span> <span class="vi">@decimal_class</span>
  <span class="nb">method</span> <span class="o">=</span> <span class="ss">:new</span>
<span class="k">elsif</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Class</span><span class="p">)</span>
  <span class="k">if</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">name</span><span class="p">.</span><span class="nf">include?</span><span class="p">(</span><span class="s2">"::"</span><span class="p">)</span>
    <span class="o">*</span><span class="n">namespace</span><span class="p">,</span> <span class="nb">name</span> <span class="o">=</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="s2">"::"</span><span class="p">)</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="no">Object</span><span class="p">.</span><span class="nf">const_get</span><span class="p">(</span><span class="n">namespace</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="s2">"::"</span><span class="p">))</span>
    <span class="nb">method</span> <span class="o">=</span> <span class="nb">name</span><span class="p">.</span><span class="nf">to_sym</span>
  <span class="k">else</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="no">Kernel</span>
    <span class="nb">method</span> <span class="o">=</span> <span class="vi">@decimal_class</span><span class="p">.</span><span class="nf">name</span><span class="p">.</span><span class="nf">to_sym</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="c1"># snip...</span>

<span class="k">if</span> <span class="nb">method</span>
  <span class="n">mod</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="nb">method</span><span class="p">,</span> <span class="vi">@buffer</span><span class="p">)</span>
<span class="k">else</span>
  <span class="vi">@buffer</span><span class="p">.</span><span class="nf">to_f</span>
<span class="k">end</span></code></pre></figure>

<p>So quite a lot of logic.</p>

<p>To be clear, I’m absolutely not pointing fingers here, hindsight is 20/20 and I’m guilty of similar mistakes in the past.
I just thought it was a good occasion to showcase how some code can become slower over time.</p>

<p>The code is initially simple and quite fast, and then it grows in complexity over time for perfectly legitimate reasons,
with targetted patches that focus on a single function.
Without an integrated benchmark suite, it’s very easy to merge changes without realizing their performance impact, especially
since you often review a diff, without necessarily paying too much attention to where it is located.</p>

<h2 id="eliding-option-hash-allocation">Eliding Option Hash Allocation</h2>

<p>Soon after rebasing Luke’s patches, I improved the setup cost further using similar techniques as for the generator.</p>

<p>The <code class="language-plaintext highlighter-rouge">JSON.parse</code> method used to be defined as:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="p">{})</span>
  <span class="no">Parser</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="n">opts</span><span class="o">||</span><span class="p">{})).</span><span class="nf">parse</span>
<span class="k">end</span></code></pre></figure>

<p>This means we always allocate an option Hash, even when no option was passed, and then splat it for little benefits.</p>

<p>By rewriting it as:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="no">Parser</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">source</span><span class="p">).</span><span class="nf">parse</span>
  <span class="k">else</span>
    <span class="no">Parser</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span><span class="p">).</span><span class="nf">parse</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>I managed to get rid of a useless allocation.</p>

<p>Similarly, the <code class="language-plaintext highlighter-rouge">JSON.load</code> method, used to be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="nb">proc</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{})</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">load_default_options</span><span class="p">.</span><span class="nf">merge</span> <span class="n">options</span>
  <span class="k">if</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span> <span class="ss">:to_str</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">to_str</span>
  <span class="k">elsif</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span> <span class="ss">:to_io</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">to_io</span><span class="p">.</span><span class="nf">read</span>
  <span class="k">elsif</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:read</span><span class="p">)</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">read</span>
  <span class="k">end</span>
  <span class="k">if</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:allow_blank</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">||</span> <span class="n">source</span><span class="p">.</span><span class="nf">empty?</span><span class="p">)</span>
    <span class="n">source</span> <span class="o">=</span> <span class="s1">'null'</span>
  <span class="k">end</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">parse</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="n">recurse_proc</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="o">&amp;</span><span class="nb">proc</span><span class="p">)</span> <span class="k">if</span> <span class="nb">proc</span>
  <span class="n">result</span>
<span class="k">end</span></code></pre></figure>

<p>Which I optimized into:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="nb">proc</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">options</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="k">if</span> <span class="n">options</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="n">load_default_options</span>
  <span class="k">else</span>
    <span class="n">load_default_options</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="k">unless</span> <span class="n">source</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">String</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span> <span class="ss">:to_str</span>
      <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">to_str</span>
    <span class="k">elsif</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span> <span class="ss">:to_io</span>
      <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">to_io</span><span class="p">.</span><span class="nf">read</span>
    <span class="k">elsif</span> <span class="n">source</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:read</span><span class="p">)</span>
      <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">read</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="k">if</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:allow_blank</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">||</span> <span class="n">source</span><span class="p">.</span><span class="nf">empty?</span><span class="p">)</span>
    <span class="n">source</span> <span class="o">=</span> <span class="s1">'null'</span>
  <span class="k">end</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">parse</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="n">recurse_proc</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="o">&amp;</span><span class="nb">proc</span><span class="p">)</span> <span class="k">if</span> <span class="nb">proc</span>
  <span class="n">result</span>
<span class="k">end</span></code></pre></figure>

<p>First to avoid a Hash allocation when no option is passed,
and also to avoid calling <code class="language-plaintext highlighter-rouge">respond_to?</code> on the most common case, which is where <code class="language-plaintext highlighter-rouge">source</code> is a String.
It also saved a useless <code class="language-plaintext highlighter-rouge">String#to_str</code> call in that common case.</p>

<p>This is very similar to the optimizations performed in earlier parts so I won’t repeat here why this is preferable.</p>

<h2 id="more-stack-allocation">More Stack Allocation</h2>

<p>Similarly, another optimization I directly ported from the encoding code, was to allocate some structures on the stack.</p>

<p>The <code class="language-plaintext highlighter-rouge">ruby/json</code> parser uses a small buffer for some operations, such as parsing numbers.</p>

<p>The underlying Ruby APIs the parser uses for that are <code class="language-plaintext highlighter-rouge">rb_cstr_to_dbl</code> and <code class="language-plaintext highlighter-rouge">rb_cstr2inum</code>.
These APIs, as indicated by their name, expect “C strings” (<code class="language-plaintext highlighter-rouge">cstr</code>), in other words, <code class="language-plaintext highlighter-rouge">NULL</code> terminated strings, which
isn’t very convenient in this context, as the numbers we’re interested in parsing are generally immediately followed by
the remainder of the JSON document, likely a comma or some other delimiter.</p>

<p>Hence, we have no choice but to first copy the string representation of the number into a separate buffer, add the <code class="language-plaintext highlighter-rouge">NULL</code>
terminator and then invoke the function provided by Ruby.</p>

<p>At this point, you are probably already thinking that this is wasteful and that it would be better to parse these numbers in
place, but we’ll come back to it in the next post.</p>

<p>In the meantime, a simple fix was to allocate that internal buffer on the stack as we did with the generator saving us a pair
of <code class="language-plaintext highlighter-rouge">malloc/free</code> calls.</p>

<p>First by <a href="https://github.com/ruby/json/commit/72110f7992c28c4a73e144b7b63b9ecded0f812e">allocating the <code class="language-plaintext highlighter-rouge">FBuffer</code> structure on the stack</a>,
then also allocating the internal buffer there as well. But that too we discussed at length in previous parts, so I won’t spend
too many words on it.</p>

<h2 id="string-unescape">String Unescape</h2>

<p>The previous optimizations were either old pull requests I rebased, or optimizations that were ported from the encoding code path,
so they were basically no-brainers.</p>

<p>After that, I went on profiling macro-benchmarks, especially <code class="language-plaintext highlighter-rouge">twitter.json</code>.</p>

<p><img src="/assets/articles/json-6/parse-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4aeZiYA">Full profile</a></p>

<p>Not so surprisingly, the most obvious hotspot was <code class="language-plaintext highlighter-rouge">json_string_unescape</code>, totaling over <code class="language-plaintext highlighter-rouge">23%</code> of the overall runtime.</p>

<p>We’ll come back quite a few times to that function, so I’ll start by copying its initial version here and
describe what it does.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="kt">size_t</span> <span class="n">MAX_STACK_BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>

<span class="k">static</span> <span class="n">VALUE</span> <span class="nf">json_string_unescape</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">string</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">stringEnd</span><span class="p">,</span> <span class="kt">int</span> <span class="n">intern</span><span class="p">,</span> <span class="kt">int</span> <span class="n">symbolize</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">result</span> <span class="o">=</span> <span class="n">Qnil</span><span class="p">;</span>
    <span class="kt">size_t</span> <span class="n">bufferSize</span> <span class="o">=</span> <span class="n">stringEnd</span> <span class="o">-</span> <span class="n">string</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">p</span> <span class="o">=</span> <span class="n">string</span><span class="p">,</span> <span class="o">*</span><span class="n">pe</span> <span class="o">=</span> <span class="n">string</span><span class="p">,</span> <span class="o">*</span><span class="n">unescape</span><span class="p">,</span> <span class="o">*</span><span class="n">bufferStart</span><span class="p">,</span> <span class="o">*</span><span class="n">buffer</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">unescape_len</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">bufferSize</span> <span class="o">&gt;</span> <span class="n">MAX_STACK_BUFFER_SIZE</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">bufferStart</span> <span class="o">=</span> <span class="n">buffer</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">bufferSize</span> <span class="o">?</span> <span class="n">bufferSize</span> <span class="o">:</span> <span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">bufferStart</span> <span class="o">=</span> <span class="n">buffer</span> <span class="o">=</span> <span class="n">ALLOCA_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">bufferSize</span> <span class="o">?</span> <span class="n">bufferSize</span> <span class="o">:</span> <span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">pe</span> <span class="o">&lt;</span> <span class="n">stringEnd</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">pe</span> <span class="o">==</span> <span class="sc">'\\'</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"?"</span><span class="p">;</span>
            <span class="n">unescape_len</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">pe</span> <span class="o">&gt;</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
              <span class="n">MEMCPY</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">pe</span> <span class="o">-</span> <span class="n">p</span><span class="p">);</span>
              <span class="n">buffer</span> <span class="o">+=</span> <span class="n">pe</span> <span class="o">-</span> <span class="n">p</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="k">switch</span> <span class="p">(</span><span class="o">*++</span><span class="n">pe</span><span class="p">)</span> <span class="p">{</span>
                <span class="k">case</span> <span class="sc">'n'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'r'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\r</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'t'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'"'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\"</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'\\'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\\</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'b'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\b</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'f'</span><span class="p">:</span>
                    <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"</span><span class="se">\f</span><span class="s">"</span><span class="p">;</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="k">case</span> <span class="sc">'u'</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">pe</span> <span class="o">&gt;</span> <span class="n">stringEnd</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="p">{</span>
                      <span class="k">if</span> <span class="p">(</span><span class="n">bufferSize</span> <span class="o">&gt;</span> <span class="n">MAX_STACK_BUFFER_SIZE</span><span class="p">)</span> <span class="p">{</span>
                        <span class="n">ruby_xfree</span><span class="p">(</span><span class="n">bufferStart</span><span class="p">);</span>
                      <span class="p">}</span>
                      <span class="n">raise_parse_error</span><span class="p">(</span><span class="s">"incomplete unicode character escape sequence at '%s'"</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
                    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                        <span class="kt">uint32_t</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">unescape_unicode</span><span class="p">((</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="o">++</span><span class="n">pe</span><span class="p">);</span>
                        <span class="n">pe</span> <span class="o">+=</span> <span class="mi">3</span><span class="p">;</span>
                        <span class="cm">/* To handle values above U+FFFF, we take a sequence of
                         * \uXXXX escapes in the U+D800..U+DBFF then
                         * U+DC00..U+DFFF ranges, take the low 10 bits from each
                         * to make a 20-bit number, then add 0x10000 to get the
                         * final codepoint.
                         *
                         * See Unicode 15: 3.8 "Surrogates", 5.3 "Handling
                         * Surrogate Pairs in UTF-16", and 23.6 "Surrogates
                         * Area".
                         */</span>
                        <span class="k">if</span> <span class="p">((</span><span class="n">ch</span> <span class="o">&amp;</span> <span class="mh">0xFC00</span><span class="p">)</span> <span class="o">==</span> <span class="mh">0xD800</span><span class="p">)</span> <span class="p">{</span>
                            <span class="n">pe</span><span class="o">++</span><span class="p">;</span>
                            <span class="k">if</span> <span class="p">(</span><span class="n">pe</span> <span class="o">&gt;</span> <span class="n">stringEnd</span> <span class="o">-</span> <span class="mi">6</span><span class="p">)</span> <span class="p">{</span>
                              <span class="k">if</span> <span class="p">(</span><span class="n">bufferSize</span> <span class="o">&gt;</span> <span class="n">MAX_STACK_BUFFER_SIZE</span><span class="p">)</span> <span class="p">{</span>
                                <span class="n">ruby_xfree</span><span class="p">(</span><span class="n">bufferStart</span><span class="p">);</span>
                              <span class="p">}</span>
                              <span class="n">raise_parse_error</span><span class="p">(</span><span class="s">"incomplete surrogate pair at '%s'"</span><span class="p">,</span> <span class="n">p</span><span class="p">);</span>
                            <span class="p">}</span>
                            <span class="k">if</span> <span class="p">(</span><span class="n">pe</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="sc">'\\'</span> <span class="o">&amp;&amp;</span> <span class="n">pe</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="sc">'u'</span><span class="p">)</span> <span class="p">{</span>
                                <span class="kt">uint32_t</span> <span class="n">sur</span> <span class="o">=</span> <span class="n">unescape_unicode</span><span class="p">((</span><span class="kt">unsigned</span> <span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="n">pe</span> <span class="o">+</span> <span class="mi">2</span><span class="p">);</span>
                                <span class="n">ch</span> <span class="o">=</span> <span class="p">(((</span><span class="n">ch</span> <span class="o">&amp;</span> <span class="mh">0x3F</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="mi">10</span><span class="p">)</span> <span class="o">|</span> <span class="p">((((</span><span class="n">ch</span> <span class="o">&gt;&gt;</span> <span class="mi">6</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xF</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="mi">16</span><span class="p">)</span>
                                        <span class="o">|</span> <span class="p">(</span><span class="n">sur</span> <span class="o">&amp;</span> <span class="mh">0x3FF</span><span class="p">));</span>
                                <span class="n">pe</span> <span class="o">+=</span> <span class="mi">5</span><span class="p">;</span>
                            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                                <span class="n">unescape</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span> <span class="s">"?"</span><span class="p">;</span>
                                <span class="k">break</span><span class="p">;</span>
                            <span class="p">}</span>
                        <span class="p">}</span>
                        <span class="n">unescape_len</span> <span class="o">=</span> <span class="n">convert_UTF32_to_UTF8</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">ch</span><span class="p">);</span>
                        <span class="n">unescape</span> <span class="o">=</span> <span class="n">buf</span><span class="p">;</span>
                    <span class="p">}</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="nl">default:</span>
                    <span class="n">p</span> <span class="o">=</span> <span class="n">pe</span><span class="p">;</span>
                    <span class="k">continue</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="n">MEMCPY</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">unescape</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">unescape_len</span><span class="p">);</span>
            <span class="n">buffer</span> <span class="o">+=</span> <span class="n">unescape_len</span><span class="p">;</span>
            <span class="n">p</span> <span class="o">=</span> <span class="o">++</span><span class="n">pe</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">pe</span><span class="o">++</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">pe</span> <span class="o">&gt;</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">MEMCPY</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">pe</span> <span class="o">-</span> <span class="n">p</span><span class="p">);</span>
      <span class="n">buffer</span> <span class="o">+=</span> <span class="n">pe</span> <span class="o">-</span> <span class="n">p</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">build_string</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">bufferStart</span><span class="p">,</span> <span class="n">intern</span><span class="p">,</span> <span class="n">symbolize</span><span class="p">);</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">bufferSize</span> <span class="o">&gt;</span> <span class="n">MAX_STACK_BUFFER_SIZE</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">ruby_xfree</span><span class="p">(</span><span class="n">bufferStart</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>The function receives a start and end pointers, in other words, a read-only slice of bytes, and then simply two minor
boolean parameters indicating whether the parsed string should be interned or cast to a symbol, but we can easily ignore that
part.</p>

<p>At the beginning of it, the function allocates a dedicated buffer, if the string to unescape is <code class="language-plaintext highlighter-rouge">128B</code> or less, the buffer is
allocated on the stack using <code class="language-plaintext highlighter-rouge">alloca</code>, or if it’s bigger, on the heap using <code class="language-plaintext highlighter-rouge">malloc</code>.</p>

<p>The function then scans the original string, byte by byte in search of backslash characters, once one is found, all the
scanned bytes until then are copied over in the buffer using <code class="language-plaintext highlighter-rouge">memcpy</code>, and then based on which characters follow the backslash,
the unescaped version of it is appended to the buffer, and then it goes back to search for the next backslash.</p>

<p>Once the entire source string has been scanned, the remaining bytes are copied with <code class="language-plaintext highlighter-rouge">memcpy</code>, and the Ruby String is built using
the buffer as a source, and finally the buffer is freed.</p>

<h2 id="a-note-on-simd">A Note on SIMD</h2>

<p>One thing to note here is that the function tries to avoid the naive solution of copying bytes one by one right after having
scanned them, and instead try to do it in batches using <code class="language-plaintext highlighter-rouge">memcpy</code> (which appears as <code class="language-plaintext highlighter-rouge">__platform_memmove</code> in profiles).
This is because, while the implementation of <code class="language-plaintext highlighter-rouge">memcpy</code> is platform-specific, most implementations
leverage SIMD registers to copy blocks of 16, 32, or more bytes in one CPU instruction, which is massively faster. So that’s good.</p>

<p>If you are unfamiliar with what SMID is, I’ll try a simple explanation. Imagine you have a string, and you need to check if
it is ASCII only or not, the naive implementation would be (using Ruby for clarity):</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">ascii_only?</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
  <span class="n">string</span><span class="p">.</span><span class="nf">each_byte</span> <span class="k">do</span> <span class="o">|</span><span class="n">byte</span><span class="o">|</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">byte</span> <span class="o">&amp;</span> <span class="mh">0x80</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="c1"># 0x80 == 0b10000000</span>
      <span class="k">return</span> <span class="kp">false</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="kp">true</span>
<span class="k">end</span></code></pre></figure>

<p>It’s quite straightforward, you go over bytes in the string one by one, and for each apply a bitmask (<code class="language-plaintext highlighter-rouge">0x80</code>) to validate
it’s in the ASCII range, because ASCII characters are in the <code class="language-plaintext highlighter-rouge">0..127</code> range, so in binary form, it means only the 7 least
significant bits can be set in each byte.</p>

<p>But that’s a bit wasteful, as for each byte we need to:</p>

<ul>
  <li>Load the byte in a register.</li>
  <li>Apply the bitwise AND.</li>
  <li>Conditionally jump.</li>
  <li>Increment the for loop counter.</li>
  <li>Another conditional jump to go back at the beginning of the loop.</li>
</ul>

<p>Even if you ignore the relative cost of each of these steps, you can see that the actual operation we want to perform,
the bitwise AND and the conditional jump, is entirely dwarfed by the work necessary to perform the looping.
That’s about only 2 out of 5 instructions.</p>

<p>But there’s a fairly well-known way to make this about 8 times faster on 64-bit processors, by checking the bytes in chunks
of 8 instead of one by one:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">ascii_only?</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>
  <span class="n">string</span><span class="p">.</span><span class="nf">unpack</span><span class="p">(</span><span class="s2">"Q*C*"</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">unsigned_int_64</span><span class="o">|</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">unsigned_int_64</span> <span class="o">&amp;</span> <span class="mh">0x8080808080808080</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
      <span class="k">return</span> <span class="kp">false</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="kp">true</span>
<span class="k">end</span></code></pre></figure>

<p>Since a character is just one byte, and a processor register can hold 8 bytes (64-bit), you can load 8 characters in a
single register, and apply the same bitmask to all of the 8 bytes at once, by simply repeating the <code class="language-plaintext highlighter-rouge">0x80</code> pattern, which
drastically the ratio of useful instructions, and the number of times you have to loop.</p>

<p>Well, <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD, which stands for Single Instruction Multiple Data</a>,
is exactly that idea, pushed further, with some even larger registers, and a wider set of specialized instructions to more easily
work on what are essentially small arrays. You may have heard it referred to as <em>vectorization</em>.
Some modern processors have SIMD registers as large as 512 bits, enough to copy or process 64 characters at once.</p>

<p>The downside however is that different processors have different APIs, so if you want to support both x86_64 processors and ARM64
processors, you need to write two versions of your routine, and probably a third version not using SIMD as a fallback.
And even if you only support x86_64, older or lower-end processors will only have older API, for instance depending on how old of
an Intel CPU you want to support you might need an SEE, SSE2, SSE3, SSSE3, SSE4.x, AVX, AVX2 and AVX-512 implementation, and as
I’m writing this, Intel as announced the future AVX10 instruction set.</p>

<p>And you don’t just need to write multiple versions, you also need some extra code to detect which CPU you’re running on
and dynamically select the best usable implementation.</p>

<p>So SIMD is very powerful, but it’s a ton of work to use it on multi-platform C code, too much work for me to consider
maintaining that in <code class="language-plaintext highlighter-rouge">ruby/json</code>.</p>

<h2 id="be-optimistic">Be Optimistic</h2>

<p>Now that we said all that, what can we do to speed up <code class="language-plaintext highlighter-rouge">json_string_unescape</code>? As always the key is to start focusing on the
happy path. We can easily assume most strings in a JSON document don’t need to be escaped. If we use <code class="language-plaintext highlighter-rouge">twitter.json</code> as an
example, some of the tweet bodies contain newline characters (<code class="language-plaintext highlighter-rouge">\n</code>), and then their <code class="language-plaintext highlighter-rouge">source</code> property contains some HTML,
hence having a few escaped double quotes. Other than that, none of the other strings need to be unescaped.</p>

<p>In those cases, the current implementation is quite wasteful, we scan bytes one by one, copy them all into a buffer, and then ask
Ruby to copy the content again inside a Ruby String. If the overwhelming majority of strings don’t need to be escaped,
we can avoid one copy, and one buffer allocation and deallocation.</p>

<p>So the idea is to wait until we’ve found the first backslash until we concern ourselves with allocating a buffer.
You can <a href="https://github.com/ruby/json/commit/7e0f66546a53d99439db6ac30bdbcf6bebc7d801">look at the full patch</a>
(if you do ignore the <code class="language-plaintext highlighter-rouge">parser.c</code> file which is machine-generated from <code class="language-plaintext highlighter-rouge">parser.rl</code>), but the crux of it is just 4 lines
added at the top of <code class="language-plaintext highlighter-rouge">json_string_unescape</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">    <span class="n">pe</span> <span class="o">=</span> <span class="n">memchr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="sc">'\\'</span><span class="p">,</span> <span class="n">bufferSize</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_LIKELY</span><span class="p">(</span><span class="n">pe</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">build_string</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="n">stringEnd</span><span class="p">,</span> <span class="n">intern</span><span class="p">,</span> <span class="n">symbolize</span><span class="p">);</span>
    <span class="p">}</span></code></pre></figure>

<p>Here I used <code class="language-plaintext highlighter-rouge">memchr</code>, which is a function that’s part of the C standard library (like <code class="language-plaintext highlighter-rouge">memcpy</code>), used to search for one
character in a string, that’s something that is the ideal use case for SIMD. So it depends on which libc is used in the end,
but there’s a very high chance it is optimized to use SIMD, without <code class="language-plaintext highlighter-rouge">ruby/json</code> needing to do the extra work.</p>

<p>The result of just that small change was pretty good:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    60.000 i/100ms
Calculating -------------------------------------
               after    603.730 (± 0.2%) i/s    (1.66 ms/i) -      3.060k in   5.068496s

Comparison:
              before:      552.0 i/s
               after:      603.7 i/s - 1.09x  faster
</code></pre></div></div>

<p>Given that <code class="language-plaintext highlighter-rouge">json_string_unescape</code> was profiled as <code class="language-plaintext highlighter-rouge">23%</code> of overall runtime, getting a <code class="language-plaintext highlighter-rouge">9%</code> speedup overall from just optimizing
that one function is huge, close to a 2x improvement.</p>

<h2 id="reuse-buffers">Reuse Buffers</h2>

<p>My next idea to improve <code class="language-plaintext highlighter-rouge">json_string_unescape</code>, was that when we’re not in the happy path, rather than use a stack or heap
buffer to do the unescaping, which we then have to copy a second time, we might as well work directly inside Ruby-owned memory,
by using the Ruby string we’ll end up returning as our intermediary buffer.</p>

<p>As I mentioned previously, Ruby strings can be hard to use as dynamic buffers from C, because if you need to resize them,
you have to be very careful as to how the GC could react.</p>

<p>But in this case, we’re unescaping JSON, so we know upfront that the final unescaped string won’t possibly be larger than the
original escaped one, so we know we won’t need to resize the string.</p>

<p>You can <a href="https://github.com/ruby/json/pull/671">look at the full patch</a>, but the crux of it is again at the top of
<code class="language-plaintext highlighter-rouge">json_string_unescape</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">VALUE</span> <span class="n">result</span> <span class="o">=</span> <span class="n">rb_str_buf_new</span><span class="p">(</span><span class="n">bufferSize</span><span class="p">);</span>
<span class="n">rb_enc_associate_index</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">utf8_encindex</span><span class="p">);</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="n">bufferStart</span> <span class="o">=</span> <span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">result</span><span class="p">);</span></code></pre></figure>

<p>Since our more realistic benchmarks don’t have that many strings that need escaping, the difference there isn’t very big,
but by crafting a dedicated micro-benchmark, we can see it more easily:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_parsing</span> <span class="s2">"lots_unescape"</span><span class="p">,</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">([</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">*</span><span class="mi">200</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing lots_unescape (40301 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after     1.809k i/100ms
Calculating -------------------------------------
               after     18.048k (± 0.3%) i/s   (55.41 μs/i) -     90.450k in   5.011607s

Comparison:
              before:    16591.5 i/s
               after:    18048.3 i/s - 1.09x  faster
</code></pre></div></div>

<p>And in general, even if something doesn’t help the happy path, hence doesn’t move the needle much on macro-benchmark, it’s
still good not to neglect the performance of the unhappy path.</p>

<h2 id="elide-parser-allocation">Elide Parser Allocation</h2>

<p>The next optimization I performed, was another direct port of a previous optimization from the generator.</p>

<p>If you remember the <code class="language-plaintext highlighter-rouge">JSON.parse</code> method:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="no">Parser</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">source</span><span class="p">).</span><span class="nf">parse</span>
  <span class="k">else</span>
    <span class="no">Parser</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">opts</span><span class="p">).</span><span class="nf">parse</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>You can see we instantiate a <code class="language-plaintext highlighter-rouge">JSON::Parser</code> instance, but immediately discard it after having called a method on it.
Using more pompous terms, the <code class="language-plaintext highlighter-rouge">Parser</code> instance doesn’t <em>escape</em> the <code class="language-plaintext highlighter-rouge">parse</code> method.
As such we can entirely skip on allocating that object, like we did with the <code class="language-plaintext highlighter-rouge">JSON::State</code> instance, but it’s even simpler
as we don’t even need logic to allocate it on the fly as it is never needed.</p>

<p>Sufficiently advanced compilers can perform this sort of optimization on their own, that’s what they refer to as “escape analysis”,
and that is how some JITs can sometimes actually reduce memory usage of an application, by automatically eluding some allocations.
Here however it would be very hard for a compiler to perform as it would need to understand both the Ruby and C parts of the program,
perhaps older versions of TruffleRuby would have been able to optimize this out when they used to interpret C extensions, but I’m not sure.</p>

<p>You can look at <a href="https://github.com/ruby/json/pull/673">the full patch</a>, which shipped with a few other optimizations like
the more efficient way to process option hashes, but nothing we haven’t talked about before, so let’s move on.</p>

<h2 id="caching-parsed-objects">Caching Parsed Objects</h2>

<p>At that point, <code class="language-plaintext highlighter-rouge">JSON.parse</code> was getting really close to alternatives on macro benchmarks,
but I didn’t have any immediate ideas on what to do to go beyond that:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.3.4 (2024-07-09 revision be1089c8ec) +YJIT [arm64-darwin23]
Warming up --------------------------------------
                json    57.000 i/100ms
                  oj    62.000 i/100ms
          Oj::Parser    78.000 i/100ms
           rapidjson    56.000 i/100ms
Calculating -------------------------------------
                json    573.527 (± 1.6%) i/s    (1.74 ms/i) -      2.907k in   5.070094s
                  oj    619.368 (± 1.6%) i/s    (1.61 ms/i) -      3.100k in   5.006550s
          Oj::Parser    770.095 (± 0.9%) i/s    (1.30 ms/i) -      3.900k in   5.064768s
           rapidjson    560.601 (± 0.4%) i/s    (1.78 ms/i) -      2.856k in   5.094597s

Comparison:
                json:      573.5 i/s
          Oj::Parser:      770.1 i/s - 1.34x  faster
                  oj:      619.4 i/s - 1.08x  faster
           rapidjson:      560.6 i/s - 1.02x  slower
</code></pre></div></div>

<p>Surely we should be able to match <code class="language-plaintext highlighter-rouge">Oj.load</code>, given it has a similar interface, but beating <code class="language-plaintext highlighter-rouge">Oj::Parser</code> wasn’t realistic
because it had a major inherent advantage, its statefulness:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">Benchmark</span><span class="p">.</span><span class="nf">ips</span> <span class="k">do</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span>
  <span class="n">x</span><span class="p">.</span><span class="nf">report</span><span class="p">(</span><span class="s2">"json"</span><span class="p">)</span>      <span class="p">{</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">json_output</span><span class="p">)</span> <span class="p">}</span> <span class="k">if</span> <span class="no">RUN</span><span class="p">[</span><span class="ss">:json</span><span class="p">]</span>
  <span class="n">x</span><span class="p">.</span><span class="nf">report</span><span class="p">(</span><span class="s2">"oj"</span><span class="p">)</span>        <span class="p">{</span> <span class="no">Oj</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">json_output</span><span class="p">)</span> <span class="p">}</span> <span class="k">if</span> <span class="no">RUN</span><span class="p">[</span><span class="ss">:oj</span><span class="p">]</span>
  <span class="n">x</span><span class="p">.</span><span class="nf">report</span><span class="p">(</span><span class="s2">"Oj::Parser"</span><span class="p">)</span> <span class="p">{</span> <span class="no">Oj</span><span class="o">::</span><span class="no">Parser</span><span class="p">.</span><span class="nf">usual</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">json_output</span><span class="p">)</span> <span class="p">}</span> <span class="k">if</span> <span class="no">RUN</span><span class="p">[</span><span class="ss">:oj</span><span class="p">]</span>
  <span class="n">x</span><span class="p">.</span><span class="nf">report</span><span class="p">(</span><span class="s2">"rapidjson"</span><span class="p">)</span> <span class="p">{</span> <span class="no">RapidJSON</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">json_output</span><span class="p">)</span> <span class="p">}</span> <span class="k">if</span> <span class="no">RUN</span><span class="p">[</span><span class="ss">:rapidjson</span><span class="p">]</span>
  <span class="n">x</span><span class="p">.</span><span class="nf">compare!</span><span class="p">(</span><span class="ss">order: :baseline</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">Oj::Parser.usual</code> always returns the same <code class="language-plaintext highlighter-rouge">Oj::Parser</code> instance, and it has a few internal caches.
For instance, it caches the parsed Hash keys, so that if the same key is encountered more than once, it is only allocated once.</p>

<p>This is made easy by Ruby, because not many people know this, but when you use a string as a hash key, it often doesn’t use the
key you gave it, but makes a copy:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># frozen_string_literal: true</span>

<span class="nb">hash</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">key</span> <span class="o">=</span> <span class="s2">"my_key"</span>
<span class="n">key_copy</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="nf">dup</span>
<span class="nb">hash</span><span class="p">[</span><span class="n">key_copy</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">hash</span><span class="p">.</span><span class="nf">keys</span><span class="p">.</span><span class="nf">first</span><span class="p">.</span><span class="nf">equal?</span><span class="p">(</span><span class="n">key_copy</span><span class="p">)</span> <span class="c1"># =&gt; false</span>
<span class="nb">hash</span><span class="p">.</span><span class="nf">keys</span><span class="p">.</span><span class="nf">first</span><span class="p">.</span><span class="nf">equal?</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="c1"># =&gt; true</span>
<span class="nb">hash</span><span class="p">.</span><span class="nf">keys</span><span class="p">.</span><span class="nf">first</span><span class="p">.</span><span class="nf">frozen?</span> <span class="c1"># =&gt; true</span></code></pre></figure>

<p>The reason is that hashes behave quite weirdly when their keys are mutated. Ruby lets you do it with other types, but given
strings are among the most common hash keys, they are treated a bit differently, in pseudo-Ruby, the logic would be something like:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Hash</span>
  <span class="k">def</span> <span class="nf">[]=</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">entry</span> <span class="o">=</span> <span class="n">find_entry</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
      <span class="n">entry</span><span class="p">.</span><span class="nf">value</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">else</span>
      <span class="k">if</span> <span class="n">key</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">String</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">key</span><span class="p">.</span><span class="nf">interned?</span>
        <span class="k">if</span> <span class="n">interned_str</span> <span class="o">=</span> <span class="o">::</span><span class="no">RubyVM</span><span class="o">::</span><span class="no">INTERNED_STRING_TABLE</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
          <span class="n">key</span> <span class="o">=</span> <span class="n">interned_str</span>
        <span class="k">elsif</span> <span class="o">!</span><span class="n">key</span><span class="p">.</span><span class="nf">frozen?</span>
          <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="nf">dup</span><span class="p">.</span><span class="nf">freeze</span>
        <span class="k">end</span>
      <span class="k">end</span>

      <span class="nb">self</span> <span class="o">&lt;&lt;</span> <span class="no">Entry</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>So when inserting into a Hash, if the key is a String, and isn’t interned, Ruby will first try to check if an equivalent string <a href="https://en.wikipedia.org/wiki/Interning_(computer_science)">has been interned</a>.
And if that’s the case, it replaces the provided key with its interned counterpart.</p>

<p>If there is no equivalent interned string, then it checks if the provided key is frozen, if it isn’t, it makes a copy and freezes it.</p>

<p>So it’s impossible to have a mutable String as a hash key, and if you insert something in a hash using a mutable string as a key,
that will likely cause an extra allocation.</p>

<p>That’s why when parsing some format into a hash, <a href="https://github.com/redis-rb/redis-client/commit/3c669f44c7478ffb222e483c8acbdb2a00bbfd65">it’s a good idea to pre-freeze string keys, as it can reduce allocations quite significantly</a>.</p>

<p>But beyond just pre-freezing, you can also pre-intern the string, which is something <a href="https://github.com/ruby/json/pull/451">I added a while ago to the JSON gem</a>,
long before I was a maintainer, using <a href="https://bugs.ruby-lang.org/issues/16029">a set of Ruby C APIs I added back in Ruby 3.0</a>.
When using Ruby-level APIs, if you are parsing something and wish to intern a string, you can’t elude the allocation, because you need
to build a string to be able to look up the interned strings table, so it’s some sort of chicken and egg problem.
But these APIs allow to “find or create” an interned Ruby String, directly from a raw C string with only 0 or 1 allocation.</p>

<p>The way they do it is by allocating what’s referred to as a “fake string” on the stack and using that to look up the table.
If it’s a hit, then it returns the existing heap object it found, if not, it spills the “fake string” on the heap and intern
it.</p>

<p>If you are curious about it, you can look at <code class="language-plaintext highlighter-rouge">rb_interned_str</code>, <code class="language-plaintext highlighter-rouge">setup_fake_str</code> and <code class="language-plaintext highlighter-rouge">register_fstring</code> <a href="https://github.com/ruby/ruby/blob/d9e1a7cdf8a6e8327cd09a891fd45d6af357f926/string.c#L12507">in <code class="language-plaintext highlighter-rouge">string.c</code></a>,
but the crux of it is here:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span>
<span class="nf">setup_fake_str</span><span class="p">(</span><span class="k">struct</span> <span class="n">RString</span> <span class="o">*</span><span class="n">fake_str</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">name</span><span class="p">,</span> <span class="kt">long</span> <span class="n">len</span><span class="p">,</span> <span class="kt">int</span> <span class="n">encidx</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">fake_str</span><span class="o">-&gt;</span><span class="n">basic</span><span class="p">.</span><span class="n">flags</span> <span class="o">=</span> <span class="n">T_STRING</span><span class="o">|</span><span class="n">RSTRING_NOEMBED</span><span class="o">|</span><span class="n">STR_NOFREE</span><span class="o">|</span><span class="n">STR_FAKESTR</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">name</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">RUBY_ASSERT_ALWAYS</span><span class="p">(</span><span class="n">len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s">""</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">ENCODING_SET_INLINED</span><span class="p">((</span><span class="n">VALUE</span><span class="p">)</span><span class="n">fake_str</span><span class="p">,</span> <span class="n">encidx</span><span class="p">);</span>

    <span class="n">RBASIC_SET_CLASS_RAW</span><span class="p">((</span><span class="n">VALUE</span><span class="p">)</span><span class="n">fake_str</span><span class="p">,</span> <span class="n">rb_cString</span><span class="p">);</span>
    <span class="n">fake_str</span><span class="o">-&gt;</span><span class="n">len</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="n">fake_str</span><span class="o">-&gt;</span><span class="n">as</span><span class="p">.</span><span class="n">heap</span><span class="p">.</span><span class="n">ptr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="p">)</span><span class="n">name</span><span class="p">;</span>
    <span class="n">fake_str</span><span class="o">-&gt;</span><span class="n">as</span><span class="p">.</span><span class="n">heap</span><span class="p">.</span><span class="n">aux</span><span class="p">.</span><span class="n">capa</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">VALUE</span><span class="p">)</span><span class="n">fake_str</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">VALUE</span>
<span class="nf">rb_interned_str</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">long</span> <span class="n">len</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="n">RString</span> <span class="n">fake_str</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">register_fstring</span><span class="p">(</span><span class="n">setup_fake_str</span><span class="p">(</span><span class="o">&amp;</span><span class="n">fake_str</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ENCINDEX_US_ASCII</span><span class="p">),</span> <span class="nb">true</span><span class="p">,</span> <span class="nb">false</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>You can notice I didn’t make the “fake string” name up, it’s right there in the <code class="language-plaintext highlighter-rouge">STR_FAKESTR</code> flag.</p>

<p>Given all the above, if you expect a hash key to appear multiple times, it can be a good idea to pre-intern it yourself,
and to keep it handy, so that you save on further hash lookups.</p>

<p>That’s something <code class="language-plaintext highlighter-rouge">Oj::Parser</code> can more easily do, because its API is stateful, you allocate a parser object, and use it multiple
times, which allows it to keep state around, cache immutable objects and re-use them. It’s not all rainbows and unicorns though, if you have some
mutable state, you have to worry about concurrent access. Generally, that means you have to synchronize a mutex whenever you access
that state, which isn’t good for performance, or simply state the API isn’t thread safe and each thread should have its own parser
object. It also means you have to concern yourself with cache eviction, as the parser may be used to parse radically different
documents, so you need to keep track of how often keys are used and get rid of the cold ones. That’s a lot of extra logic so it’s
not guaranteed at all to pay off.</p>

<p>In <code class="language-plaintext highlighter-rouge">ruby/json</code>’s case, I wanted to make the already existing <code class="language-plaintext highlighter-rouge">JSON.parse</code> API faster, not expose a new faster one, so this sort
of persistent cache isn’t a great fit. But that doesn’t mean the general idea couldn’t be adapted.</p>

<p>Having a persistent cache makes a huge difference on micro-benchmarks, so in a way, it would be nice, but it really isn’t as
big of a deal on more real-world workloads, at least not most of them, unless you have lots of parser instances and you always
re-use the same instance to parse the same JSON schemas.</p>

<p>But if you look at the macro-benchmarks in <code class="language-plaintext highlighter-rouge">ruby/json</code>, a lot of them have a similar structure, it’s one big array of objects with
all the same keys:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">[</span><span class="w">
  </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"src"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://..."</span><span class="p">,</span><span class="w">
    </span><span class="err">...</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"src"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://..."</span><span class="p">,</span><span class="w">
    </span><span class="err">...</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="err">...</span><span class="w">
</span><span class="p">]</span></code></pre></figure>

<p>And that shouldn’t be a surprise, because that’s one of the biggest use cases for parsing JSON documents, REST APIs, GraphQL, etc.</p>

<p>With such a structure being expected to be common, even a cache that doesn’t escape the <code class="language-plaintext highlighter-rouge">JSON.parse</code> method could improve performance.
And if we’re not sharing the cache between documents, we don’t need to bother with synchronization or concurrent accesses,
don’t even really need to bother with evictions, and can probably afford it being relatively smaller. Small enough that it would
safely fit on the stack?</p>

<p>Since I liked the idea, I figured I might as well lean all the way into it. The kinda go-to data structure to use for caches
is some form of hash table, or binary tree. But these structures have lots of references, they don’t make the best use of limited
memory space.</p>

<p>That’s where I started remembering Aaron’s work on Ruby’s object shapes lookup cache, for which he used a cool data
structure: <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree">Red Black Trees</a>.
I’m not going to go into too much detail about those, because Aaron did multiple talks on them recently,
<a href="https://www.youtube.com/watch?v=Sav8S_7iWJc">for instance his keynote at Tropical.rb</a>, and he explains them extremely well.</p>

<p>But in short, it’s a tree structure that offers a good <code class="language-plaintext highlighter-rouge">O(log n)</code> search and insertion performance and doesn’t require that much
overhead on top of the useful payload. Each tree node needs one bit to store the color and two references to child nodes on top
of holding one entry. By packing structs efficiently, this could be done with just 16B per entry, so pretty good.</p>

<p>But as I was implementing it, I realized it was a lot of complexity for a cache I intended to be very small, a few dozen,
certainly less than a hundred entries.
And when dealing with a very small amount of data, algorithm complexity isn’t always the best predictor of performance.</p>

<p>So I figured I’d first try with what’s probably part of Computer Science 101<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>: a good old binary search.</p>

<p>If you think about it, doing a binary search in a sorted array has the same <code class="language-plaintext highlighter-rouge">O(log n)</code> complexity, but it’s also much more compact.
The one big downside is that during insertion you might need to move some elements, so it’s potentially <code class="language-plaintext highlighter-rouge">O(n)</code>,
but since we know we’ll be using a small array, it means not a lot of data to move, and since we’re not considering evictions,
we’ll fairly quickly stop inserting.</p>

<p>So most of the downsides of that solution don’t fully apply here, and being more compact is good given we want to use the stack
to store it, and it plays well with CPU caches and such, no pointer chasing or anything. In the worst case, if it didn’t perform well, I could easily swap it for
another data structure, and the interface would remain the same.</p>

<p>You can have a look at <a href="https://github.com/ruby/json/commit/f8887b9beba24464f0ec020e023e2b88afc4d8f4">the full patch</a>, there’s not
a whole lot I feel I can explain about it.</p>

<p>The only few key details are that I settled for a cache size of <code class="language-plaintext highlighter-rouge">63</code> entries and that strings longer than <code class="language-plaintext highlighter-rouge">55B</code> aren’t considered
for caching. Both of those are somewhat eye-balled heuristics of when it’s no longer worth trying to use the cache:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define JSON_RSTRING_CACHE_CAPA 63
#define JSON_RSTRING_CACHE_MAX_ENTRY_LENGTH 55
</span><span class="k">typedef</span> <span class="k">struct</span> <span class="n">rstring_cache_struct</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">length</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">entries</span><span class="p">[</span><span class="n">JSON_RSTRING_CACHE_CAPA</span><span class="p">];</span>
<span class="p">}</span> <span class="n">rstring_cache</span><span class="p">;</span></code></pre></figure>

<p>This immediately yielded a nice <code class="language-plaintext highlighter-rouge">15%</code> improvement on the <code class="language-plaintext highlighter-rouge">activitypub.json</code> and <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing twitter.json (567916 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    70.000 i/100ms
Calculating -------------------------------------
               after    708.951 (± 0.6%) i/s    (1.41 ms/i) -      3.570k in   5.035785s

Comparison:
              before:      617.3 i/s
               after:      709.0 i/s - 1.15x  faster
</code></pre></div></div>

<p>But they’re exactly the kind of documents I had in mind, so somewhat expected.
What was less good, however, is that another macro-benchmark was impacted, but negatively:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing citm_catalog.json (1727030 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    30.000 i/100ms
Calculating -------------------------------------
               after    303.890 (± 0.3%) i/s    (3.29 ms/i) -      1.530k in   5.034746s

Comparison:
              before:      323.8 i/s
               after:      303.9 i/s - 1.07x  slower
</code></pre></div></div>

<p>That I didn’t like, so I started to investigate.</p>

<p>It turned out that <code class="language-plaintext highlighter-rouge">citm_catalog.json</code> was the key cache’s worst nightmare:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
    </span><span class="nl">"areaNames"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"205705993"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène central"</span><span class="p">,</span><span class="w">
        </span><span class="err">//</span><span class="w"> </span><span class="mi">15</span><span class="w"> </span><span class="err">more</span><span class="w"> </span><span class="err">unique</span><span class="w"> </span><span class="err">keys</span><span class="w">
        </span><span class="nl">"342752287"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Zone physique secrète"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"audienceSubCategoryNames"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"337100890"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Abonné"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"blockNames"</span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
    </span><span class="nl">"events"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"138586341"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"description"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">138586341</span><span class="p">,</span><span class="w">
            </span><span class="nl">"logo"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"30th Anniversary Tour"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"subTopicIds"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="mi">337184269</span><span class="p">,</span><span class="w">
                </span><span class="mi">337184283</span><span class="w">
            </span><span class="p">],</span><span class="w">
            </span><span class="nl">"subjectCode"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
            </span><span class="nl">"subtitle"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
            </span><span class="nl">"topicIds"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="mi">324846099</span><span class="p">,</span><span class="w">
                </span><span class="mi">107888604</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="nl">"138586345"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"description"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
            </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">138586345</span><span class="p">,</span><span class="w">
            </span><span class="err">//</span><span class="w"> </span><span class="err">snipp</span></code></pre></figure>

<p>It does have a lot of repeated keys like we expect many JSON documents to have, however, it happens to also
have many numeric keys, likely internal database IDs, and since JSON only supports strings as object keys, they’re
all represented as strings, and these aren’t repeated much and fill the cache with junk almost immediately.</p>

<p>Even though the gain on <code class="language-plaintext highlighter-rouge">twitter.json</code> and <code class="language-plaintext highlighter-rouge">activitypub.json</code> was much bigger than the loss on <code class="language-plaintext highlighter-rouge">citm_catalog.json</code>,
that didn’t feel great, and that annoyed me a lot.</p>

<p>After some reflection, I figured the idea behind this optimization was to help with JSON objects that are essentially
tables rows, <code class="language-plaintext highlighter-rouge">citm_catalog.json</code> was mostly one, but mixed with some references.
Based on this, It seemed fair game to all keys that don’t look like a “column” name, such as the one starting with a digit,
so I added one little check:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">isalpha</span><span class="p">(</span><span class="n">str</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span> <span class="p">{</span>
    <span class="c1">// Simple heuristic, if the first character isn't a letter,</span>
    <span class="c1">// we're much less likely to see this string again.</span>
    <span class="c1">// We mostly want to cache strings that are likely to be repeated.</span>
    <span class="k">return</span> <span class="n">rb_str_freeze</span><span class="p">(</span><span class="n">rb_utf8_str_new</span><span class="p">(</span><span class="n">str</span><span class="p">,</span> <span class="n">length</span><span class="p">));</span>
<span class="p">}</span></code></pre></figure>

<p>With that extra little check, the <code class="language-plaintext highlighter-rouge">7%</code> loss turned into a <code class="language-plaintext highlighter-rouge">15%</code> gain:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Parsing citm_catalog.json (1727030 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    36.000 i/100ms
Calculating -------------------------------------
               after    369.793 (± 0.3%) i/s    (2.70 ms/i) -      1.872k in   5.062369s

Comparison:
              before:      321.7 i/s
               after:      369.8 i/s - 1.15x  faster
</code></pre></div></div>

<p>I know it might sound like benchmark gaming, but this whole optimization is based on heuristics that I really think holds
true for a very large number of documents parsed with <code class="language-plaintext highlighter-rouge">ruby/json</code>, and it’s not that different from the cap on <code class="language-plaintext highlighter-rouge">55B</code> strings.</p>

<p>Later on, I went further with heuristics for when the cache should and shouldn’t be used, notably by skipping it if we’re
not currently parsing an array:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
  </span><span class="nl">"not_worth_caching"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
  </span><span class="nl">"items"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"worth_caching"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"also_worth_caching"</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>You can see <a href="https://github.com/ruby/json/pull/705">the followup patch here</a>.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>I have about three more parser optimizations to talk about, and after that, I think this series will be finally done,
unless I talk about other things JSON, like my ideas for the future, or some thoughts on what I think isn’t good in its
current API, but we’ll see.</p>

<p>Edit: <a href="/ruby/json/2025/01/14/optimizing-ruby-json-part-7.html">Part 7 is here</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>Actually I have no idea what’s in Computer Science 101. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[After wrapping up about the encoder optimizations in the previous post, we can now start talking about the parser side.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 5</title><link href="https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 5" /><published>2025-01-04T19:28:51+00:00</published><updated>2025-01-04T19:28:51+00:00</updated><id>https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html"><![CDATA[<p><a href="/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html">In the previous post</a>, we showed how we eliminated two <code class="language-plaintext highlighter-rouge">malloc/free</code> pairs of calls
when generating small JSON documents, and how that put us ahead of Oj when reusing the <code class="language-plaintext highlighter-rouge">JSON::State</code> object.</p>

<p>But that API isn’t the one people use, so if we wanted to come out ahead in the micro-benchmarks users might perform themselves, we had to
find a way to get rid of that <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation too, or to somehow make it faster.</p>

<h2 id="typed-data">Typed Data</h2>

<p>Because that <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation, isn’t just about any allocation. In Ruby, everything is an object, but not all objects are created equal.
In previous parts I touched on how some objects aren’t actually allocated, and called “immediates”, I also touched on how core objects like <code class="language-plaintext highlighter-rouge">String</code> and
<code class="language-plaintext highlighter-rouge">Array</code> have both “embedded” and “heap” representations.</p>

<p><code class="language-plaintext highlighter-rouge">JSON::State</code> is a type defined in C from the extension, using the <code class="language-plaintext highlighter-rouge">TypedData</code> API. <a href="https://blog.peterzhu.ca/ruby-c-ext-part-7/">Peter Zhu has a great blog post that goes in-depth into
how these work and how to use them</a>, but I’ll offer a quicker explanation here.</p>

<p>To define a custom object type, you start by defining a C structure that holds the type metadata:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="n">rb_data_type_t</span> <span class="n">JSON_Generator_State_type</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"JSON/Generator/State"</span><span class="p">,</span>
    <span class="p">{</span>
        <span class="p">.</span><span class="n">dmark</span> <span class="o">=</span> <span class="n">State_mark</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dfree</span> <span class="o">=</span> <span class="n">State_free</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dsize</span> <span class="o">=</span> <span class="n">State_memsize</span><span class="p">,</span>
        <span class="p">.</span><span class="n">dcompact</span> <span class="o">=</span> <span class="n">State_compact</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">RUBY_TYPED_WB_PROTECTED</span> <span class="o">|</span> <span class="n">RUBY_TYPED_FREE_IMMEDIATELY</span> <span class="o">|</span> <span class="n">RUBY_TYPED_FROZEN_SHAREABLE</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure>

<p>You can read Peter’s post if you want to know all the juicy details, but in short, it’s a collection of flags and callbacks to instruct the GC
on how to deal with this object. For instance <code class="language-plaintext highlighter-rouge">State_mark</code> allows the GC to list all the references this object has to other objects.</p>

<p>And then you define an allocator function, that will replace the default <code class="language-plaintext highlighter-rouge">Class#allocate</code> method for that class when you register it with <code class="language-plaintext highlighter-rouge">rb_define_alloc_func</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_s_allocate</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">klass</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">obj</span> <span class="o">=</span> <span class="n">TypedData_Make_Struct</span><span class="p">(</span>
      <span class="n">klass</span><span class="p">,</span>
      <span class="n">JSON_Generator_State</span><span class="p">,</span>
      <span class="o">&amp;</span><span class="n">JSON_Generator_State_type</span><span class="p">,</span>
      <span class="n">state</span>
    <span class="p">);</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">buffer_initial_length</span> <span class="o">=</span> <span class="n">FBUFFER_INITIAL_LENGTH_DEFAULT</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">obj</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// snip...</span>

<span class="kt">void</span> <span class="nf">Init_generator</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">mJSON</span> <span class="o">=</span> <span class="n">rb_define_module</span><span class="p">(</span><span class="s">"JSON"</span><span class="p">);</span>
    <span class="n">VALUE</span> <span class="n">mExt</span> <span class="o">=</span> <span class="n">rb_define_module_under</span><span class="p">(</span><span class="n">mJSON</span><span class="p">,</span> <span class="s">"Ext"</span><span class="p">);</span>
    <span class="n">VALUE</span> <span class="n">mGenerator</span> <span class="o">=</span> <span class="n">rb_define_module_under</span><span class="p">(</span><span class="n">mExt</span><span class="p">,</span> <span class="s">"Generator"</span><span class="p">);</span>

    <span class="n">cState</span> <span class="o">=</span> <span class="n">rb_define_class_under</span><span class="p">(</span><span class="n">mGenerator</span><span class="p">,</span> <span class="s">"State"</span><span class="p">,</span> <span class="n">rb_cObject</span><span class="p">);</span>
    <span class="n">rb_define_alloc_func</span><span class="p">(</span><span class="n">cState</span><span class="p">,</span> <span class="n">cState_s_allocate</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">TypedData_Make_Struct</code> macro takes care of allocating a <code class="language-plaintext highlighter-rouge">40B</code> object slots of type <code class="language-plaintext highlighter-rouge">T_DATA</code>, as well as to call <code class="language-plaintext highlighter-rouge">ruby_xcalloc(sizeof(JSON_Generator_State))</code>
so we have some heap memory to store the object state.</p>

<p>The difference between <code class="language-plaintext highlighter-rouge">calloc</code> and <code class="language-plaintext highlighter-rouge">malloc</code>, is that when you use <code class="language-plaintext highlighter-rouge">malloc</code>, the memory that is allocated for you is left as is, with whatever data was
in it when it was last freed. Whereas <code class="language-plaintext highlighter-rouge">calloc</code> will do some extra work to fill that memory with zeros.</p>

<p>The struct used to interpret the content of the <code class="language-plaintext highlighter-rouge">40B</code> slot is <a href="https://github.com/ruby/ruby/blob/c936699431477a565b9e4036bc3b1fc186ac9918/include/ruby/internal/core/rtypeddata.h#L350-L371"><code class="language-plaintext highlighter-rouge">RTypedData</code> defined in <code class="language-plaintext highlighter-rouge">rtypeddata.h</code></a>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">RTypedData</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">RBasic</span> <span class="n">basic</span><span class="p">;</span>
    <span class="k">const</span> <span class="n">rb_data_type_t</span> <span class="o">*</span><span class="k">const</span> <span class="n">type</span><span class="p">;</span>
    <span class="k">const</span> <span class="n">VALUE</span> <span class="n">typed_flag</span><span class="p">;</span>
    <span class="kt">void</span> <span class="o">*</span><span class="n">data</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>type</th>
      <th>typed_flag</th>
      <th>*data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x0c</td>
      <td>0xffeff</td>
      <td>0xbbbef</td>
      <td>0x1</td>
      <td>0xcccdef</td>
    </tr>
  </tbody>
</table>

<p>As for the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct, it’s a simple struct holding our configuration, for a total of <code class="language-plaintext highlighter-rouge">72B</code> on 64-bit platforms:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">JSON_Generator_StateStruct</span> <span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">indent</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">space</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">space_before</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">object_nl</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">array_nl</span><span class="p">;</span>

    <span class="kt">long</span> <span class="n">max_nesting</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">depth</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">buffer_initial_length</span><span class="p">;</span>

    <span class="n">bool</span> <span class="n">allow_nan</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">ascii_only</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">script_safe</span><span class="p">;</span>
    <span class="n">bool</span> <span class="n">strict</span><span class="p">;</span>
<span class="p">}</span> <span class="n">JSON_Generator_State</span><span class="p">;</span></code></pre></figure>

<p>With this explanation, you may have understood that it’s not a simple object allocation we’re dealing with, but a noticeably more expensive operation.
This can be easily confirmed by profiling yet again:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">JSON</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>If we consider the cost of the object slot allocation, plus the heap allocation, and also the extra cost of Ruby’s GC having to call
<code class="language-plaintext highlighter-rouge">ruby_xfree</code> when these objects are garbage collected, it all amounts to practically 30% of the overall runtime, which is massive:</p>

<p><img src="/assets/articles/json-5/json-state-alloc-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/40odFp1">Full profile</a></p>

<p>In addition, you can see inside <code class="language-plaintext highlighter-rouge">rb_class_new_instance_pass_kw</code> that we’re spending quite a bit of time inside <code class="language-plaintext highlighter-rouge">rb_call0</code>.
That’s because when you call <code class="language-plaintext highlighter-rouge">.new</code> on a Ruby class, it pretty much works like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Class</span>
  <span class="k">def</span> <span class="nf">new</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">instance</span> <span class="o">=</span> <span class="n">allocate</span>
    <span class="n">instance</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:initialize</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
    <span class="n">instance</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>But as of Ruby 3.4, this logic is implemented in C, so it can’t benefit from an inline cache and other niceties,
instead, it has to rely on the Global Call Cache Cache Table, but also forwards arguments from C, which isn’t the most efficient.</p>

<p>That’s why <a href="https://github.com/ruby/ruby/pull/9289">Aaron Patterson has been trying to reimplement <code class="language-plaintext highlighter-rouge">Class#new</code> in Ruby</a>, but it’s not quite ready yet.</p>

<h2 id="embeding-rtypeddata">Embeding RTypedData</h2>

<p>As you might have noticed on the flame graph, allocating the object slot really is the least of our problems, it’s really the heap allocation and
deallocation that’s impacting performance very negatively.
Given that the existing API somewhat imposes a <code class="language-plaintext highlighter-rouge">JSON::State</code> allocation, if we can’t eliminate it, we can instead try to make it cheaper.</p>

<p>Since our <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> is only <code class="language-plaintext highlighter-rouge">72B</code>, with the extra <code class="language-plaintext highlighter-rouge">32B</code> imposed by <code class="language-plaintext highlighter-rouge">RTypedData</code> it could theoretically fit in a <code class="language-plaintext highlighter-rouge">160B</code> slot,
which would be perfect.</p>

<p>Back in 2023, <a href="https://github.com/ruby/ruby/pull/7440">I paired with Peter on allowing <code class="language-plaintext highlighter-rouge">TypedData</code> objects to be embeded</a>,
and we used that new capability to embed various core classes, <a href="https://github.com/ruby/ruby/pull/7440">the most notable one being <code class="language-plaintext highlighter-rouge">Time</code></a>, and it
did almost cut the cost of <code class="language-plaintext highlighter-rouge">Time.now</code> in half:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|                        |compare-ruby|built-ruby|
|:-----------------------|-----------:|---------:|
|Time.now                |     12.150M|   22.025M|
|                        |           -|     1.81x|
|Time.now(in: "+09:00")  |      3.545M|    4.794M|
|                        |           -|     1.35x|
</code></pre></div></div>

<p>So embedding <code class="language-plaintext highlighter-rouge">JSON::State</code> would be a big win with very little effort.
I’d just need to add <code class="language-plaintext highlighter-rouge">RUBY_TYPED_EMBEDDABLE</code> in the <code class="language-plaintext highlighter-rouge">JSON_Generator_State_type</code>, and remove the <code class="language-plaintext highlighter-rouge">ruby_xfree</code> call in <code class="language-plaintext highlighter-rouge">State_free</code>, and that’s it,
the setup cost would be cut in half.</p>

<p>Except there was one problem: we never made <code class="language-plaintext highlighter-rouge">RUBY_TYPED_EMBEDDABLE</code> a public API, as we thought it might be too easy to shoot yourself in
the foot with it, and we didn’t want to expose the C API users to a whole new class of hard-to-understand crashes.</p>

<p>Embedded objects are hard to use from C because, since Ruby 2.7, Ruby’s GC is capable of compacting the heap, which means moving live objects from one
slot to another. So when working in C with an embedded object, you have to be very careful not to hold onto a native pointer that is pointing inside
the object slot, because if the GC moves the object, the pointer you previously got is now pointing inside a totally different object, which can
cause all sorts of memory corruption issues, and from experience these are among the hardest bugs to investigate and fix.</p>

<p>Maybe we should still expose this API, it could definitely lead to some nice performance gains for some native gems, but that requires some careful
considerations, and would take time. When I was working on this patch, we were already almost in November, way too late in the Ruby release cycle to
hope to get a decision before the Ruby 3.4 release.</p>

<p>So that wasn’t a viable option, I needed to find another solution.</p>

<h2 id="using-a-t_object">Using a T_OBJECT</h2>

<p>That’s where I thought about using a “regular” object, AKA a <code class="language-plaintext highlighter-rouge">T_OBJECT</code>. That’s the internal type of all the objects you define in pure Ruby,
and as long as you define all the instance variables in the <code class="language-plaintext highlighter-rouge">initialize</code> method, they’re pretty much guaranteed to be embedded too.</p>

<p>After all, I recently moved the <code class="language-plaintext highlighter-rouge">State#configure</code> method from C into Ruby, I could go further and turn
<code class="language-plaintext highlighter-rouge">JSON::State</code> into a PORO. That would for sure make it much faster to allocate and initialize, plus it would benefit from JIT, and would allow sharing
more code with the JRuby and TruffleRuby implementations of <code class="language-plaintext highlighter-rouge">JSON.generate</code>.</p>

<p>But while the instantiation would get faster, access to the <code class="language-plaintext highlighter-rouge">JSON::State</code> fields from C would get slower, and that is for two reasons.</p>

<p>First, all the native fields in the struct, like <code class="language-plaintext highlighter-rouge">long depth</code>, would now need to be boxed (<a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html#boxing-day">I explained what it means in part 3</a>).
So that means some small overhead for every access, but it would probably be negligible.</p>

<p>The real problem would be uncached instance variable lookups. Because to look up an instance variable, just like for methods,
you need quite a bit of work. Here again, you can check <a href="https://railsatscale.com/2023-10-24-memoization-pattern-and-object-shapes/">my previous post on Object Shapes to understand why</a>.</p>

<p>When that lookup is done from Ruby code, we benefit from inline caches, so most of the time it’s just an integer comparison to revalidate the cache,
and then a simple memory read at an offset.</p>

<p>But when looking up the instance variables of an object from C extensions, the only possible API is <code class="language-plaintext highlighter-rouge">rb_ivar_get</code>, so that means no inline caches.
Contrary to uncached method lookups, you have no equivalent to the Global Call Cache Cache Table for instance variables, you have to go through a
full lookup every time. It’s less expensive than for a method, but still, you have to walk up the shape tree, so that’s potentially a lot of pointer
chasing.</p>

<p>If there was a C API to do cached instance variable lookups, I think using a <code class="language-plaintext highlighter-rouge">T_OBJECT</code> would have been a great solution, but since it isn’t
the case, I quickly gave up on the idea, it wasn’t even worth prototyping and profiling, and I 100% expected it not to perform well enough.</p>

<p>I also quickly considered using a Ruby <code class="language-plaintext highlighter-rouge">Struct</code> class, as those aren’t <code class="language-plaintext highlighter-rouge">T_OBJECT</code> but <code class="language-plaintext highlighter-rouge">T_STRUCT</code>, they’re also embedded, but the position of each
member is stored in an Array, so in some cases, it can be a bit faster to look up uncached, but I wasn’t hopeful it would move the needle enough.</p>

<h2 id="reusing-state">Reusing State</h2>

<p>If I couldn’t make the allocation faster, another avenue would be to find a way to reuse the object.</p>

<p>Technically, the <code class="language-plaintext highlighter-rouge">JSON::State</code> is mutable, and the various <code class="language-plaintext highlighter-rouge">#to_json</code> methods are free to add arbitrary fields into it, like some sort of Hash,
as a way to pass information around. But in practice, no-one really uses that, so I was OK with considering such a minor breaking change.</p>

<p>But a bigger challenge was JSON’s global configuration.</p>

<p>If you look at the <code class="language-plaintext highlighter-rouge">JSON.generate</code> method:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">opts</span>
  <span class="k">else</span>
    <span class="n">state</span> <span class="o">=</span> <span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">end</span>
  <span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>It would be easy to avoid allocating a new <code class="language-plaintext highlighter-rouge">State</code> object when <code class="language-plaintext highlighter-rouge">opts</code> is <code class="language-plaintext highlighter-rouge">nil</code> and instead use a single immutable <code class="language-plaintext highlighter-rouge">State</code> object.
That would definitely speed up <code class="language-plaintext highlighter-rouge">JSON.generate</code> enough to get ahead on all or at least most micro-benchmarks.</p>

<p>But even though the benchmarks inside <code class="language-plaintext highlighter-rouge">ruby/json</code> call <code class="language-plaintext highlighter-rouge">JSON.generate</code>, a lot of code out there, and presumably other people’s benchmarks might just as
well call <code class="language-plaintext highlighter-rouge">JSON.dump</code>, and in such case, <code class="language-plaintext highlighter-rouge">opts</code> wouldn’t be <code class="language-plaintext highlighter-rouge">nil</code>, but set to <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> or another Hash derived from it, hence that
optimization would be out the window pretty quickly.</p>

<p>I toyed with various ideas on how I could detect changes to <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> to keep a cached <code class="language-plaintext highlighter-rouge">JSON::State</code> object around,
but that’s not realistic because it defaults to a mutable hash, so I’d need to monkey-patch dozens of methods to be notified when it is mutated.</p>

<p>As a side note, I really hate <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code>. It’s really not a good idea to
globally change how a library behaves like this, as the various other libraries that depend on the <code class="language-plaintext highlighter-rouge">json</code> gem likely don’t expect it at all.
I’d like to deprecate it for the next major version, but we’ll see.</p>

<h2 id="lazy-allocation">Lazy Allocation</h2>

<p>At that point, I had been thinking about this problem for a few days, with no real solution in sight, until it hit me: the <code class="language-plaintext highlighter-rouge">JSON::State</code> only needs to be
allocated if a <code class="language-plaintext highlighter-rouge">#to_json</code> method has to be called, and it’s not that frequent.
If you are using some serialization framework in the style of Active Model Serializers, it most likely already converts all objects that don’t directly
map to a JSON type into some more primitive Ruby objects that are serializable without having to call <code class="language-plaintext highlighter-rouge">#to_json</code> on them.</p>

<p>Similarly, if you use Rails JSON rendering, likely via something like <code class="language-plaintext highlighter-rouge">render json: obj</code>, <a href="https://github.com/rails/rails/blob/e64e5d31cdeafee142e32e604b513a39de779651/activesupport/lib/active_support/json/encoding.rb#L57-L88">it first converts the given object tree into primitive types</a>,
so here again, <code class="language-plaintext highlighter-rouge">#to_json</code> calls are unlikely.</p>

<p>Overall, if <code class="language-plaintext highlighter-rouge">#to_json</code> needs to be called, we’re likely not in a situation where that one extra allocation will make a measurable difference.</p>

<p>But even if we don’t need to allocate the <code class="language-plaintext highlighter-rouge">JSON::State</code> instance, we still need to have some memory somewhere for a <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct,
because our C code needs to be able to check the configuration somehow.
Since it’s only <code class="language-plaintext highlighter-rouge">72B</code>, it can very comfortably fit in the C stack, making it close to free.</p>

<p>The downside though, is that <a href="/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html#jump-tables">the <code class="language-plaintext highlighter-rouge">State#configure</code> method we moved from C to Ruby in part two</a>,
well <a href="https://github.com/ruby/json/commit/5c0d428d4c518e651edd3d57dca83ab601944505">it had to go back to C</a>.
I was a bit sad, but as we say here, sometimes you need to take a step back in order to take a big jump forward.</p>

<p>The next step was to introduce a new internal API to allow to bypass <code class="language-plaintext highlighter-rouge">State#generate</code>, so that <code class="language-plaintext highlighter-rouge">JSON.generate</code> was now:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
    <span class="n">opts</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
  <span class="k">else</span>
    <span class="no">State</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>By calling into a class method, we don’t require the allocation.
For the pure-Ruby version of the generator, it didn’t change much, as there would be no way to elide the allocation, so I implemented
<code class="language-plaintext highlighter-rouge">JSON::Pure::State.generate</code> in a fairly obvious way:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">module</span> <span class="nn">JSON</span>
  <span class="k">module</span> <span class="nn">Pure</span>
    <span class="k">module</span> <span class="nn">Generator</span>
    <span class="k">class</span> <span class="nc">State</span>
      <span class="k">def</span> <span class="nc">self</span><span class="o">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
        <span class="n">new</span><span class="p">(</span><span class="n">opts</span><span class="p">).</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>For the C extension, this allowed to allocate the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> on the stack:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_m_generate</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">klass</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">obj</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">opts</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">JSON_Generator_State</span> <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
    <span class="n">state_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">state</span><span class="p">);</span>
    <span class="n">configure_state</span><span class="p">(</span><span class="o">&amp;</span><span class="n">state</span><span class="p">,</span> <span class="n">opts</span><span class="p">);</span>
    <span class="kt">char</span> <span class="n">stack_buffer</span><span class="p">[</span><span class="n">FBUFFER_STACK_SIZE</span><span class="p">];</span>
    <span class="n">FBuffer</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
    <span class="n">fbuffer_stack_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffer</span><span class="p">,</span> <span class="n">state</span><span class="p">.</span><span class="n">buffer_initial_length</span><span class="p">,</span> <span class="n">stack_buffer</span><span class="p">,</span> <span class="n">FBUFFER_STACK_SIZE</span><span class="p">);</span>
    <span class="k">struct</span> <span class="n">generate_json_data</span> <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">buffer</span><span class="p">,</span>
        <span class="p">.</span><span class="n">vstate</span> <span class="o">=</span> <span class="n">Qfalse</span><span class="p">,</span>
        <span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">state</span><span class="p">,</span>
        <span class="p">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">obj</span><span class="p">,</span>
        <span class="p">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">generate_json</span><span class="p">,</span>
    <span class="p">};</span>
    <span class="n">rb_rescue</span><span class="p">(</span><span class="n">generate_json_try</span><span class="p">,</span> <span class="p">(</span><span class="n">VALUE</span><span class="p">)</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span> <span class="n">generate_json_rescue</span><span class="p">,</span> <span class="p">(</span><span class="n">VALUE</span><span class="p">)</span><span class="o">&amp;</span><span class="n">data</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">fbuffer_to_s</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffer</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>If you are unfamiliar with the <code class="language-plaintext highlighter-rouge">state = {0};</code> syntax, it’s asking the compiler to zero out the memory it allocated on the stack, because otherwise
our struct would just be initialized with whatever was left on the stack, which isn’t great.</p>

<p>The other important thing to notice here is the <code class="language-plaintext highlighter-rouge">struct generate_json_data</code>, which is defined as this:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="p">{</span>
    <span class="n">FBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">vstate</span><span class="p">;</span>
    <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">;</span>
    <span class="n">VALUE</span> <span class="n">obj</span><span class="p">;</span>
    <span class="n">generator_func</span> <span class="n">func</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<p>That structure isn’t new, it was there before the patch, but you can notice it has both <code class="language-plaintext highlighter-rouge">JSON_Generator_State *state</code>, in other words, a pointer
to the struct holding our configuration, and <code class="language-plaintext highlighter-rouge">VALUE vstate</code> which is a reference to the <code class="language-plaintext highlighter-rouge">TypedData</code> that holds the pointer.</p>

<p>It’s a bit of a duplication, but that avoids some pointer chasing every time the code needs to check if some configuration flag is set.</p>

<p>The <code class="language-plaintext highlighter-rouge">vstate</code> used to be initialized to <code class="language-plaintext highlighter-rouge">self</code>, but now we initialize it to <code class="language-plaintext highlighter-rouge">Qfalse</code>, which conceptually is the global reference to Ruby’s singleton
<code class="language-plaintext highlighter-rouge">false</code> object. But in practice <code class="language-plaintext highlighter-rouge">false</code> is an immediate, and simply <code class="language-plaintext highlighter-rouge">0</code>.</p>

<p>With that in place, I could then implement the lazy initialization. A lot of internal functions used to receive the <code class="language-plaintext highlighter-rouge">vstate</code> as an argument, and in C
arguments are passed by copy, so if I wanted to lazily allocate the <code class="language-plaintext highlighter-rouge">State</code> object, it had to be passed by reference instead.</p>

<p>In short, it meant changing the signature of many functions like this:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gd">- static void generate_json_integer(FBuffer *buffer, VALUE Vstate, JSON_Generator_State *state, VALUE obj)
</span><span class="gi">+ static void generate_json_integer(FBuffer *buffer, struct generate_json_data *data, JSON_Generator_State *state, VALUE obj)</span></code></pre></figure>

<p>And then change the one place where we call <code class="language-plaintext highlighter-rouge">#to_json</code>, to use a new <code class="language-plaintext highlighter-rouge">vstate_get</code> helper:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gd">- tmp = rb_funcall(obj, i_to_json, 1, Vstate);
</span><span class="gi">+ tmp = rb_funcall(obj, i_to_json, 1, vstate_get(data));</span></code></pre></figure>

<p>Which is in concept very similar to the class memoization pattern in Ruby:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">vstate_spill</span><span class="p">(</span><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">vstate</span> <span class="o">=</span> <span class="n">cState_s_allocate</span><span class="p">(</span><span class="n">cState</span><span class="p">);</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">vstate</span><span class="p">);</span>
    <span class="n">MEMCPY</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">state</span><span class="p">,</span> <span class="n">JSON_Generator_State</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">data</span><span class="o">-&gt;</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="p">;</span>
    <span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span> <span class="o">=</span> <span class="n">vstate</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">static</span> <span class="kr">inline</span> <span class="n">VALUE</span> <span class="nf">vstate_get</span><span class="p">(</span><span class="k">struct</span> <span class="n">generate_json_data</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">vstate_spill</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">data</span><span class="o">-&gt;</span><span class="n">vstate</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>As always, C code makes it a bit cryptic, but you should be able to recognize the memoization pattern in <code class="language-plaintext highlighter-rouge">vstate_get</code>.</p>

<p>As for <code class="language-plaintext highlighter-rouge">vstate_spill</code>, spilling is a term often used when moving data from registers onto the RAM because it can’t fit there anymore.
Similarly here, we’re “spilling” the <code class="language-plaintext highlighter-rouge">JSON_Generator_State</code> struct from the stack onto the heap.</p>

<p>We also update the <code class="language-plaintext highlighter-rouge">data-&gt;state</code> pointer, so that if the <code class="language-plaintext highlighter-rouge">#to_json</code> method we called mutate the configuration,
it’s immediately reflected (but please don’t do this, I beg you).</p>

<p>As predicted by the flame graph, avoiding this allocation had a massive impact on micro-benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   506.104k i/100ms
Calculating -------------------------------------
               after      5.389M (± 0.2%) i/s  (185.57 ns/i) -     27.330M in   5.071556s

Comparison:
              before:  3113113.5 i/s
               after:  5388830.4 i/s - 1.73x  faster
</code></pre></div></div>

<p>Enough of a jump that <code class="language-plaintext highlighter-rouge">JSON.generate</code> performance was now almost on par with re-using the <code class="language-plaintext highlighter-rouge">JSON::State</code> object, and a bit ahead of <code class="language-plaintext highlighter-rouge">Oj</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                json   613.914k i/100ms
        json (reuse)   624.068k i/100ms
                  oj   545.935k i/100ms
Calculating -------------------------------------
                json      6.550M (± 0.1%) i/s  (152.67 ns/i) -     33.151M in   5.061360s
        json (reuse)      6.667M (± 0.1%) i/s  (149.99 ns/i) -     33.700M in   5.054534s
                  oj      5.822M (± 0.1%) i/s  (171.76 ns/i) -     29.480M in   5.063498s

Comparison:
                json:  6549898.9 i/s
        json (reuse):  6667228.7 i/s - 1.02x  faster
                  oj:  5822168.8 i/s - 1.12x  slower
</code></pre></div></div>

<p>And now, the setup cost was finally almost invisible on the flame graph:</p>

<p><img src="/assets/articles/json-5/final-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4abYzY8">Full profile</a></p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>This was the final optimization done to the generator worth detailing here.</p>

<p>Hence, I can finally start talking about the parser in the next part.</p>

<p>I think I’ll only need two, maybe three parts for the parsing side.</p>

<p>Edit: <a href="/ruby/json/2025/01/12/optimizing-ruby-json-part-6.html">Part 6 is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, we showed how we eliminated two malloc/free pairs of calls when generating small JSON documents, and how that put us ahead of Oj when reusing the JSON::State object.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 4</title><link href="https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 4" /><published>2024-12-29T18:21:51+00:00</published><updated>2024-12-29T18:21:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html"><![CDATA[<p><a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html">In the previous post</a>, we established that as long as <code class="language-plaintext highlighter-rouge">ruby/json</code> wasn’t competitive on
micro-benchmarks, public perception wouldn’t change. Since what made <code class="language-plaintext highlighter-rouge">ruby/json</code> appear so bad on micro-benchmarks was its setup cost, we had to
find ways to reduce it further.</p>

<h2 id="spot-the-seven-differences">Spot the Seven Differences</h2>

<p>So I decided to file <a href="https://github.com/ruby/json/issues/655">this performance discrepancy as a bug</a>, and investigate it as such and started
profiling Stephen’s micro-benchmark with both <code class="language-plaintext highlighter-rouge">ruby/json</code> and <code class="language-plaintext highlighter-rouge">oj</code>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"small mixed"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span></code></pre></figure>

<p>As mentioned in previous parts, I expected the extra allocation would be the main issue, and that re-using the <code class="language-plaintext highlighter-rouge">JSON::State</code> object would
put us on par with <code class="language-plaintext highlighter-rouge">Oj</code>, but it’s always good to revalidate our assumptions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
        json (reuse)   467.051k i/100ms
                json   252.570k i/100ms
                  oj   529.741k i/100ms
Calculating -------------------------------------
        json (reuse)      4.857M (± 1.9%) i/s  (205.88 ns/i) -     24.287M in   5.001995s
                json      2.689M (± 0.5%) i/s  (371.86 ns/i) -     13.639M in   5.071865s
                  oj      5.860M (± 0.6%) i/s  (170.65 ns/i) -     29.665M in   5.062753s

Comparison:
        json (reuse):  4857171.1 i/s
                  oj:  5859811.8 i/s - 1.21x  faster
                json:  2689181.9 i/s - 1.81x  slower
</code></pre></div></div>

<p>Even without that extra allocation, we were still 20% slower, that was unexpected, and should be fixed before exploring ways to eliminate the <code class="language-plaintext highlighter-rouge">State</code> allocation.</p>

<p>As always, this meant profiling, but this time I profiled both <code class="language-plaintext highlighter-rouge">ruby/json</code> and <code class="language-plaintext highlighter-rouge">Oj</code> to see where the difference might be:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="n">state</span> <span class="o">=</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><a href="https://share.firefox.dev/3W29huf">Full profile</a></p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"oj"</span>

<span class="no">Oj</span><span class="p">.</span><span class="nf">default_options</span> <span class="o">=</span> <span class="no">Oj</span><span class="p">.</span><span class="nf">default_options</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">mode: :compat</span><span class="p">)</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"string"</span><span class="p">,</span> <span class="p">{</span> <span class="ss">a: </span><span class="mi">1</span><span class="p">,</span> <span class="ss">b: </span><span class="mi">2</span> <span class="p">},</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">Oj</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><a href="https://share.firefox.dev/40d4VTH">Full profile</a></p>

<p>Once I got the two profiles, it was a matter of playing “Spot the seven differences”.</p>

<p><img src="/assets/articles/json-4/oj-flamegraph.png" alt="" /></p>

<p><img src="/assets/articles/json-4/json-flamegraph.png" alt="" /></p>

<p>Something that jumped to me quite quickly, is that on that micro-benchmark, even though we’re re-using our <code class="language-plaintext highlighter-rouge">JSON::State</code> object,
we still spend a significant amount of time allocating and freeing our internal buffer. Still, on the <code class="language-plaintext highlighter-rouge">Oj</code> profile, there wasn’t
any <code class="language-plaintext highlighter-rouge">malloc</code> or <code class="language-plaintext highlighter-rouge">free</code> call. This suggested that <code class="language-plaintext highlighter-rouge">Oj</code> re-used a persistent buffer across calls or allocated it on the stack.</p>

<p>A quick investigation of <code class="language-plaintext highlighter-rouge">Oj</code>’s source code confirmed it was the latter:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">_out</span> <span class="p">{</span>
    <span class="kt">char</span>      <span class="n">stack_buffer</span><span class="p">[</span><span class="mi">4096</span><span class="p">];</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">buf</span><span class="p">;</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">end</span><span class="p">;</span>
    <span class="kt">char</span>     <span class="o">*</span><span class="n">cur</span><span class="p">;</span>
    <span class="c1">// ...</span>
<span class="p">}</span> <span class="o">*</span><span class="n">Out</span><span class="p">;</span>

<span class="c1">// ...</span>

<span class="cm">/* Document-method: dump
 * call-seq: dump(obj, options={})
 *
 * Dumps an Object (obj) to a string.
 * - *obj* [_Object_] Object to serialize as an JSON document String
 * - *options* [_Hash_] same as default_options
 */</span>
<span class="k">static</span> <span class="n">VALUE</span> <span class="nf">dump</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">argv</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">dump_arg</span> <span class="n">arg</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">_out</span>     <span class="n">out</span><span class="p">;</span> <span class="c1">// Stack allocation</span>
    <span class="k">struct</span> <span class="n">_options</span> <span class="n">copts</span> <span class="o">=</span> <span class="n">oj_default_options</span><span class="p">;</span>
    <span class="c1">// ...</span>
<span class="p">}</span></code></pre></figure>

<h2 id="stack-and-heap">Stack and Heap</h2>

<p>Since this post is intended for people not necessarily familiar with C, I need to explain a bit what the stack and the heap are.
This is just meant as a quick introduction.</p>

<p>The heap is most of the RAM available on your system, if you need memory to store some data, you call <code class="language-plaintext highlighter-rouge">malloc(number_of_bytes)</code>
and get a pointer back that is at least as big as the number of bytes you asked for, and once you are done with it you call <code class="language-plaintext highlighter-rouge">free(pointer)</code>.</p>

<p>There are many different allocators (e.g. <code class="language-plaintext highlighter-rouge">jemalloc</code>, <code class="language-plaintext highlighter-rouge">tcmalloc</code>), using various algorithms and techniques to keep track of which memory is used and
how large each allocated chunk is, but even with the best allocators, <code class="language-plaintext highlighter-rouge">malloc</code> and <code class="language-plaintext highlighter-rouge">free</code> are somewhat costly. In addition, if you don’t know upfront
how much memory you actually need, you might need to call <code class="language-plaintext highlighter-rouge">new_pointer = realloc(pointer, new_size)</code> to allocate a larger chunk and copy the content
over and free the old chunk, this is fairly expensive.</p>

<p>And for Ruby C extensions specifically, you generally don’t use <code class="language-plaintext highlighter-rouge">malloc / free / realloc</code>, but <code class="language-plaintext highlighter-rouge">ruby_xmalloc / ruby_xfree / ruby_xrealloc</code>,
which are wrappers around the standard functions which additionally update Ruby GC statistics, so that the GC can trigger after some
threshold is reached which can further increase the cost of heap allocations.</p>

<p>On the other hand, the stack is a memory region that’s preallocated for each native thread, and that is used to store the current state of a function,
such as local variables while calling another function. For instance, if you have a function <code class="language-plaintext highlighter-rouge">f</code> with two <code class="language-plaintext highlighter-rouge">int64_t</code> local variables <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>,
<code class="language-plaintext highlighter-rouge">a</code> will be stored at <code class="language-plaintext highlighter-rouge">stack_pointer + 0</code> and <code class="language-plaintext highlighter-rouge">b</code> at <code class="language-plaintext highlighter-rouge">stack_pointer + 8</code>. And if <code class="language-plaintext highlighter-rouge">f</code> calls into another function <code class="language-plaintext highlighter-rouge">f2</code>, the stack pointer will be
incremented by <code class="language-plaintext highlighter-rouge">16</code> before entering <code class="language-plaintext highlighter-rouge">f2</code>, and restored back to its previous value when returning from <code class="language-plaintext highlighter-rouge">f2</code>.</p>

<p>This makes stack allocations essentially free, at least compared to heap allocations, and it’s almost guaranteed data stored there will be in the CPU
cache as it’s a very “hot” memory region.</p>

<p>But stack allocation isn’t a silver bullet, first because whenever you return from the function that memory should be considered freed, so in many
cases that’s not suitable. You can also not resize (<code class="language-plaintext highlighter-rouge">realloc</code>) it from a callee function.
Additionally, the stack is limited in size.
On most modern UNIX-like systems you got a fairly generous <code class="language-plaintext highlighter-rouge">8MiB</code> of stack space for the main thread, but only <code class="language-plaintext highlighter-rouge">1MiB</code> on Windows.
And most systems give less stack space to additional threads, for instance, Alpine Linux which uses the <code class="language-plaintext highlighter-rouge">musl libc</code> only gives
<code class="language-plaintext highlighter-rouge">128kiB</code> of stack space to additional threads, which really isn’t a lot. That’s why it’s not rare for Ruby C extension maintainers
to get Alpine-specific bug reports.</p>

<h2 id="stack-allocated-buffer-struct">Stack Allocated Buffer Struct</h2>

<p>So stack allocations should be used carefully and reasonably, the conventional wisdom being to not allocate more than <code class="language-plaintext highlighter-rouge">1kiB</code> on the stack, and to only
do it in leaf functions (that don’t call any other functions), or functions that only call into a few known functions.</p>

<p>In our case, the <code class="language-plaintext highlighter-rouge">JSON::State#generate</code> method isn’t a leaf function, and might call into arbitrary Ruby code if it needs to call <code class="language-plaintext highlighter-rouge">#to_json</code> or
<code class="language-plaintext highlighter-rouge">#to_s</code> on an object, so <code class="language-plaintext highlighter-rouge">4kiB</code> seemed a bit excessive to me, but still, we could use stack allocations reasonably to gain some performance.</p>

<p><code class="language-plaintext highlighter-rouge">ruby/json</code> wasn’t just doing one <code class="language-plaintext highlighter-rouge">malloc+free</code> call, but two. The first one in <code class="language-plaintext highlighter-rouge">cState_prepare_buffer</code> allocates the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct, which
contains the buffer metadata, such as its capacity:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">FBufferStruct</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">initial_length</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">capa</span><span class="p">;</span>
<span class="p">}</span> <span class="n">FBuffer</span><span class="p">;</span></code></pre></figure>

<p>That struct being just <code class="language-plaintext highlighter-rouge">32B</code> large, it makes a lot of sense to allocate it on the stack, which would save a pair of <code class="language-plaintext highlighter-rouge">malloc+free</code> calls,
and only increase the stack size by a negligible amount.</p>

<p><a href="https://github.com/ruby/json/pull/657/">You can see the diff</a>, it’s not complicated but requires a lot of small changes across the
codebase. Additionally, since the parser also used <code class="language-plaintext highlighter-rouge">FBuffer</code>, it had to be modified too to embed the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct inside the <code class="language-plaintext highlighter-rouge">JSON_ParserStruct</code>
instead of just keeping a pointer.</p>

<p>The gains were pretty good for such a small change:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   265.435k i/100ms
Calculating -------------------------------------
               after      2.831M (± 1.2%) i/s  (353.28 ns/i) -     14.333M in   5.064502s

Comparison:
              before:  2630445.8 i/s
               after:  2830628.7 i/s - 1.08x  faster
</code></pre></div></div>

<p>But still not enough.</p>

<h2 id="efficient-integer-printing">Efficient Integer Printing</h2>

<p>Before continuing on reducing the setup cost, another thing that surprised me on that profile was the <code class="language-plaintext highlighter-rouge">3.6%</code> spent in <code class="language-plaintext highlighter-rouge">fltoa</code>.
Not that <code class="language-plaintext highlighter-rouge">3.6%</code> is anywhere near a hotspot, but that’s a bit much for such a simple function.
If you are not familiar with C naming conventions, you may wonder what this function is doing. In the C standard library you have
several functions to parse strings as various integer types, such as <code class="language-plaintext highlighter-rouge">atoi</code>, <code class="language-plaintext highlighter-rouge">atol</code>, and <code class="language-plaintext highlighter-rouge">atoll</code>, for <code class="language-plaintext highlighter-rouge">int</code>, <code class="language-plaintext highlighter-rouge">long</code> and <code class="language-plaintext highlighter-rouge">long long</code>
respectively. Why <code class="language-plaintext highlighter-rouge">ato</code>? Because these functions assume a stream of ASCII encoded bytes<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, hence “ASCII to int” -&gt; <code class="language-plaintext highlighter-rouge">atoi</code>. That’s also probably
where the Ruby <code class="language-plaintext highlighter-rouge">#to_i</code> method got its name from.</p>

<p>So here, <code class="language-plaintext highlighter-rouge">fltoa</code> is a <code class="language-plaintext highlighter-rouge">long to ASCII</code> conversion function, and <code class="language-plaintext highlighter-rouge">f</code> is just the namespace for the <code class="language-plaintext highlighter-rouge">fbuffer.h</code> file.</p>

<p>Let’s have a look at how it is done:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">freverse</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">end</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">c</span><span class="p">;</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">end</span> <span class="o">&gt;</span> <span class="n">start</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">c</span> <span class="o">=</span> <span class="o">*</span><span class="n">end</span><span class="p">,</span> <span class="o">*</span><span class="n">end</span><span class="o">--</span> <span class="o">=</span> <span class="o">*</span><span class="n">start</span><span class="p">,</span> <span class="o">*</span><span class="n">start</span><span class="o">++</span> <span class="o">=</span> <span class="n">c</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">long</span> <span class="nf">fltoa</span><span class="p">(</span><span class="kt">long</span> <span class="n">number</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">buf</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">static</span> <span class="kt">char</span> <span class="n">digits</span><span class="p">[]</span> <span class="o">=</span> <span class="s">"0123456789"</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">sign</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="kt">char</span><span class="o">*</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">buf</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="n">number</span> <span class="o">=</span> <span class="o">-</span><span class="n">number</span><span class="p">;</span>
    <span class="k">do</span> <span class="o">*</span><span class="n">tmp</span><span class="o">++</span> <span class="o">=</span> <span class="n">digits</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">];</span> <span class="k">while</span> <span class="p">(</span><span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span><span class="n">tmp</span><span class="o">++</span> <span class="o">=</span> <span class="sc">'-'</span><span class="p">;</span>
    <span class="n">freverse</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">tmp</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">tmp</span> <span class="o">-</span> <span class="n">buf</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_append_long</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">long</span> <span class="n">number</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">20</span><span class="p">];</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>There’s something quite odd here. First, we allocate a <code class="language-plaintext highlighter-rouge">20B</code> buffer on the stack, write the number in reverse in the buffer, reverse the string
and finally copy the stack buffer onto the output buffer.</p>

<p>In Ruby, it would look like:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">DIGITS</span> <span class="o">=</span> <span class="p">(</span><span class="sc">'0'</span><span class="p">..</span><span class="sc">'9'</span><span class="p">).</span><span class="n">to_a</span>

<span class="n">def</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">)</span>
  <span class="n">negative</span> <span class="o">=</span> <span class="n">number</span><span class="p">.</span><span class="n">negative</span><span class="o">?</span>
  <span class="n">number</span> <span class="o">=</span> <span class="n">number</span><span class="p">.</span><span class="n">abs</span>

  <span class="n">buffer</span> <span class="o">=</span> <span class="s">""</span><span class="p">.</span><span class="n">b</span>

  <span class="n">loop</span> <span class="k">do</span>
    <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">DIGITS</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">]</span>
    <span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span>
    <span class="k">break</span> <span class="k">if</span> <span class="n">number</span><span class="p">.</span><span class="n">zero</span><span class="o">?</span>
  <span class="n">end</span>

  <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="s">"-"</span> <span class="k">if</span> <span class="n">negative</span>

  <span class="n">buffer</span><span class="p">.</span><span class="n">reverse</span><span class="o">!</span>
  <span class="n">buffer</span>
<span class="n">end</span></code></pre></figure>

<p>Writing the number in reverse can be a useful trick if you are appending it to an existing buffer of dynamic length because you don’t know upfront
how long the number will be nor where the buffer ends.</p>

<p>But here we’re writing inside a stack buffer of known size and then copying the result, so it’s a bit wasteful.</p>

<p>Instead <a href="https://github.com/ruby/json/pull/656">we can write in the stack buffer backward, starting from the end of the buffer</a>,
and save on having to reverse the digits at the end.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">long</span> <span class="nf">fltoa</span><span class="p">(</span><span class="kt">long</span> <span class="n">number</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">buf</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">static</span> <span class="k">const</span> <span class="kt">char</span> <span class="n">digits</span><span class="p">[]</span> <span class="o">=</span> <span class="s">"0123456789"</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">sign</span> <span class="o">=</span> <span class="n">number</span><span class="p">;</span>
    <span class="kt">char</span><span class="o">*</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">buf</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="n">number</span> <span class="o">=</span> <span class="o">-</span><span class="n">number</span><span class="p">;</span>
    <span class="k">do</span> <span class="o">*</span><span class="n">tmp</span><span class="o">--</span> <span class="o">=</span> <span class="n">digits</span><span class="p">[</span><span class="n">number</span> <span class="o">%</span> <span class="mi">10</span><span class="p">];</span> <span class="k">while</span> <span class="p">(</span><span class="n">number</span> <span class="o">/=</span> <span class="mi">10</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sign</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span><span class="n">tmp</span><span class="o">--</span> <span class="o">=</span> <span class="sc">'-'</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">buf</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#define LONG_BUFFER_SIZE 20
</span><span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_append_long</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">long</span> <span class="n">number</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="n">LONG_BUFFER_SIZE</span><span class="p">];</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">buffer_end</span> <span class="o">=</span> <span class="n">buf</span> <span class="o">+</span> <span class="n">LONG_BUFFER_SIZE</span><span class="p">;</span>
    <span class="kt">long</span> <span class="n">len</span> <span class="o">=</span> <span class="n">fltoa</span><span class="p">(</span><span class="n">number</span><span class="p">,</span> <span class="n">buffer_end</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">fbuffer_append</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">buffer_end</span> <span class="o">-</span> <span class="n">len</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>Here again, it’s a small optimization on a very specific part of the generator, so I crafted a micro-benchmark to see if it had the expected benefits:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"integers"</span><span class="p">,</span> <span class="p">(</span><span class="mi">1_000_000</span><span class="o">..</span><span class="mi">1_001_000</span><span class="p">).</span><span class="nf">to_a</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding integers (8009 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after     9.770k i/100ms
Calculating -------------------------------------
               after     97.929k (± 0.9%) i/s   (10.21 μs/i) -    498.270k in   5.088542s

Comparison:
              before:    88309.9 i/s
               after:    97928.6 i/s - 1.11x  faster
</code></pre></div></div>

<p>Not bad, probably will only be noticeable for documents containing lots of large integers, but also a very simple optimization.</p>

<p>This can probably be optimized further by writing directly in the output buffer so that we don’t need to copy, and maybe even use <code class="language-plaintext highlighter-rouge">log</code> to
compute upfront how many digits the number has, but that was good enough for now, so I went back to reduce setup cost.</p>

<h2 id="using-an-rstring-as-buffer">Using an RString as Buffer</h2>

<p>So I went to profile Stephen’s micro-benchmark again:</p>

<p><img src="/assets/articles/json-4/json-flamegraph-2.png" alt="" /></p>

<p><a href="https://share.firefox.dev/4a4oocr">Full profile</a></p>

<p>As you can see, we’re now calling <code class="language-plaintext highlighter-rouge">malloc</code> and <code class="language-plaintext highlighter-rouge">free</code> half as much, but still 100% more than <code class="language-plaintext highlighter-rouge">Oj</code>, and once we’re done filling our buffer,
we copy all its content in another memory region managed by Ruby when calling <code class="language-plaintext highlighter-rouge">str_enc_new</code> (actually <code class="language-plaintext highlighter-rouge">rb_utf8_str_new</code>, but the profiler doesn’t see it because of inlining).</p>

<p>On micro-benchmarks the copy is negligible, but on larger ones like <code class="language-plaintext highlighter-rouge">twitter.json</code>, it can amount to as much as 4% of the overall runtime:</p>

<p><img src="/assets/articles/json-4/strnew-flamegraph.png" alt="" /></p>

<p>The cost of allocating the String object is close to invisible compared to the copy.</p>

<p>So at that point, you are probably wondering why not simply directly use the Ruby String as our buffer.
We would let Ruby manage the memory right from the start, save the copy, and for micro-benchmarks, we’d probably
fit inside an embedded String (more on that later). We also wouldn’t have to be extra careful to free our internal buffer
in case an exception is raised, so it would eliminate many potential sources of memory leaks.</p>

<p>That’s not exactly a novel idea, there are a bunch of methods inside Ruby itself that do that exact thing, like <code class="language-plaintext highlighter-rouge">Time#strftime</code>,
and <a href="https://github.com/ruby/json/compare/master...etiennebarrie:json:use-ruby-strings">I had prototyped it a couple of month prior during a pairing session</a>
with <a href="https://github.com/etiennebarrie">Étienne Barrié</a>.</p>

<p>So I went on <a href="https://github.com/byroot/json/commit/8e61886e009f4df1e447f1808293f8e62a09c90a">to reimplement that again</a>, given so much had
changed since then that rebasing would have been harder.</p>

<p>Unfortunately, it wasn’t the win you could expect, quite the opposite:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   208.242k i/100ms
Calculating -------------------------------------
               after      2.201M (± 1.0%) i/s  (454.41 ns/i) -     11.037M in   5.015727s

Comparison:
              before:  2648506.5 i/s
               after:  2200665.8 i/s - 1.20x  slower


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   205.000 i/100ms
Calculating -------------------------------------
               after      2.065k (± 1.5%) i/s  (484.37 μs/i) -     10.455k in   5.065262s

Comparison:
              before:     2099.6 i/s
               after:     2064.5 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>It didn’t move the needle on real-world benchmarks, and noticeably degraded performance on micro-benchmarks.</p>

<p><img src="/assets/articles/json-4/rstring-buffer-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/40dqHXk">Full profile</a>.</p>

<p>Why did it end up slower? The answer is it depends. When resizing a Ruby String, Ruby doesn’t simply call <code class="language-plaintext highlighter-rouge">realloc</code> like <code class="language-plaintext highlighter-rouge">ruby/json</code>
does for its raw buffer, it also calls <a href="https://man7.org/linux/man-pages/man3/malloc_usable_size.3.html"><code class="language-plaintext highlighter-rouge">malloc_usable_size</code></a>,
or the platform equivalent, <a href="https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/malloc_size.3.html"><code class="language-plaintext highlighter-rouge">malloc_size</code> on <code class="language-plaintext highlighter-rouge">macOS</code></a>
or <a href="https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/msize?view=msvc-170"><code class="language-plaintext highlighter-rouge">_msize</code> on Windows</a>.</p>

<p><img src="/assets/articles/json-4/str-resize-flamegraph.png" alt="" /></p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="o">*</span>
<span class="nf">rb_gc_impl_realloc</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">objspace_ptr</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">new_size</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">old_size</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snip...</span>

    <span class="n">old_size</span> <span class="o">=</span> <span class="n">objspace_malloc_size</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">old_size</span><span class="p">);</span>
    <span class="n">TRY_WITH_GC</span><span class="p">(</span><span class="n">new_size</span><span class="p">,</span> <span class="n">mem</span> <span class="o">=</span> <span class="n">RB_GNUC_EXTENSION_BLOCK</span><span class="p">(</span><span class="n">realloc</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">new_size</span><span class="p">)));</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">mem</span><span class="p">)</span> <span class="k">return</span> <span class="n">mem</span><span class="p">;</span>
    <span class="n">new_size</span> <span class="o">=</span> <span class="n">objspace_malloc_size</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">new_size</span><span class="p">);</span>

    <span class="c1">// snip...</span>

    <span class="n">objspace_malloc_increase</span><span class="p">(</span><span class="n">objspace</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">new_size</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">MEMOP_TYPE_REALLOC</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">mem</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>This again is to keep the GC statistics up to date and give the opportunity to the GC to trigger if some threshold is hit.</p>

<p>Something I wonder though, and that I ought to investigate, is that <code class="language-plaintext highlighter-rouge">rb_gc_impl_realloc</code> is provided with the known <code class="language-plaintext highlighter-rouge">old_size</code>
and <code class="language-plaintext highlighter-rouge">new_size</code>. Sometimes it’s <code class="language-plaintext highlighter-rouge">0</code> when the called doesn’t know what the size was, but for strings, I believe it does, and yet
data information is simply ignored unless no <code class="language-plaintext highlighter-rouge">malloc_usable_size</code> is available:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">size_t</span>
<span class="nf">objspace_malloc_size</span><span class="p">(</span><span class="n">rb_objspace_t</span> <span class="o">*</span><span class="n">objspace</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">hint</span><span class="p">)</span>
<span class="p">{</span>
<span class="cp">#ifdef HAVE_MALLOC_USABLE_SIZE
</span>    <span class="k">return</span> <span class="n">malloc_usable_size</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
<span class="cp">#else
</span>    <span class="k">return</span> <span class="n">hint</span><span class="p">;</span>
<span class="cp">#endif
</span><span class="p">}</span></code></pre></figure>

<p>Just like <code class="language-plaintext highlighter-rouge">malloc / free</code> etc, the performance of <code class="language-plaintext highlighter-rouge">malloc_usable_size</code> varies a lot depending on the allocator, I haven’t benchmarked
on Linux, nor with <code class="language-plaintext highlighter-rouge">jemalloc</code>, so it’s possible that this overhead would have been negligible there, and that may be why Ruby doesn’t try to skip
that call when possible?</p>

<p>But as mentioned at the end of the last post, we’re here to change perception, so we have to be faster on the machines users are more likely to use
for benchmarking, and that includes <code class="language-plaintext highlighter-rouge">macOS</code> with the default allocator.</p>

<p>In hindsight, there’s something else I could have done to make using a Ruby string as a buffer faster:</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="gh">diff --git a/ext/json/ext/generator/generator.c b/ext/json/ext/generator/generator.c
index da78fe1..effc8cc 100644
</span><span class="gd">--- a/ext/json/ext/generator/generator.c
</span><span class="gi">+++ b/ext/json/ext/generator/generator.c
</span><span class="p">@@ -1024,8 +1024,8 @@</span> static VALUE cState_partial_generate(VALUE self, VALUE obj)
 {
     GET_STATE(self);
 
<span class="gd">-    VALUE string = rb_utf8_str_new(NULL, 0);
-    rb_str_resize(string, state-&gt;buffer_initial_length - 1);
</span><span class="gi">+    VALUE string = rb_str_buf_new(state-&gt;buffer_initial_length - 1);
+    rb_enc_associate_index(string, utf8_encindex);
</span>     SBuffer buffer = {
         .capa = state-&gt;buffer_initial_length - 1,
         .str = string,</code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   290.040k i/100ms
Calculating -------------------------------------
               after      3.127M (± 0.3%) i/s  (319.84 ns/i) -     15.662M in   5.009436s

Comparison:
              before:  2616126.5 i/s
               after:  3126563.7 i/s - 1.20x  faster


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   202.000 i/100ms
Calculating -------------------------------------
               after      2.049k (± 2.9%) i/s  (488.12 μs/i) -     10.302k in   5.032888s

Comparison:
              before:     2114.5 i/s
               after:     2048.7 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>Quite a nice gain for such a small change, and you may wonder what’s so different about these two lines of code.</p>

<h2 id="variable-width-allocation-and-embeded-objects">Variable Width Allocation and Embeded Objects</h2>

<p>When Ruby allocates an object, it doesn’t call <code class="language-plaintext highlighter-rouge">malloc</code> like a C program would.
Instead, it asks the GC for what’s called a “slot”, which means a fixed-size memory region inside a memory page
managed by the GC.</p>

<p>Up until the introduction of <a href="https://bugs.ruby-lang.org/issues/18045">Variable Width Allocation</a> by <a href="https://peterzhu.ca/">Peter Zhu</a> and
<a href="https://www.eightbitraptor.com/">Matt Valentine-House</a> in Ruby 3.2, all Ruby slots were of the same size: <code class="language-plaintext highlighter-rouge">40B</code>.</p>

<p>You might wonder, how can all objects be of the same size if you are able to create strings or arrays of arbitrary size?
That’s because many of the Ruby core types, like <code class="language-plaintext highlighter-rouge">String</code>, <code class="language-plaintext highlighter-rouge">Array</code> etc, have multiple internal representations.</p>

<p>To stick with the <code class="language-plaintext highlighter-rouge">String</code> example, here is a simplified version of what its layout looks like in <code class="language-plaintext highlighter-rouge">rstring.h</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">struct</span> <span class="n">RString</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">RBasic</span> <span class="p">{</span>
      <span class="n">VALUE</span> <span class="n">flags</span><span class="p">;</span>
      <span class="n">VALUE</span> <span class="n">klass</span><span class="p">;</span>
    <span class="p">}</span> <span class="n">basic</span><span class="p">;</span>

    <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
    <span class="k">union</span> <span class="p">{</span>
        <span class="k">struct</span> <span class="p">{</span>
            <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>
            <span class="kt">long</span> <span class="n">capa</span><span class="p">;</span>
        <span class="p">}</span> <span class="n">heap</span><span class="p">;</span>

        <span class="k">struct</span> <span class="p">{</span>
            <span class="kt">char</span> <span class="n">ary</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
        <span class="p">}</span> <span class="n">embed</span><span class="p">;</span>
    <span class="p">}</span> <span class="n">as</span><span class="p">;</span>
<span class="p">};</span></code></pre></figure>

<p>If you are unfamiliar with C’s <code class="language-plaintext highlighter-rouge">union</code>, it means that the struct can contain either of its sub structs.</p>

<p>To better visualize, here’s how Ruby stores the <code class="language-plaintext highlighter-rouge">"Hello World"</code> string:</p>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>length</th>
      <th>*ptr</th>
      <th>capa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x000234</td>
      <td>0xffeff</td>
      <td>11</td>
      <td>Hello Wo</td>
      <td>rld\0</td>
    </tr>
  </tbody>
</table>

<p>Each column is 8 bytes wide, or 64 bits, the first 8 bytes are used to store the object flags, we touched on those before,
the following 8 bytes are used to store a pointer to the object class, and then the last 24 bytes are used to store the string content inside
the object slot.</p>

<p>So you can deduce that strings can be as long as 16 ASCII characters, or rather 15 because you need one byte to store the terminating <code class="language-plaintext highlighter-rouge">NULL</code> byte.
Perhaps you’ve read in the past about this limit, and remember that it was 23 characters. That was true but <a href="https://github.com/ruby/ruby/pull/7908">was recently changed by Peter</a>
because it required packing the embedded length inside the <code class="language-plaintext highlighter-rouge">flags</code> bitmap instead, which made things slower. That’s your classic memory usage vs execution speed tradeoff.</p>

<p>Now if we try to append content to that string, and go past the embedded capacity, say, 200 characters long, it will call <code class="language-plaintext highlighter-rouge">malloc(201)</code>, store the string content inside
that malloced region and the object slot will look like this instead:</p>

<table>
  <thead>
    <tr>
      <th>flags</th>
      <th>klass</th>
      <th>length</th>
      <th>*ptr</th>
      <th>capa</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0x000234</td>
      <td>0xffeff</td>
      <td>200</td>
      <td>0xbbbef</td>
      <td>200</td>
    </tr>
  </tbody>
</table>

<p>But with the introduction of Variable Width Allocation, slots are still fixed-sized in a way, but there are now multiple sizes: <code class="language-plaintext highlighter-rouge">40</code>, <code class="language-plaintext highlighter-rouge">80</code>, <code class="language-plaintext highlighter-rouge">160</code>,
<code class="language-plaintext highlighter-rouge">320</code> and <code class="language-plaintext highlighter-rouge">640</code>. A slot can’t grow in size, so in the above scenario where we appended to a string, nothing changes, Ruby will still have to “spill”
the content on the string on the heap by calling <code class="language-plaintext highlighter-rouge">malloc</code>.</p>

<p>However, if we ask Ruby upfront for a larger string, it will make sure to allocate a larger slot for it if that allows it to be embedded.</p>

<p>In the diff above I call <code class="language-plaintext highlighter-rouge">rb_str_buf_new(state-&gt;buffer_initial_length - 1)</code> or <code class="language-plaintext highlighter-rouge">rb_str_buf_new(511)</code>, so on Ruby 3.2+, Ruby will allocate a <code class="language-plaintext highlighter-rouge">640B</code>
wide slot for us, allowing us to store up to <code class="language-plaintext highlighter-rouge">640 - 24 - 1 = 615</code> bytes before having to spill on the heap, and given our micro-benchmark only needs <code class="language-plaintext highlighter-rouge">34B</code>
it means no <code class="language-plaintext highlighter-rouge">malloc</code> nor <code class="language-plaintext highlighter-rouge">free</code> call for the buffer, only a Ruby object slot allocation, which is way cheaper in most cases.</p>

<p>Since we’ll need to ask Ruby to allocate us an object slot so we can return a String object, we might as well ask for a larger one in case we can 
fit in it. If the cost for a <code class="language-plaintext highlighter-rouge">40B</code> or <code class="language-plaintext highlighter-rouge">640B</code> slot is the same, might as well get the bigger one.</p>

<p>In addition to saving on the <code class="language-plaintext highlighter-rouge">malloc</code> call, we also save on the <code class="language-plaintext highlighter-rouge">free</code> call. When GC triggers and there’s no longer any reference to that slot, Ruby
will just mark the slot as available.</p>

<p>But I didn’t think of this at that time, so maybe that’s something I’ll need to revisit in the future.</p>

<h2 id="be-nice-to--your-mother">Be Nice To  Your Mother</h2>

<p>Instead <a href="https://github.com/ruby/json/commit/fe607f4806ac1d448c1ea5ae7324fdbab183d2ca">I resigned myself to using a stack allocation for the buffer content too</a>.
But I went with a much more conservative size than <code class="language-plaintext highlighter-rouge">Oj</code>, a mere <code class="language-plaintext highlighter-rouge">512B</code>.</p>

<p>The implementation is rather simple, I simply had to add one extra <code class="language-plaintext highlighter-rouge">type</code> field inside the <code class="language-plaintext highlighter-rouge">FBuffer</code> struct
to keep track of the buffer provenance, so that we behave a bit differently inside <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> if the buffer is on the stack.
Here’s the implementation with some extra comments:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">fbuffer_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">requested</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">required</span><span class="p">;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="o">!</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">);</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">initial_length</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">required</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">;</span> <span class="n">requested</span> <span class="o">&gt;</span> <span class="n">required</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">;</span> <span class="n">required</span> <span class="o">&lt;&lt;=</span> <span class="mi">1</span><span class="p">);</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">required</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">type</span> <span class="o">==</span> <span class="n">STACK</span><span class="p">)</span> <span class="p">{</span>
                <span class="c1">// If the buffer is on the stack</span>
                <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">old_buffer</span> <span class="o">=</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">;</span>
                <span class="c1">// We allocate a larger buffer on the heap</span>
                <span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">ALLOC_N</span><span class="p">(</span><span class="kt">char</span><span class="p">,</span> <span class="n">required</span><span class="p">);</span>
                <span class="c1">// Mark it as now being on the heap</span>
                <span class="n">fb</span><span class="o">-&gt;</span><span class="n">type</span> <span class="o">=</span> <span class="n">HEAP</span><span class="p">;</span>
                <span class="c1">// Copy the old content over</span>
                <span class="n">MEMCPY</span><span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">,</span> <span class="n">old_buffer</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">REALLOC_N</span><span class="p">(</span><span class="n">fb</span><span class="o">-&gt;</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">char</span><span class="p">,</span> <span class="n">required</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">=</span> <span class="n">required</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>This had the expected effect on micro-benchmarks, a nice 7% improvement:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   286.112k i/100ms
Calculating -------------------------------------
               after      3.024M (± 0.7%) i/s  (330.67 ns/i) -     15.164M in   5.014435s

Comparison:
              before:  2836034.1 i/s
               after:  3024200.8 i/s - 1.07x  faster
</code></pre></div></div>

<p>However, I quickly noticed that it also became way slower on real-world benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   156.000 i/100ms
Calculating -------------------------------------
               after      1.572k (± 1.7%) i/s  (636.13 μs/i) -      7.956k in   5.062686s

Comparison:
              before:     2134.0 i/s
               after:     1572.0 i/s - 1.36x  slower
</code></pre></div></div>

<p>While I was determined to spend a lot of effort in improving <code class="language-plaintext highlighter-rouge">ruby/json</code> performance on micro-benchmarks, degrading its performance
on real-world benchmarks was a huge red line for me, so I had to figure out what happened.</p>

<p>So I went back to my profiler, and started playing “Spot the seven differences” again:</p>

<p>Before:</p>

<p><img src="/assets/articles/json-4/before.png" alt="" /></p>

<p>After:</p>

<p><img src="/assets/articles/json-4/after.png" alt="" /></p>

<p>It’s far from obvious if you don’t know what to look for, but you can see that before we were spending <code class="language-plaintext highlighter-rouge">50%</code> of the runtime in <code class="language-plaintext highlighter-rouge">generate_json_string</code>, and afterward, only <code class="language-plaintext highlighter-rouge">3.1%</code>
and instead, the top was trusted by a bunch of smaller functions called by <code class="language-plaintext highlighter-rouge">generate_json_string</code>.</p>

<p>These are the signs of what is sometimes referred to as “the mother of all optimizations”: inlining.</p>

<p>Even in C, calling a function isn’t that cheap. It’s cheap enough that you generally don’t think about it but costly enough that you try to minimize
function calls in hotspots.</p>

<p>You can do that by refactoring your code to use bigger functions, or even copying code around using macros, but that gets old quickly.
Instead, the compiler does that for us, it identifies the small leaf functions that aren’t worth calling and instead copies its content inside the parent,
even if it means copy-pasting it dozens and dozens of times. In addition to saving on the overhead of a function call, it also allows to optimize the caller
and callee together, sometimes allowing to eliminate redundant computations or simply dead code.</p>

<p>That’s what the <code class="language-plaintext highlighter-rouge">inline</code> keyword is for in the <code class="language-plaintext highlighter-rouge">static inline void fbuffer_inc_capa...</code> declaration, it’s a way to tell the compiler that it would be
a good idea to inline this function. But that’s all it is, just a compiler hint, the compiler can still decide that you are wrong and that it knows better.</p>

<p>I don’t know the intricacies of <code class="language-plaintext highlighter-rouge">LLVM/clang</code> enough to know for certain why it decided to no longer inline all these functions, but I guessed that it
was because I made <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> much larger.</p>

<p>The reason it’s important <code class="language-plaintext highlighter-rouge">fbuffer_inc_capa</code> is inlined, is because 99%+ of the time, we return from it after just a very simple comparison:
<code class="language-plaintext highlighter-rouge">RB_UNLIKELY(requested &gt; fb-&gt;capa - fb-&gt;len)</code>. That’s the part we want inlined, so we don’t pay for a function call just for that check.
The rest of the function we don’t care so much, we rarely ever go into it.</p>

<p>So to appease the compiler, and make that conditional appealing to inline again, <a href="https://github.com/ruby/json/commit/41c021580e48754aa4bfc71c8363b1fb233ed8c8">the solution would be to extract the large amount of code that is
rarely executed in another function that isn’t marked as <code class="language-plaintext highlighter-rouge">inline</code></a>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">fbuffer_do_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// snip...</span>
<span class="p">}</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="kt">void</span> <span class="nf">fbuffer_inc_capa</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">fb</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">requested</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">requested</span> <span class="o">&gt;</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">capa</span> <span class="o">-</span> <span class="n">fb</span><span class="o">-&gt;</span><span class="n">len</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">fbuffer_do_inc_capa</span><span class="p">(</span><span class="n">fb</span><span class="p">,</span> <span class="n">requested</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>Running the benchmarks again with both changes, we finally had what we expected:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   290.616k i/100ms
Calculating -------------------------------------
               after      3.093M (± 0.3%) i/s  (323.30 ns/i) -     15.693M in   5.073761s

Comparison:
              before:  2829771.3 i/s
               after:  3093060.4 i/s - 1.09x  faster


== Encoding twitter.json (466906 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   208.000 i/100ms
Calculating -------------------------------------
               after      2.088k (± 0.5%) i/s  (479.01 μs/i) -     10.608k in   5.081469s

Comparison:
              before:     2108.3 i/s
               after:     2087.6 i/s - same-ish: difference falls within error
</code></pre></div></div>

<p>We squeezed a tiny bit more performance on the micro-benchmark, and the real work benchmark wasn’t noticeably impacted.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>At that point, with all the above optimizations, we were now faster than <code class="language-plaintext highlighter-rouge">Oj</code> when reusing the <code class="language-plaintext highlighter-rouge">JSON::State</code> object,
but still quite a bit slower when allocating it on every call:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.1 (2024-12-25 revision 48d4efcb85) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
        json (reuse)   619.700k i/100ms
                json   291.441k i/100ms
                  oj   532.966k i/100ms
Calculating -------------------------------------
        json (reuse)      6.628M (± 4.9%) i/s  (150.88 ns/i) -     33.464M in   5.064856s
                json      3.191M (± 0.5%) i/s  (313.35 ns/i) -     16.029M in   5.022818s
                  oj      5.873M (± 0.9%) i/s  (170.26 ns/i) -     29.846M in   5.082087s

Comparison:
        json (reuse):  6627811.3 i/s
                  oj:  5873337.3 i/s - 1.13x  slower
                json:  3191361.6 i/s - 2.08x  slower
</code></pre></div></div>

<p>So there was no way around it, I had to find how to automatically re-use that <code class="language-plaintext highlighter-rouge">JSON::State</code> object. Or how to not allocate it at all?</p>

<p>But that’s a story for <a href="/ruby/json/2025/01/04/optimizing-ruby-json-part-5.html">the next part</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>In the initial version of this post I wrongly assumed the <code class="language-plaintext highlighter-rouge">a</code> suffix was referring to “arrays of bytes”. Thanks to f33d5173 and ciupicri for lettingme know the real meaning on HN. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, we established that as long as ruby/json wasn’t competitive on micro-benchmarks, public perception wouldn’t change. Since what made ruby/json appear so bad on micro-benchmarks was its setup cost, we had to find ways to reduce it further.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 3</title><link href="https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 3" /><published>2024-12-27T09:05:51+00:00</published><updated>2024-12-27T09:05:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html"><![CDATA[<p><a href="/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html">In the previous post</a>, I covered how I reimplemented <code class="language-plaintext highlighter-rouge">JSON::Generator::State#configure</code>
in Ruby and some other changes. Unfortunately, it didn’t go as well as I initially thought.</p>

<h2 id="mistakes-were-made">Mistakes Were Made</h2>

<p>The default gems that ship with Ruby are automatically copied inside <code class="language-plaintext highlighter-rouge">ruby/ruby</code>’s repo.
In short, there’s a bot aptly named <a href="https://github.com/matzbot">matzbot</a>, that replicates all the commits from the various <code class="language-plaintext highlighter-rouge">ruby/*</code> gems,
inside <code class="language-plaintext highlighter-rouge">ruby/ruby</code>, and <a href="https://github.com/ruby/ruby/commit/0e2ac4658430ae5c8beba36e0b608902b3404879">that’s what it did with my <code class="language-plaintext highlighter-rouge">State#configure</code> patch</a>.</p>

<p>The reason is that Ruby runs on many different platforms and its CI tests many different compilers, in different versions, and also test builds
with various compilation flags enabled to hopefully catch some subtle bugs, these gems will ultimately ship as part of Ruby, so they might as
well, be tested together.</p>

<p>Depending on which files the commit touches, it can trigger up to 150 CI tasks just on GitHub:</p>

<p><img src="/assets/articles/json-3/gha.png" alt="" /></p>

<p>And that’s only the beginning, after such a commit is merged, there are other secondary CIs maintained by core contributors which will
test Ruby on various OS and platforms that are hard to integrate into GitHub actions, such as Solaris and some CPU architectures
I barely know the existence of.</p>

<p>This is centralized in a channel inside Ruby committers’ Slack: <code class="language-plaintext highlighter-rouge">#alert-emoji</code>.</p>

<p>On October 17th, Mame pinged me because that <code class="language-plaintext highlighter-rouge">State#configure</code> commit <a href="https://github.com/ruby/ruby/actions/runs/11384118908">started making builds fail</a>,
with this crash report:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Assertion Failed: ../src/vm_core.h:1394:VM_ENV_FLAGS:FIXNUM_P(flags)
ruby 3.4.0dev (2024-10-17T11:35:33Z master 0e2ac46584) +PRISM [i686-linux-gnu]

-- Control frame information -----------------------------------------------
Assertion Failed: ../src/vm_core.h:1394:VM_ENV_FLAGS:FIXNUM_P(flags)
ruby 3.4.0dev (2024-10-17T11:35:33Z master 0e2ac46584) +PRISM [i686-linux-gnu]

Crashed while printing bug report
running file: /home/runner/work/ruby/ruby/src/test/json/json_common_interface_test.rb

A test worker crashed. It might be an interpreter bug or
a bug in test/unit/parallel.rb. Try again without the -j
option.
</code></pre></div></div>

<p>This is the worst for me. Normally when Ruby runs into a SEGV or some other bug, before it exits, it collects lots of debug information
including the native C stacktrace, and print a useful report that helps a lot in the debugging process.</p>

<p>But sometimes, the process is corrupted enough, that the crash reporter itself crashes while trying to collect that data, and that’s what happened here.</p>

<p>Yet, we still have a few information. Since we failed an assertion, we do know which condition was wrong:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kr">inline</span> <span class="kt">unsigned</span> <span class="kt">long</span>
<span class="nf">VM_ENV_FLAGS</span><span class="p">(</span><span class="k">const</span> <span class="n">VALUE</span> <span class="o">*</span><span class="n">ep</span><span class="p">,</span> <span class="kt">long</span> <span class="n">flag</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">ep</span><span class="p">[</span><span class="n">VM_ENV_DATA_INDEX_FLAGS</span><span class="p">];</span>
    <span class="n">VM_ASSERT</span><span class="p">(</span><span class="n">FIXNUM_P</span><span class="p">(</span><span class="n">flags</span><span class="p">));</span> <span class="c1">// CRASHED HERE.</span>
    <span class="k">return</span> <span class="n">flags</span> <span class="o">&amp;</span> <span class="n">flag</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>And we also do know that the crash was triggered by a test inside <code class="language-plaintext highlighter-rouge">test/json/json_common_interface_test.rb</code>, but not which one exactly.</p>

<p>Unfortunately, for some reason, I’m still not quite clear on why the crash would only happen on <code class="language-plaintext highlighter-rouge">i686</code>, aka 32-bit Intel, and all I have is an arm64 machine (I really should do something about that).
In some cases, you can use emulation layers, but it’s terribly slow, so I was looking at hours of compilation, and generally when emulating another
architecture you can’t use debuggers like <code class="language-plaintext highlighter-rouge">gdb</code> or <code class="language-plaintext highlighter-rouge">lldb</code> so it’s not that helpful.</p>

<p>So that’s where I called a favor from my colleague <a href="https://peterzhu.ca/">Peter Zhu</a>, who owns an x86_64 machine, to ask him if he could get me a proper
backtrace or something, and generally give me some more information about what was going on.</p>

<p>But Peter being Peter, <a href="https://github.com/ruby/json/pull/621">he directly opened a pull request on <code class="language-plaintext highlighter-rouge">ruby/json</code> with the fix</a>.</p>

<p>Turns out, I didn’t introduce the bug, it had been present in the <code class="language-plaintext highlighter-rouge">State#max_nesting=</code> since October 2009, 15 years!
My change caused it to be covered by tests, while before it wasn’t.</p>

<p>But you might wonder what the bug is exactly, so let me explain.</p>

<h3 id="boxing-day">Boxing Day</h3>

<p>In the Ruby VM, object references are held in the <code class="language-plaintext highlighter-rouge">VALUE</code> type, which in short is a pointer type. Meaning on 64-bit hardware it’s a 64-bit integer,
and on 32-bit hardware, it’s a 32-bit integer.</p>

<p>This is so that for objects that are allocated on the heap, their reference is simply a pointer to their location, and there’s no lookup or
transformation needed to access that reference, you simply use it like a normal C pointer. This might seem obvious, but some other VMs don’t do it this way, it’s a tradeoff.</p>

<p>But not all <code class="language-plaintext highlighter-rouge">VALUE</code> references are an actual pointer to an active memory region on the heap, some of them are what is called “immediates”.</p>

<p>This is a technique often referred to as “pointer tagging”, that exploits the fact that pointers are guaranteed to be aligned on 8 bytes, in other words all the pointers you’ll
get from malloc and such will always be divisible by 8, so that <code class="language-plaintext highlighter-rouge">(pointer % 8) == 0</code>, always.</p>

<p>In binary form, that means the last 3 bits of a pointer are always <code class="language-plaintext highlighter-rouge">0</code>, and Ruby would never leave 3 good bits to go to waste.
For objects that are fully immutable, like <code class="language-plaintext highlighter-rouge">Integer</code>, you don’t need them to be stored in allocated memory, you can simply pack them in
the pointer instead, and use these 3 bits as “tag”, to inform Ruby that it’s not a real memory pointer, but an immediate value that needs to be
massaged first to be used.</p>

<p>The way these are used is defined in <a href="https://github.com/ruby/ruby/blob/335bba0fde0c0407377b6e10050ab6c2ad0d3270/include/ruby/internal/special_consts.h#L86-L120">the <code class="language-plaintext highlighter-rouge">ruby_special_consts</code> enum in <code class="language-plaintext highlighter-rouge">special_const.h</code></a>
and can vary based on which architecture Ruby is compiled for, typically 32-bit and 64-bit Rubies are quite different.</p>

<p>Here I’ll just focus on how <code class="language-plaintext highlighter-rouge">Integer</code> is tagged. On both 32 and 64 bits, if the least significant bit is set, then we’re dealing with an immediate integer.</p>

<p>So to know if a reference is an immediate integer, you just have to check that bit:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">RUBY_FIXNUM_FLAG</span> <span class="o">=</span> <span class="mh">0x01</span>

<span class="k">static</span> <span class="kr">inline</span> <span class="n">bool</span>
<span class="nf">RB_FIXNUM_P</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">return</span> <span class="n">obj</span> <span class="o">&amp;</span> <span class="n">RUBY_FIXNUM_FLAG</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">_P</code> prefix is the convention used by Ruby to encode question mark <code class="language-plaintext highlighter-rouge">?</code> into valid C function names, as for <code class="language-plaintext highlighter-rouge">fixnum</code>, that’s how integers small
enough to be immediates were called in the past. Before Ruby 2.4, you had two Integer classes, <code class="language-plaintext highlighter-rouge">Fixnum</code> and <code class="language-plaintext highlighter-rouge">Bignum</code>. The two were merged and now as a Ruby user you can only
observe a single <code class="language-plaintext highlighter-rouge">Integer</code> class, but internally in the virtual machine, they’re still very much distinct.</p>

<p>Based on this to convert a C integer into a Ruby fixnum you use some simple bitwise transformations:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">int_to_fixnum</span><span class="p">(</span><span class="n">int</span><span class="p">)</span>
  <span class="p">(</span><span class="n">int</span> <span class="o">&lt;&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="k">end</span>

<span class="k">def</span> <span class="nf">fixnum_to_int</span><span class="p">(</span><span class="n">fixnum</span><span class="p">)</span>
  <span class="n">fixnum</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span>
<span class="k">end</span>

<span class="nb">p</span><span class="p">(</span><span class="mi">5</span><span class="p">.</span><span class="nf">times</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="n">int_to_fixnum</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="p">})</span> <span class="c1"># =&gt; [1, 3, 5, 7, 9]</span></code></pre></figure>

<p>This sort of conversion is often referred to as “boxing” and “unboxing”, the idea being to take a native integer type, and put it in a “box” so that
it fits the same generic pattern than all other object references. And then when you need to use it you have to “unbox” it back to the native type.</p>

<p>In the Ruby C API, these types of functions are provided as <code class="language-plaintext highlighter-rouge">NUM2&lt;ctype&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;ctype&gt;2NUM</code> or <code class="language-plaintext highlighter-rouge">FIX2&lt;ctype&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;ctype&gt;2FIX</code>, for instance,
to convert a <code class="language-plaintext highlighter-rouge">FIXNUM</code> into a native C <code class="language-plaintext highlighter-rouge">long</code>, you use <code class="language-plaintext highlighter-rouge">FIX2LONG</code>.</p>

<p>Going back to our crash, what Ruby was complaining about, is that it was expecting to read a <code class="language-plaintext highlighter-rouge">FIXNUM</code> on the stack,
but somehow, the <code class="language-plaintext highlighter-rouge">VALUE</code> it read wasn’t a <code class="language-plaintext highlighter-rouge">FIXNUM</code>, as its least significant bit wasn’t set.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_max_nesting_set</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">self</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">depth</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">Check_Type</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">T_FIXNUM</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="n">NUM2LONG</span><span class="p">(</span><span class="n">depth</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>With what I explained above, you might be able to spot that <code class="language-plaintext highlighter-rouge">State#max_nesting=</code> is supposed to return a Fixnum, but actually returns the native C <code class="language-plaintext highlighter-rouge">long</code> integer,
and thanks to C’s weak typing, none of the many compilers Ruby is tested against ever complained about it.</p>

<p>You might also have deduced that this crash would only happen if <code class="language-plaintext highlighter-rouge">depth</code> happens to be an even number.</p>

<p>But also the crash was only happening on debug builds of Ruby, because that function is a setter, so unless you do something weird, the return value
is just dropped on the floor.</p>

<p>But you can easily reproduce it on older versions of the JSON gem:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">VERSION</span>
<span class="o">=&gt;</span> <span class="s2">"2.5.1"</span>
<span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="o">=</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="o">=&gt;</span> <span class="mi">2</span>
<span class="o">&gt;&gt;</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="o">=</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="sr">/opt/</span><span class="n">rubies</span><span class="o">/</span><span class="mf">3.0</span><span class="o">.</span><span class="mi">7</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">ruby</span><span class="o">/</span><span class="mf">3.0</span><span class="o">.</span><span class="mi">0</span><span class="o">/</span><span class="n">pp</span><span class="p">.</span><span class="nf">rb</span><span class="p">:</span><span class="mi">582</span><span class="p">:</span> <span class="p">[</span><span class="no">BUG</span><span class="p">]</span> <span class="no">Segmentation</span> <span class="n">fault</span> <span class="n">at</span> <span class="mh">0x0000000000000014</span>
<span class="n">ruby</span> <span class="mf">3.0</span><span class="o">.</span><span class="mi">7</span><span class="n">p220</span> <span class="p">(</span><span class="mi">2024</span><span class="o">-</span><span class="mo">04</span><span class="o">-</span><span class="mi">23</span> <span class="n">revision</span> <span class="mi">724</span><span class="n">a071175</span><span class="p">)</span> <span class="p">[</span><span class="n">arm64</span><span class="o">-</span><span class="n">darwin23</span><span class="p">]</span>
<span class="o">....</span></code></pre></figure>

<p>But this post is named “Optimizing Ruby’s JSON”, we’re not here to talk about bugs, so let’s move on.</p>

<h2 id="path-splitting">Path Splitting</h2>

<p>After the previous optimizations I mentioned in parts 1 and 2, I still wasn’t satisfied with the <code class="language-plaintext highlighter-rouge">JSON.dump</code> performance.
So I went back to profile the <code class="language-plaintext highlighter-rouge">twitter.json</code> macro benchmark:</p>

<p><img src="/assets/articles/json-3/generate-json-string-flamegraph.png" alt="" /></p>

<p><a href="https://share.firefox.dev/3P3BTzr">Full Profile</a></p>

<p>As you can see, we’re spending 55% (13% + 28% + 14%) of our time in <code class="language-plaintext highlighter-rouge">generate_json_string</code>, and most of that is spent in <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
which is essentially our <code class="language-plaintext highlighter-rouge">escape</code> function.</p>

<p>This makes sense, of all the JSON types, it’s one of the most common and requires some costly scanning and escaping.</p>

<p>Having such an obvious hotspot is pleasant in a way, as it gives you a very specific area to focus on.</p>

<p>Looking more specifically at the heatmap of <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>, we can see that Mame’s precondition check
helps, but we’re still spending quite a lot of time in the slow path, decoding UTF-8.</p>

<p><img src="/assets/articles/json-3/generate-json-string-heatmap.png" alt="" /></p>

<p>That’s because the <code class="language-plaintext highlighter-rouge">twitter.json</code> payload happens to contain mostly Japanese tweets, hence it’s quite UTF-8
heavy, but that’s good, it means it’s not only benchmarking the happy path.</p>

<p>That said, even in this case, actual UTF-8 strings are the minority in the document, most of them are pure ASCII,
as such it would be interesting not to bother decoding UTF-8 at all when we know the string is plain ASCII.</p>

<p>As mentioned in part 1, we already know if the string is pure ASCII upfront, because we asked Ruby to compute the string coderange.</p>

<p>But you may also wonder, why we even bother decoding UTF-8, after all, UTF-8 is a superset of ASCII, and all we care about are <code class="language-plaintext highlighter-rouge">\</code> and <code class="language-plaintext highlighter-rouge">"</code> characters
as well as characters that are <code class="language-plaintext highlighter-rouge">&lt; 0x20</code>. That’s the nice thing with UTF-8, any code that only knows about ASCII will be compatible with UTF-8 as long
as it ignores characters outside the ASCII range.</p>

<p>But the reason we need to care about UTF-8 is the <code class="language-plaintext highlighter-rouge">script_safe: true</code> option. On paper, JSON is an extremely simple spec, but it also somewhat claims
to be a subset of JavaScript, hence you may want to interpolate some JSON inside JavaScript as a way to pass data from Ruby to JS. e.g.</p>

<figure class="highlight"><pre><code class="language-erb" data-lang="erb"><span class="nt">&lt;script&gt;</span>
  <span class="nx">MyLibrary</span><span class="p">.</span><span class="nx">configure</span><span class="p">(</span><span class="cp">&lt;%=</span> <span class="no">MyLib</span><span class="o">::</span><span class="no">CONFIG</span><span class="p">.</span><span class="nf">to_json</span> <span class="cp">%&gt;</span><span class="p">);</span>
<span class="nt">&lt;/script&gt;</span></code></pre></figure>

<p>And this works well except that you need to escape more characters. First forward slashes (<code class="language-plaintext highlighter-rouge">/</code>) to prevent XSS, we touched on that in part 1, but
also two weird characters, the infamous <code class="language-plaintext highlighter-rouge">U+2028</code> and <code class="language-plaintext highlighter-rouge">U+2029</code> characters aka Line Separator and Paragraph Separator.</p>

<p><a href="https://stackoverflow.com/a/9168133">The ECMAScript standard specifies that these two characters are treated as new lines</a>,
and you can’t put newlines in a JavaScript string so you end up with some syntax errors.</p>

<p>So if you plan to embed your JSON in JS, you need to care about characters outside the ASCII range, but here again,
this is the exception, not the common case, as such we should be able to implement a fast path that doesn’t care about that.</p>

<p>You can see <a href="https://github.com/ruby/json/pull/620/commits/2aefa41d51efff154f8bbd24ba6cfa35521cea87">the full commit on GitHub</a>,
but the key part can be understood by just looking at <code class="language-plaintext highlighter-rouge">generate_json_string</code>. Now it dispatches to a much simpler <code class="language-plaintext highlighter-rouge">convert_ASCII_to_JSON</code>
when possible.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="kt">void</span> <span class="nf">generate_json_string</span><span class="p">(</span><span class="n">FBuffer</span> <span class="o">*</span><span class="n">buffer</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">Vstate</span><span class="p">,</span> <span class="n">JSON_Generator_State</span> <span class="o">*</span><span class="n">state</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">obj</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">enc_utf8_compatible_p</span><span class="p">(</span><span class="n">RB_ENCODING_GET</span><span class="p">(</span><span class="n">obj</span><span class="p">)))</span> <span class="p">{</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">rb_str_export_to_enc</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">rb_utf8_encoding</span><span class="p">());</span>
    <span class="p">}</span>

    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="sc">'"'</span><span class="p">);</span>

    <span class="k">switch</span><span class="p">(</span><span class="n">rb_enc_str_coderange</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">case</span> <span class="n">ENC_CODERANGE_7BIT</span><span class="p">:</span>
            <span class="n">convert_ASCII_to_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="k">case</span> <span class="n">ENC_CODERANGE_VALID</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">RB_UNLIKELY</span><span class="p">(</span><span class="n">state</span><span class="o">-&gt;</span><span class="n">ascii_only</span><span class="p">))</span> <span class="p">{</span>
                <span class="n">convert_UTF8_to_ASCII_only_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                <span class="n">convert_UTF8_to_JSON</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">state</span><span class="o">-&gt;</span><span class="n">script_safe</span><span class="p">);</span>
            <span class="p">}</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="nl">default:</span>
            <span class="n">rb_raise</span><span class="p">(</span><span class="n">rb_path2class</span><span class="p">(</span><span class="s">"JSON::GeneratorError"</span><span class="p">),</span> <span class="s">"source sequence is illegal/malformed utf-8"</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">fbuffer_append_char</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="sc">'"'</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>And it had a pretty nice impact:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding twitter.json (466906 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   189.000 i/100ms
Calculating -------------------------------------
               after      1.894k (± 1.2%) i/s  (527.87 μs/i) -      9.639k in   5.088860s

Comparison:
              before:     1489.1 i/s
               after:     1894.4 i/s - 1.27x  faster
</code></pre></div></div>

<p>Note: because Mame’s lookup table patch was almost a year old when I took over the gem, it had to be rebased
and adapted quite a bit, so in reality, Mame’s lookup table patch was applied after this split of <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
<a href="https://github.com/ruby/json/pull/620">as part of a PR that combined both</a>.
If the two commits had been applied in the opposite order I suspect my patch’s impact would have been much smaller, if not null.</p>

<p>The logical followup would have been to also make optimized versions of <code class="language-plaintext highlighter-rouge">convert_</code> methods, that assume <code class="language-plaintext highlighter-rouge">script_safe = false</code>,
allowing to get one more conditional out of the loop. But I didn’t want to have to maintain this many versions of the same subroutine,
as it was already a bit tedious. And anyway, I already had another idea.</p>

<h2 id="dont-ignore-the-not-so-happy-path">Don’t Ignore the “Not So Happy” Path</h2>

<p>While we can expect most JSON strings to be ASCII only, we can also likely assume that even in strings that aren’t pure ASCII,
most of the characters still are in the ASCII range.</p>

<p>The <code class="language-plaintext highlighter-rouge">twitter.json</code> benchmark is a total counter-example because all strings in it are either English or Japanese, so either full ASCII
or close to no ASCII at all.
But over a larger corpus, you’d likely see strings that are mostly ASCII, but a few of them might contain an accent or some symbol.
Even English texts will often contain a couple of characters outside the ASCII range, be it some emojis or some word borrowed from
French to look fancy.</p>

<p>A good example of that is the <code class="language-plaintext highlighter-rouge">ctim_catalog.json</code> benchmark, which contains some French language strings:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="err">//</span><span class="w"> </span><span class="err">...</span><span class="w">
    </span><span class="nl">"areaNames"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"205705993"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705994"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705995"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon bergerie cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705996"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon bergerie jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705998"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon bergerie jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205705999"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon bergerie cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706000"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706001"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Arrière-scène cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706002"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706003"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème balcon cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706004"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2ème Balcon central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706005"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706006"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1er balcon cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706007"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre central"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706008"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre jardin"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"205706009"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Orchestre cour"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"342752287"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Zone physique secrète"</span><span class="w">
    </span><span class="p">}</span><span class="err">,</span></code></pre></figure>

<p>To make it easier to profile <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> in this particular case, I added another micro-benchmark in the suite:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">benchmark_encoding</span> <span class="s2">"mixed utf8"</span><span class="p">,</span> <span class="p">([(</span><span class="s2">"a"</span> <span class="o">*</span> <span class="mi">5000</span><span class="p">)</span> <span class="o">+</span> <span class="s2">"€"</span> <span class="o">+</span> <span class="p">(</span><span class="s2">"a"</span> <span class="o">*</span> <span class="mi">5000</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">500</span><span class="p">)</span></code></pre></figure>

<p>It’s a <code class="language-plaintext highlighter-rouge">10kiB</code> string, with just one character outside the ASCII range, and repeated <code class="language-plaintext highlighter-rouge">500</code> times to reduce
the relative cost of the setup, giving me a profile with 91% of the time spent inside <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code>
and a pretty clear heatmap:</p>

<p><img src="/assets/articles/json-3/mixed-utf8-heatmap.png" alt="" /></p>

<p>All this code <a href="https://github.com/ruby/json/pull/567">had recently been rewritten pretty much from scratch by Luke Shumaker</a> to resolve some
potential licensing issues with the original code from the early days of the gem.
It’s a fairly clear and straightforward implementation that first decodes UTF-8 bytes into 32-bit codepoints, then checks whether escaping is needed.
If it is, we’d then copy all the scanned bytes into the buffer, followed by the escaped character. Otherwise, the loop would just continue onto the next
codepoint.</p>

<p>While this code is very clean and generic, with a good separation of the multiple levels of abstractions, such as bytes and codepoints,
that would make it very easy to extend the escaping logic,
it isn’t taking advantage of many assumptions <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> could make to take shortcuts.</p>

<p>One of these for instance is that there’s no point validating the UTF-8 encoding because Ruby did it for us and it’s impossible to end up inside
<code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> with invalid UTF-8.</p>

<p>Another is that there are only two multi-byte characters we care about, and both start with the same <code class="language-plaintext highlighter-rouge">0xE2</code> byte, so the decoding into codepoints is a bit superfluous.</p>

<p>So what can we do about it? Well, the same thing we do every day Pinky, eliminate conditionals.</p>

<p>You can see <a href="https://github.com/ruby/json/pull/629">the full pull request</a>, but let me try to explain what it does.</p>

<p>To replace the complex conditional that defines if the character needs to be escaped, we can re-use Mame’s lookup table, but with a twist.
Instead of only storing a boolean, which tells us if the character needs to be escaped or not, we can also pack the character length.</p>

<p>Wikipedia has <a href="https://en.wikipedia.org/wiki/UTF-8#Byte_map">a pretty good table to understand how UTF-8 works</a>:</p>

<p><img src="/assets/articles/json-3/utf8-table.png" alt="" /></p>

<p>If we turn this into a lookup table, with just one pointer offset we can efficiently figure out for each byte
if it needs to be escaped or if we have to deal with a multi-byte character:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="kt">char</span> <span class="n">escape_table</span><span class="p">[</span><span class="mi">256</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1">// ASCII Control Characters</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1">// ASCII Characters</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span> <span class="c1">// '"'</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span> <span class="c1">// '\\'</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span>
    <span class="c1">// Continuation byte</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1">// First byte of a 2-byte code point</span>
    <span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span>
    <span class="c1">// First byte of a 4-byte code point</span>
    <span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span>
    <span class="c1">//First byte of a 4+byte code point</span>
    <span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">0</code> here means a single-byte character that doesn’t require escaping, and <code class="language-plaintext highlighter-rouge">&gt;= 2</code> means a multi-byte character.
We also have a second version of that table for the <code class="language-plaintext highlighter-rouge">script_safe: true</code> escaping mode, with forward-slash (<code class="language-plaintext highlighter-rouge">/</code>) set to <code class="language-plaintext highlighter-rouge">1</code>,
and <code class="language-plaintext highlighter-rouge">convert_UTF8_to_JSON</code> takes the table to use as an argument.</p>

<p>In pseudo-Ruby, the function would now look like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">convert_UTF8_to_JSON</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="n">lookup_table</span><span class="p">)</span>
  <span class="n">buffer</span> <span class="o">=</span> <span class="o">+</span><span class="s2">""</span>
  <span class="n">beginning</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">position</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">while</span> <span class="n">position</span> <span class="o">&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">bytesize</span>
    <span class="n">byte</span> <span class="o">=</span> <span class="n">string</span><span class="p">.</span><span class="nf">getbyte</span><span class="p">(</span><span class="n">position</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">escape</span> <span class="o">=</span> <span class="n">lookup_table</span><span class="p">[</span><span class="n">byte</span><span class="p">]</span>
      <span class="k">case</span> <span class="n">escape</span>
      <span class="k">when</span> <span class="mi">1</span>
        <span class="c1"># Copy all the bytes we saw didn't need escaping</span>
        <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">byteslice</span><span class="p">(</span><span class="n">beginning</span><span class="o">..</span><span class="n">position</span><span class="p">)</span>

        <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">escape</span><span class="p">(</span><span class="n">byte</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">beginning</span> <span class="o">=</span> <span class="n">position</span>
      <span class="k">when</span> <span class="mi">3</span>
        <span class="k">if</span> <span class="n">script_safe?</span> <span class="o">&amp;&amp;</span> <span class="n">byte</span> <span class="o">==</span> <span class="mh">0xE2</span> <span class="o">&amp;&amp;</span> <span class="n">string</span><span class="p">.</span><span class="nf">getbyte</span><span class="p">(</span><span class="n">position</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="o">...</span>
          <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">string</span><span class="p">.</span><span class="nf">byteslice</span><span class="p">(</span><span class="n">beginning</span><span class="o">..</span><span class="n">position</span><span class="p">)</span>
          <span class="n">buffer</span> <span class="o">&lt;&lt;</span> <span class="n">escape</span><span class="p">(</span><span class="n">byte</span><span class="p">)</span>
          <span class="n">position</span> <span class="o">+=</span> <span class="mi">3</span>
          <span class="n">beginning</span> <span class="o">=</span> <span class="n">position</span>
        <span class="k">end</span> 
      <span class="k">else</span>
        <span class="n">position</span> <span class="o">+=</span> <span class="n">escape</span>
      <span class="k">end</span>
    <span class="k">else</span>
      <span class="n">position</span> <span class="o">+=</span> <span class="mi">1</span> 
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>Since our assumption is that the overwhelming majority of characters don’t need escaping and are single bytes,
for most iterations, we’re not even going to enter the <code class="language-plaintext highlighter-rouge">if escape</code> condition.</p>

<p>This resulted in the new micro-benchmark being sped up by more than 2x:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding mixed utf8 (5003001 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after    37.000 i/100ms
Calculating -------------------------------------
               after    439.128 (± 8.7%) i/s    (2.28 ms/i) -      2.183k in   5.012174s

Comparison:
              before:      194.6 i/s
               after:      439.1 i/s - 2.26x  faster
</code></pre></div></div>

<p>And the function heatmap shows that we’re now down to pretty much just table lookups:</p>

<p><img src="/assets/articles/json-3/mixed-utf8-heatmap-after.png" alt="" /></p>

<p>However, this, unfortunately, didn’t translate in a particularly measurable gain on the macro-benchmarks, even <code class="language-plaintext highlighter-rouge">ctim_catalog.json</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding citm_catalog.json (500298 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   132.000 i/100ms
Calculating -------------------------------------
               after      1.351k (± 0.5%) i/s  (739.92 μs/i) -      6.864k in   5.078953s

Comparison:
              before:     1330.9 i/s
               after:     1351.5 i/s - 1.02x  faster
</code></pre></div></div>

<p>It doesn’t mean it wasn’t worth optimizing, but I misjudged how much time was spent dealing with this sort of mixed strings, and should have
prioritized another hostspot. But I still merged the improvements, because benchmarks are just arbitrary workloads, someone out there might 
significantly benefit from the improvement.</p>

<p>I also realize now that I’m writing this, that I could have used something other than <code class="language-plaintext highlighter-rouge">3</code> in the lookup table for <code class="language-plaintext highlighter-rouge">0xE2</code> so that we don’t
do any extra work for the 15 other bytes that mark the start of a 3-byte wide codepoint we’re not interested in, and also so that only the
script safe version of the escape table would ever enter this branch of the code.</p>

<h2 id="micro-benchmarks-shouldnt-matter-but-clearly-they-do">Micro-Benchmarks Shouldn’t Matter, But Clearly They Do</h2>

<p>At that point, <code class="language-plaintext highlighter-rouge">ruby/json</code> was now on par with alternatives on macro-benchmarks, and I didn’t have any more immediate ideas on how to speed it up
further.</p>

<p>We were still very significantly slower on micro-benchmarks, but micro-benchmarks as explained before were simply dominated by allocations, and because
of the API exposed by <code class="language-plaintext highlighter-rouge">ruby/json</code> we have to allocate one more object than <code class="language-plaintext highlighter-rouge">oj</code>, so it’s just impossible to match its performance there.</p>

<p>But to me, that wasn’t a big deal, because micro-benchmarks are nowhere near indicative of real-world performance. As demonstrated above,
they can be useful to help focus on optimizing a specific part of a larger system, but other than that, they don’t serve any actual purpose.
Unless of course online flamewars on who got the fastest is your purpose.</p>

<p>Additionally, if somehow you needed to generate a lot of small documents, you could use a lower-level API to elide that allocation,
by reusing the <code class="language-plaintext highlighter-rouge">Generator::State</code> object:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">state</span> <span class="o">=</span> <span class="no">JSON</span><span class="o">::</span><span class="no">State</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span><span class="p">)</span>
<span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">ruby_obj</span><span class="p">)</span>
<span class="n">state</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">another_obj</span><span class="p">)</span></code></pre></figure>

<p>Using this API, <code class="language-plaintext highlighter-rouge">ruby/json</code> was very much on par with alternatives:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small nested array (121 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                  oj   223.200k i/100ms
                json   167.997k i/100ms
        json (reuse)   237.781k i/100ms
Calculating -------------------------------------
                  oj      2.295M (± 1.2%) i/s  (435.64 ns/i) -     11.606M in   5.056904s
                json      1.742M (± 0.2%) i/s  (574.13 ns/i) -      8.736M in   5.015536s
        json (reuse)      2.449M (± 0.2%) i/s  (408.28 ns/i) -     12.365M in   5.048249s

Comparison:
                  oj:  2295492.3 i/s
        json (reuse):  2449294.2 i/s - 1.07x  faster
                json:  1741765.4 i/s - 1.32x  slower


== Encoding small hash (65 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
                  oj   676.718k i/100ms
                json   269.175k i/100ms
        json (reuse)   500.536k i/100ms
Calculating -------------------------------------
                  oj      7.305M (± 0.3%) i/s  (136.90 ns/i) -     36.543M in   5.002601s
                json      2.855M (± 0.2%) i/s  (350.23 ns/i) -     14.535M in   5.090715s
        json (reuse)      5.371M (± 3.7%) i/s  (186.18 ns/i) -     27.029M in   5.041441s

Comparison:
                  oj:  7304845.2 i/s
        json (reuse):  5371216.1 i/s - 1.36x  slower
                json:  2855303.9 i/s - 2.56x  slower
</code></pre></div></div>

<p>So I started working on releasing <code class="language-plaintext highlighter-rouge">json 2.7.3</code>, and announced that from now on, I’d consider
significant performance differences on <em>realistic</em> benchmarks a bug.</p>

<p><img src="/assets/articles/json-3/tweet-release.png" alt="" /></p>

<p>I specifically said <em>realistic</em>, because I had no intention to spent time optimizing for what I consider to be unrealistic micro-benchmarks.</p>

<p>And yet, I pretty quickly got a response saying <code class="language-plaintext highlighter-rouge">ruby/json</code> was 3x slower than <code class="language-plaintext highlighter-rouge">oj</code>:</p>

<p><img src="/assets/articles/json-3/tweet-response.png" alt="" /></p>

<p>So clearly, no amount of communication on how micro-benchmarks don’t matter would be enough to change people’s perceptions.</p>

<p>If I wanted the public perception to change, I had to make <code class="language-plaintext highlighter-rouge">ruby/json</code> faster on micro-benchmarks too, and that meant
reducing the setup cost even further. But that’s a story for the next post.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>In the next post, we’ll dive into how the setup cost was optimized further, and then at some point, we’ll have to
start talking about optimizing the parser.</p>

<p>Edit: <a href="/ruby/json/2024/12/29/optimizing-ruby-json-part-4.html">Part four is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, I covered how I reimplemented JSON::Generator::State#configure in Ruby and some other changes. Unfortunately, it didn’t go as well as I initially thought.]]></summary></entry><entry><title type="html">Optimizing Ruby’s JSON, Part 2</title><link href="https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html" rel="alternate" type="text/html" title="Optimizing Ruby’s JSON, Part 2" /><published>2024-12-18T16:05:51+00:00</published><updated>2024-12-18T16:05:51+00:00</updated><id>https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2</id><content type="html" xml:base="https://byroot.github.io/ruby/json/2024/12/18/optimizing-ruby-json-part-2.html"><![CDATA[<p><a href="/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html">In the previous post</a>, I covered my motivations for improving <code class="language-plaintext highlighter-rouge">ruby/json</code>’s performance,
and detailed the first 4 notable optimizations applied to speed up JSON generation.</p>

<p>If I was to cover every single optimization applied, at this rate I’d end up with a dozen parts, so I’ll try to only focus on the one that made a
significant difference or used an interesting pattern.</p>

<h2 id="reducing-setup-cost---argument-parsing-edition">Reducing Setup Cost - Argument Parsing Edition</h2>

<p>As mentioned in Part 1, When your benchmark only serializes a few dozen bytes of JSON, you end up measuring the baseline overhead of 
operations needed before you get to the actual work you’re here to perform, what I call “setup cost”.</p>

<p>The very high setup cost of <code class="language-plaintext highlighter-rouge">ruby/json</code> made it perform poorly on micro-benchmarks compared to alternatives.</p>

<p>If you look at <a href="https://share.firefox.dev/3BAhuPi">the native profile</a> of <code class="language-plaintext highlighter-rouge">JSON.dump([1, "string", { a: 1, b: 2 }, [3, 4, 5]])</code>,
you can see that we only spend <code class="language-plaintext highlighter-rouge">39%</code> of the time in <code class="language-plaintext highlighter-rouge">cState_generate</code> which is where we’re actually generating JSON, everything else is the setup cost.</p>

<p><img src="/assets/articles/json-2/micro-bench-flamegraph.png" alt="" /></p>

<p>So if we want to make <code class="language-plaintext highlighter-rouge">ruby/json</code> look good on micro-benchmarks, the setup cost is what need to be reduced.</p>

<p>And a big part of that was how <code class="language-plaintext highlighter-rouge">JSON.dump</code> parses the arguments it receives, because <code class="language-plaintext highlighter-rouge">JSON.dump</code> is one of these cursed methods that can be used in
way too many different ways. Aside from the first argument which is the object to serialize, <code class="language-plaintext highlighter-rouge">dump</code> accepts 3 positional arguments that are all optional.</p>

<p>In RDoc style, the signature would be <code class="language-plaintext highlighter-rouge">dump(obj, [anIo], [depth_limit], [options])</code>. This sort of signature is quite common in old gems that predate the
introduction of keyword arguments back in Ruby 2.0, and often cause an explosion of call patterns.</p>

<p>Here are 7 different ways the method can be called.</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({})</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="mi">12</span><span class="p">,</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; "{}"</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">))</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="mi">12</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="mi">12</span><span class="p">,</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span>
<span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">({},</span> <span class="no">File</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="s2">"/tmp/foo.json"</span><span class="p">,</span> <span class="s2">"w+"</span><span class="p">),</span> <span class="ss">strict: </span><span class="kp">true</span><span class="p">)</span> <span class="c1"># =&gt; #&lt;File:/tmp/foo.json&gt;</span></code></pre></figure>

<p>Here’s how the argument parsing was implemented:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="n">io_limit_opt</span> <span class="o">=</span> <span class="p">[</span><span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">].</span><span class="nf">compact</span>
  <span class="n">kwargs</span> <span class="o">=</span> <span class="n">io_limit_opt</span><span class="p">.</span><span class="nf">pop</span> <span class="k">if</span> <span class="n">io_limit_opt</span><span class="p">.</span><span class="nf">last</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
  <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="n">io_limit_opt</span>
  <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_io</span><span class="p">)</span>
    <span class="n">anIO</span> <span class="o">=</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">to_io</span>
  <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:write</span><span class="p">)</span>
    <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">anIO</span>
  <span class="k">end</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">:max_nesting</span> <span class="o">=&gt;</span> <span class="n">limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">limit</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">merge_dump_options</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">if</span> <span class="n">kwargs</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">anIO</span>
    <span class="n">anIO</span><span class="p">.</span><span class="nf">write</span> <span class="n">result</span>
    <span class="n">anIO</span>
  <span class="k">else</span>
    <span class="n">result</span>
  <span class="k">end</span>
<span class="k">rescue</span> <span class="no">JSON</span><span class="o">::</span><span class="no">NestingError</span>
  <span class="k">raise</span> <span class="no">ArgumentError</span><span class="p">,</span> <span class="s2">"exceed depth limit"</span>
<span class="k">end</span></code></pre></figure>

<p>There are a number of operations in there that are reasonably costly in abstract, but costly enough that you don’t want to use them in hot spots.</p>

<p>The first one is <code class="language-plaintext highlighter-rouge">[anIO, limit, kwargs].compact</code>, which is used to ignore <code class="language-plaintext highlighter-rouge">nil</code> arguments. It’s quite pleasing to the eye, and fairly idiomatic Ruby,
but it means one extra allocation, which is a lot on micro-benchmarks.</p>

<p>The alternative we’re trying to catch up to, only allocates a single object on its equivalent path, the returned JSON document as a String.
But <code class="language-plaintext highlighter-rouge">ruby/json</code> also need to allocate the <code class="language-plaintext highlighter-rouge">JSON::Generator::State</code> object, so that’s a total of 3 allocations, 3 times as much as <code class="language-plaintext highlighter-rouge">oj</code> or <code class="language-plaintext highlighter-rouge">rapidjson-ruby</code>.</p>

<p>Allocations aren’t that big of a problem on modern Ruby, it’s actually quite fast, the problem is that allocating will ultimately trigger the GC,
and while that too is negligible when doing a meaningful amount of work, it’s a huge proportion of the runtime in a micro-benchmark.</p>

<p><img src="/assets/articles/json-2/setup-cost-flamegraph.png" alt="" /></p>

<p>Then, there’s the <code class="language-plaintext highlighter-rouge">respond_to?(:to_io)</code> call (and sometimes the second one), which too is totally mundane and idiomatic Ruby code, but something
you want to avoid in hot paths.</p>

<p><code class="language-plaintext highlighter-rouge">respond_to?</code> does all the same work a method call does to find which method to call, but the major difference is that method calls have an inline cache
while <code class="language-plaintext highlighter-rouge">respond_to?</code> doesn’t, so it has to do more work than most method calls.</p>

<h3 id="method-lookup">Method Lookup</h3>

<p>To give you an idea of how much work looking up a method without a cache can entail, here is what it would look like if implemented in Ruby</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Object</span>
  <span class="k">def</span> <span class="nf">respond_to?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">ancestor</span><span class="o">|</span>
      <span class="k">return</span> <span class="kp">true</span> <span class="k">if</span> <span class="n">ancestor</span><span class="p">.</span><span class="nf">methods_hash</span><span class="p">.</span><span class="nf">key?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="k">end</span>

    <span class="c1"># object doesn't respond to `method` but maybe it has a `respond_to_missing?` method.</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">ancestor</span><span class="o">|</span>
      <span class="k">if</span> <span class="n">respond_to_missing</span> <span class="o">=</span> <span class="n">ancestor</span><span class="p">.</span><span class="nf">methods_hash</span><span class="p">[</span><span class="ss">:respond_to_missing?</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">respond_to_missing</span><span class="p">.</span><span class="nf">bind_call</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="nb">method</span><span class="p">)</span>
      <span class="k">end</span>
    <span class="k">end</span>

    <span class="kp">false</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>If you assume most of the time <code class="language-plaintext highlighter-rouge">anIO</code> is <code class="language-plaintext highlighter-rouge">nil</code>, that’s a lot of needless hash lookups, because <code class="language-plaintext highlighter-rouge">nil</code> has way more ancestors than you’d think:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 4</span>
<span class="nb">require</span> <span class="s2">"json"</span>
<span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 6</span>
<span class="nb">require</span> <span class="s2">"active_support/all"</span>
<span class="nb">p</span> <span class="kp">nil</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">ancestors</span><span class="p">.</span><span class="nf">size</span> <span class="c1"># =&gt; 9</span></code></pre></figure>

<p>And on a miss, you might actually have to do all that a second time, to check if perhaps that class implements <code class="language-plaintext highlighter-rouge">#respond_to_missing</code>.</p>

<p>As mentioned, calling a method conceptually requires as much work, however, most method calls don’t result in a <code class="language-plaintext highlighter-rouge">NoMethodError</code> so you normally don’t
go all the way up the ancestor chain, and more importantly method calls have inline caches.</p>

<h3 id="inline-caches">Inline Caches</h3>

<p><a href="https://railsatscale.com/2023-10-24-memoization-pattern-and-object-shapes/#inline-caches">I touched a bit on what inline caches are last year in my post about object shapes</a>,
but to reiterate here, when Ruby compiles your code into YARV bytecode, for every method call it leaves a little bit of space called an inline cache.</p>

<p>For instance, if Ruby has to execute <code class="language-plaintext highlighter-rouge">nil.bar</code>, it will compile that into an <code class="language-plaintext highlighter-rouge">opt_send_without_block</code> instruction:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sx">%{nil.bar}</span><span class="p">).</span><span class="nf">disasm</span>
<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(1,7)&gt;</span>
<span class="mo">0000</span> <span class="n">putnil</span>                                                           <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:bar</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="n">leave</span></code></pre></figure>

<p>Which down the line will end up in <a href="https://github.com/ruby/ruby/blob/8417d09f9381c93352fe2cddbdfd4144b5924979/vm_insnhelper.c#L2256-L2279"><code class="language-plaintext highlighter-rouge">vm_search_method_fastpath</code></a>, that has access to <code class="language-plaintext highlighter-rouge">cc</code> AKA a “callcache”.
The actual method is a bit hard to read with lots of asserts etc, but here’s a stripped-down version that should be easy to understand:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">const</span> <span class="k">struct</span> <span class="n">rb_callcache</span> <span class="o">*</span>
<span class="nf">vm_search_method_fastpath</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">cd_owner</span><span class="p">,</span> <span class="k">struct</span> <span class="n">rb_call_data</span> <span class="o">*</span><span class="n">cd</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">klass</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="k">struct</span> <span class="n">rb_callcache</span> <span class="o">*</span><span class="n">cc</span> <span class="o">=</span> <span class="n">cd</span><span class="o">-&gt;</span><span class="n">cc</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">LIKELY</span><span class="p">(</span><span class="n">cc</span><span class="o">-&gt;</span><span class="n">klass</span> <span class="o">==</span> <span class="n">klass</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">LIKELY</span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">cc</span><span class="o">-&gt;</span><span class="n">cme</span><span class="o">-&gt;</span><span class="n">flags</span> <span class="o">&amp;</span> <span class="n">INVALIDATED_FLAG</span><span class="p">))))</span> <span class="p">{</span>
            <span class="k">return</span> <span class="n">cc</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">vm_search_method_slowpath0</span><span class="p">(</span><span class="n">cd_owner</span><span class="p">,</span> <span class="n">cd</span><span class="p">,</span> <span class="n">klass</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>So in short, every single call site has a cache that contains the class of the last object this method was called on, and the result of the previous search.
Revalidating that cache is just a simple pointer comparison to ensure we’re still dealing with an instance of the same class,
and a check in a bitmap to ensure the cache wasn’t invalidated by something like <code class="language-plaintext highlighter-rouge">define_method</code> or <code class="language-plaintext highlighter-rouge">remove_method</code>.</p>

<p>That is a ton less work than the slow path, and since in practice most call sites are “monomorphic”, meaning they only ever apply to a single type,
this cache hit rate is fairly high.</p>

<p>The problem with <code class="language-plaintext highlighter-rouge">respond_to?</code> is that the name of the method we’re looking for is passed as an argument:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="o">&gt;&gt;</span> <span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="sx">%{nil.respond_to?(:bar)}</span><span class="p">).</span><span class="nf">disasm</span>
<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(1,21)&gt;</span>
<span class="mo">0000</span> <span class="n">putnil</span>                                                           <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">putobject</span>                              <span class="ss">:bar</span>
<span class="mo">0003</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:respond_to?</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0005</span> <span class="n">leave</span></code></pre></figure>

<p>So here we have a call cache to lookup <code class="language-plaintext highlighter-rouge">respond_to?</code> on <code class="language-plaintext highlighter-rouge">nil</code>, but nowhere to cache the lookup of <code class="language-plaintext highlighter-rouge">bar</code>.</p>

<p>It actually wouldn’t be too hard to add such a cache, we’d need to modify the Ruby compiler to compile
<code class="language-plaintext highlighter-rouge">respond_to?</code> calls into a specialized <code class="language-plaintext highlighter-rouge">opt_respond_to</code> instruction that does have two caches instead of one.
The first cache would be used to look up <code class="language-plaintext highlighter-rouge">respond_to?</code> on the object to make sure it wasn’t redefined,
and the second one to look up the method we’re interested in. Or perhaps even 3 caches, as you also need to
check if the object has a <code class="language-plaintext highlighter-rouge">respond_to_missing?</code> method defined in some cases.</p>

<p>That’s an idea I remember discussing in the past with some fellow committers, but I can’t quite remember if
there was a reason we didn’t do it yet.</p>

<h3 id="nested-caching">Nested Caching</h3>

<p>That said, even without inline caches, <code class="language-plaintext highlighter-rouge">respond_to?</code> usually avoids doing the full method lookup.</p>

<p>Given how horrendously expensive they are, method lookups have two layers of cache.
Inside the <code class="language-plaintext highlighter-rouge">Class</code> object structure, there is a field called <code class="language-plaintext highlighter-rouge">cc_tbl</code> for “call cache table”.
That’s essentially a Hash with method names as keys, and “call caches” as values.</p>

<p>So <code class="language-plaintext highlighter-rouge">respond_to?</code>’s implementation is actually more like this:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Object</span>
  <span class="k">def</span> <span class="nf">respond_to?</span><span class="p">(</span><span class="nb">method</span><span class="p">)</span>
    <span class="n">cc</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">call_cache</span><span class="p">[</span><span class="nb">method</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">method_entry</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">search_method_with_cache</span><span class="p">(</span><span class="nb">method</span><span class="p">,</span> <span class="n">cc</span><span class="p">)</span>
      <span class="k">return</span> <span class="kp">true</span>
    <span class="k">end</span>

    <span class="n">respond_to_missing_cc</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">call_cache</span><span class="p">[</span><span class="nb">method</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">respond_to_missing</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">class</span><span class="p">.</span><span class="nf">search_method_with_cache</span><span class="p">(</span><span class="ss">:respond_to_missing?</span><span class="p">,</span> <span class="n">cc</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">respond_to_missing</span><span class="p">.</span><span class="nf">bind_call</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="nb">method</span><span class="p">)</span>
    <span class="k">end</span>

    <span class="kp">false</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>So it’s thankfully much less work than an uncached method lookup, but when <code class="language-plaintext highlighter-rouge">respond_to?</code> returns <code class="language-plaintext highlighter-rouge">false</code>
we’re still doing at least two hash lookups to get the corresponding call caches.</p>

<p>So you can see how calling <code class="language-plaintext highlighter-rouge">respond_to?</code> on <code class="language-plaintext highlighter-rouge">nil</code> is a bit of a waste.</p>

<h3 id="cheaper-argument-parsing">Cheaper Argument Parsing</h3>

<p>But enough digression, and back to the problem at hand.</p>

<p>In most cases, none of these options are set, so the goal is to avoid allocating an array,
and avoid <code class="language-plaintext highlighter-rouge">respond_to?</code> when possible, <a href="https://github.com/ruby/json/pull/616">which led me to rewrite <code class="language-plaintext highlighter-rouge">dump</code> as this</a>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">kwargs</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="k">if</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span>
      <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">anIO</span>
        <span class="n">anIO</span> <span class="o">=</span> <span class="kp">nil</span>
      <span class="k">end</span>
    <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
      <span class="n">kwargs</span> <span class="o">=</span> <span class="n">limit</span>
      <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="k">unless</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">nil?</span>
    <span class="k">if</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_io</span><span class="p">)</span>
      <span class="n">anIO</span> <span class="o">=</span> <span class="n">anIO</span><span class="p">.</span><span class="nf">to_io</span>
    <span class="k">elsif</span> <span class="n">limit</span><span class="p">.</span><span class="nf">nil?</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">anIO</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:write</span><span class="p">)</span>
      <span class="n">anIO</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">anIO</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="n">opts</span> <span class="o">=</span> <span class="no">JSON</span><span class="p">.</span><span class="nf">dump_default_options</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="ss">:max_nesting</span> <span class="o">=&gt;</span> <span class="n">limit</span><span class="p">)</span> <span class="k">if</span> <span class="n">limit</span>
  <span class="n">opts</span> <span class="o">=</span> <span class="n">merge_dump_options</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">if</span> <span class="n">kwargs</span>

  <span class="k">begin</span>
    <span class="k">if</span> <span class="no">State</span> <span class="o">===</span> <span class="n">opts</span>
      <span class="n">opts</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span><span class="p">)</span>
    <span class="k">else</span>
      <span class="no">State</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">opts</span><span class="p">,</span> <span class="n">anIO</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">rescue</span> <span class="no">JSON</span><span class="o">::</span><span class="no">NestingError</span>
    <span class="k">raise</span> <span class="no">ArgumentError</span><span class="p">,</span> <span class="s2">"exceed depth limit"</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>So instead of using <code class="language-plaintext highlighter-rouge">Array#compact</code>, we do multiple nested <code class="language-plaintext highlighter-rouge">if thing.nil?</code> checks. It’s more verbose, but much more efficient, allocations
free, and JIT very well.</p>

<p>The <code class="language-plaintext highlighter-rouge">is_a?(Hash)</code> calls are no performance concern on Ruby 3.2+ thanks to <a href="https://www.youtube.com/watch?v=qlq-iQGtCgs">John Hawthorn’s stellar work</a>, so they can stay.</p>

<p>As for <code class="language-plaintext highlighter-rouge">respond_to?</code>, we can’t fully eliminate it, but at least we can avoid calling it when the variable is <code class="language-plaintext highlighter-rouge">nil</code>, which should be most of the time.</p>

<p>All this combined yielded a nice <code class="language-plaintext highlighter-rouge">16%</code> improvement on micro benchmarks:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   227.226k i/100ms
Calculating -------------------------------------
               after      2.415M (± 0.9%) i/s  (414.02 ns/i) -     12.270M in   5.080537s

Comparison:
              before:  2078464.1 i/s
               after:  2415336.1 i/s - 1.16x  faster
</code></pre></div></div>

<p>After I merged that patch, <a href="https://github.com/eregon">Benoit Daloze</a> a fellow Ruby committer and TruffleRuby lead, suggested a funny trick that is
used very effectively in the Ruby stdlib for optimizing this sort of signature:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">anIO</span> <span class="o">=</span> <span class="p">(</span><span class="n">no_args_set</span> <span class="o">=</span> <span class="kp">true</span><span class="p">;</span> <span class="kp">nil</span><span class="p">),</span> <span class="n">limit</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">unless</span> <span class="n">no_args_set</span>
    <span class="c1"># do the whole argument parsing</span>
  <span class="k">end</span>

  <span class="c1"># ...</span>
<span class="k">end</span></code></pre></figure>

<p>I love that trick because it exploits the fact that, like pretty much everything in Ruby, arguments’ default values are expressions.</p>

<p>This trick is most commonly used when you need to know if an argument was passed as <code class="language-plaintext highlighter-rouge">nil</code> or just not passed, <a href="https://github.com/ruby/ruby/blob/8417d09f9381c93352fe2cddbdfd4144b5924979/hash.rb#L37-L39">an example of that
is <code class="language-plaintext highlighter-rouge">Hash#initialize</code></a></p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">class</span> <span class="nc">Hash</span>
  <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">ifnone</span> <span class="o">=</span> <span class="p">(</span><span class="n">ifnone_unset</span> <span class="o">=</span> <span class="kp">true</span><span class="p">),</span> <span class="ss">capacity: </span><span class="mi">0</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">block</span><span class="p">)</span>
    <span class="no">Primitive</span><span class="p">.</span><span class="nf">rb_hash_init</span><span class="p">(</span><span class="n">capacity</span><span class="p">,</span> <span class="n">ifnone_unset</span><span class="p">,</span> <span class="n">ifnone</span><span class="p">,</span> <span class="n">block</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>If it used the classic <code class="language-plaintext highlighter-rouge">ifnone = nil</code> signature, it wouldn’t be possible to differentiate <code class="language-plaintext highlighter-rouge">Hash.new</code> and <code class="language-plaintext highlighter-rouge">Hash.new(nil)</code>.</p>

<p>However in this case that trick didn’t make a measurable difference, so I didn’t include that suggestion, but I thought it was worth a mention.</p>

<h2 id="jump-tables">Jump Tables</h2>

<p>The previous optimization helped with the setup cost, but it was still way more expensive than it should.</p>

<p>So I went to craft an even more micro-benchmark, trying to reduce the time spent generating JSON to better see the setup cost:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s2">"json"</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">20_000_000</span>
<span class="n">obj</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>
  <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="no">JSON</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p><img src="/assets/articles/json-2/setup-cost-flamegraph-2.png" alt="" /></p>

<p><a href="https://share.firefox.dev/41EtIkw">Full profile.</a></p>

<p>As you may have spotted on that flame graph, a huge part of the setup is spent in <code class="language-plaintext highlighter-rouge">rb_hash_aref</code> and <code class="language-plaintext highlighter-rouge">rb_hash_has_key</code>, which are the
C API equivalents of <code class="language-plaintext highlighter-rouge">Hash#[]</code> and <code class="language-plaintext highlighter-rouge">Hash#key?</code>.</p>

<p>And all of this was in the <code class="language-plaintext highlighter-rouge">JSON::Generator::State#configure</code> method, implemented in C this way:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define option_given_p(opts, key) RTEST(rb_funcall(opts, i_key_p, 1, key))
</span>
<span class="k">static</span> <span class="n">VALUE</span> <span class="nf">cState_configure</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">self</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">opts</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">VALUE</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="n">GET_STATE</span><span class="p">(</span><span class="n">self</span><span class="p">);</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_check_convert_type</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">T_HASH</span><span class="p">,</span> <span class="s">"Hash"</span><span class="p">,</span> <span class="s">"to_hash"</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">NIL_P</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_convert_type</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">T_HASH</span><span class="p">,</span> <span class="s">"Hash"</span><span class="p">,</span> <span class="s">"to_h"</span><span class="p">);</span>
    <span class="n">opts</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_indent</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
        <span class="n">Check_Type</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">T_STRING</span><span class="p">);</span>
        <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">indent</span> <span class="o">=</span> <span class="n">fstrndup</span><span class="p">(</span><span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">tmp</span><span class="p">),</span> <span class="n">len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">indent_len</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_space</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">len</span><span class="p">;</span>
        <span class="n">Check_Type</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">T_STRING</span><span class="p">);</span>
        <span class="n">len</span> <span class="o">=</span> <span class="n">RSTRING_LEN</span><span class="p">(</span><span class="n">tmp</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">space</span> <span class="o">=</span> <span class="n">fstrndup</span><span class="p">(</span><span class="n">RSTRING_PTR</span><span class="p">(</span><span class="n">tmp</span><span class="p">),</span> <span class="n">len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">state</span><span class="o">-&gt;</span><span class="n">space_len</span> <span class="o">=</span> <span class="n">len</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// ....</span>

    <span class="n">tmp</span> <span class="o">=</span> <span class="n">ID2SYM</span><span class="p">(</span><span class="n">i_max_nesting</span><span class="p">);</span>
    <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">option_given_p</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">tmp</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">VALUE</span> <span class="n">max_nesting</span> <span class="o">=</span> <span class="n">rb_hash_aref</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">tmp</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">RTEST</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">))</span> <span class="p">{</span>
            <span class="n">Check_Type</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">,</span> <span class="n">T_FIXNUM</span><span class="p">);</span>
            <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="n">FIX2LONG</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">state</span><span class="o">-&gt;</span><span class="n">max_nesting</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span></code></pre></figure>

<p>Which again is very verbose and noisy because it’s in C, but is essentially the naive way you’d initialize some object state from an options hash:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">configure</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">indent</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:indent</span><span class="p">]</span>
    <span class="vi">@indent</span> <span class="o">=</span> <span class="n">ensure_string</span><span class="p">(</span><span class="n">indent</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="k">if</span> <span class="n">space</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:space</span><span class="p">]</span>
    <span class="vi">@space</span> <span class="o">=</span> <span class="n">ensure_string</span><span class="p">(</span><span class="n">space</span><span class="p">)</span>
  <span class="k">end</span>

  <span class="c1"># ...</span>

  <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">key?</span><span class="p">(</span><span class="ss">:max_nesting</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_nesting</span> <span class="o">=</span> <span class="n">opts</span><span class="p">[</span><span class="ss">:max_nesting</span><span class="p">]</span>
      <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="no">Integer</span><span class="p">(</span><span class="n">max_nesting</span><span class="p">)</span>
    <span class="k">else</span>
      <span class="vi">@max_nesting</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<h3 id="gccct">gccct</h3>

<p>On the surface, there is some weirdly inefficient code here, such as using:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">RTEST</span><span class="p">(</span><span class="n">rb_funcall</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">i_key_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">key</span><span class="p">))</span></code></pre></figure>

<p>To check if the option hash contains a key. Calling a method from C is quite costly because, you guessed it, looking up a method without a cache is costly.
Here again, we don’t have an inline cache, so Ruby has yet another trick down its sleeve to not make the performance atrocious,
the <code class="language-plaintext highlighter-rouge">gccct</code>. No I’m not having a stroke, it’s the acronym for “Global Call Cache Cache Table”, and yes it’s a cache of caches.</p>

<p>I did write <a href="https://twitter.com/_byroot/status/1831417434223604146">a Twitter thread back in September that talked about the <code class="language-plaintext highlighter-rouge">gccct</code></a>, but since
that site is quite hostile to outsiders, I’ll repeat some of it here.</p>

<p>The <code class="language-plaintext highlighter-rouge">gccct</code> is just a big global array of exactly <code class="language-plaintext highlighter-rouge">1023</code> <code class="language-plaintext highlighter-rouge">call_cache</code> objects, so when you need to lookup a method and there’s no better cache you can use,
you use one of these global caches:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span> <span class="o">=</span> <span class="mi">1023</span>
<span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE</span> <span class="o">=</span> <span class="no">Array</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gccct_method_search</span><span class="p">(</span><span class="n">receiver</span><span class="p">,</span> <span class="n">method_name</span><span class="p">)</span>
  <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">receiver</span><span class="p">.</span><span class="nf">class</span><span class="p">,</span> <span class="n">method_name</span><span class="p">].</span><span class="nf">hash</span> <span class="o">%</span> <span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE_SIZE</span>
  <span class="n">call_cache</span> <span class="o">=</span> <span class="no">GLOBAL_CALL_CACHE_CACHE_TABLE</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
  <span class="n">cached_method_search</span><span class="p">(</span><span class="n">receiver</span><span class="p">,</span> <span class="n">method_name</span><span class="p">,</span> <span class="n">call_cache</span><span class="p">)</span>
<span class="k">end</span></code></pre></figure>

<p>It’s as simple as that, we do a digest of the receiver class and the method name, and use that as an offset inside the array to select a call cache.</p>

<p>Of course, it can be subject to collisions, so distinct calls can end up sharing the same cache and make it flip-flop, but it still offers some decent
hit rate for cheap, so it’s better than nothing.</p>

<p>But that’s yet another digression because ultimately we just don’t need that at all, given the C API exposes some C functions
that allow us to check if a key exists without needing to go through method lookup. I suspect this may have been implemented this way
a long time ago to also support Hash-like objects, but it really isn’t worth the overhead.</p>

<p>In another Pull Request, <a href="https://github.com/luke-gru">Luke Gruber</a> had done <a href="https://github.com/ruby/json/pull/512/files#diff-2f079e65e9070fc3350059dbb4804c04be215ff9bed44144ee68b4de90faf2a6R20-R27">a similar optimization for the parser initialization</a>,
rewriting <code class="language-plaintext highlighter-rouge">option_given_p</code> into:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="n">VALUE</span> <span class="nf">hash_has_key</span><span class="p">(</span><span class="n">VALUE</span> <span class="n">hash</span><span class="p">,</span> <span class="n">VALUE</span> <span class="n">key</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">Qundef</span> <span class="o">==</span> <span class="n">rb_hash_lookup2</span><span class="p">(</span><span class="n">hash</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">Qundef</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">Qtrue</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">Qfalse</span><span class="p">;</span>
<span class="p">}</span>
<span class="cp">#define option_given_p(opts, key) (RTEST(hash_has_key(opts, key)))</span></code></pre></figure>

<p>And I could probably have done the same here, but I had another, less conventional, idea.</p>

<h3 id="inversion-of-priorities">Inversion of Priorities</h3>

<p>There’s probably a name for that optimization, but if so I don’t know it.</p>

<p>When thinking about the problem, it occurred to me that there are 13 possible option keys we need to check,
but in the vast majority of cases, the hash will only contain a few of them.</p>

<p>By default <code class="language-plaintext highlighter-rouge">JSON.dump</code> starts from the <code class="language-plaintext highlighter-rouge">JSON.dump_default_options</code> global config, so if you call dump with no extra options, that’s what we’ll get:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">  <span class="n">self</span><span class="p">.</span><span class="n">dump_default_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="o">:</span><span class="n">max_nesting</span> <span class="o">=&gt;</span> <span class="nb">false</span><span class="p">,</span>
    <span class="o">:</span><span class="n">allow_nan</span>   <span class="o">=&gt;</span> <span class="nb">true</span><span class="p">,</span>
    <span class="o">:</span><span class="n">script_safe</span> <span class="o">=&gt;</span> <span class="nb">false</span><span class="p">,</span>
  <span class="p">}</span></code></pre></figure>

<p>Actually, out of these 3 keys, the third one is useless, as it’s already the default, so really most of the time we only have two keys to check.</p>

<p>So what if instead of doing one to two lookups for every possible key (13), we’d iterate over the provided keys and use a <a href="https://en.wikipedia.org/wiki/Branch_table">jump table</a>?</p>

<p>The problem, however, is to do jump tables in C, you need a <code class="language-plaintext highlighter-rouge">switch</code> statement with static values, and hash keys are Ruby symbol objects, hence we can’t statically
know their value because they’re defined at runtime.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">switch</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">case</span> <span class="n">sym_max_nesting</span><span class="p">:</span> <span class="c1">// This is just not possible...</span>
    <span class="k">break</span><span class="p">;</span>
  
<span class="p">}</span></code></pre></figure>

<p>But what few people know, is that Ruby’s <code class="language-plaintext highlighter-rouge">case</code> statement do generate a jump table when possible. Let me show you:</p>

<p>By default Ruby’s <code class="language-plaintext highlighter-rouge">case</code> just compiles down to a series of <code class="language-plaintext highlighter-rouge">if / elsif</code>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="o">&lt;&lt;~</span><span class="no">RUBY</span><span class="p">).</span><span class="nf">disasm</span><span class="sh">
case key
when /foo/
  something
when /bar/
  something_else
end
</span><span class="no">RUBY</span>

<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(6,3)&gt;</span>
<span class="mo">0000</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:key</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="n">putobject</span>                              <span class="sr">/foo/</span>                     <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0005</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0007</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">000</span><span class="mi">9</span> <span class="n">branchif</span>                               <span class="mi">22</span>
<span class="mo">0011</span> <span class="n">putobject</span>                              <span class="sr">/bar/</span>                     <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0013</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0015</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0017</span> <span class="n">branchif</span>                               <span class="mi">27</span>
<span class="mo">001</span><span class="mi">9</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">1</span><span class="p">)</span>
<span class="mo">0020</span> <span class="n">putnil</span>
<span class="mo">0021</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0022</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0023</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">3</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0024</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0026</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0027</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">002</span><span class="mi">8</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">5</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">002</span><span class="mi">9</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something_else</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0031</span> <span class="n">leave</span></code></pre></figure>

<p>If you’re not familar with YARV assembly, here’s the “desugared” Ruby version of it:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">if</span> <span class="n">key</span> <span class="o">===</span> <span class="sr">/foo/</span>
  <span class="n">something</span>
<span class="k">elsif</span> <span class="n">key</span> <span class="o">===</span> <span class="sr">/bar/</span>
  <span class="n">something_else</span>
<span class="k">end</span></code></pre></figure>

<p>So it’s not a jump table, just some syntax sugar for <code class="language-plaintext highlighter-rouge">if / elsif</code>.
But if all the <code class="language-plaintext highlighter-rouge">when</code> values are essentially static (this includes literal numbers, literal symbols and literal strings),
Ruby generates some slightly different bytecode:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">puts</span> <span class="no">RubyVM</span><span class="o">::</span><span class="no">InstructionSequence</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="o">&lt;&lt;~</span><span class="no">RUBY</span><span class="p">).</span><span class="nf">disasm</span><span class="sh">
case key
when :foo
  something
when :bar
  something_else
end
</span><span class="no">RUBY</span>

<span class="o">==</span> <span class="ss">disasm: </span><span class="c1">#&lt;ISeq:&lt;compiled&gt;@&lt;compiled&gt;:1 (1,0)-(6,3)&gt;</span>
<span class="mo">0000</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">1</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0001</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:key</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0003</span> <span class="nb">dup</span>
<span class="mo">0004</span> <span class="n">opt_case_dispatch</span>                      <span class="o">&lt;</span><span class="n">cdhash</span><span class="o">&gt;</span><span class="p">,</span> <span class="mi">23</span>
<span class="mo">0007</span> <span class="n">putobject</span>                              <span class="ss">:foo</span>                      <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">000</span><span class="mi">9</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">0011</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0013</span> <span class="n">branchif</span>                               <span class="mi">26</span>
<span class="mo">0015</span> <span class="n">putobject</span>                              <span class="ss">:bar</span>                      <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0017</span> <span class="n">topn</span>                                   <span class="mi">1</span>
<span class="mo">001</span><span class="mi">9</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:===</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0021</span> <span class="n">branchif</span>                               <span class="mi">31</span>
<span class="mo">0023</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">1</span><span class="p">)</span>
<span class="mo">0024</span> <span class="n">putnil</span>
<span class="mo">0025</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0026</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">2</span><span class="p">)</span>
<span class="mo">0027</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">3</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">002</span><span class="mi">8</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0030</span> <span class="n">leave</span>                                                            <span class="p">(</span>   <span class="mi">5</span><span class="p">)</span>
<span class="mo">0031</span> <span class="n">pop</span>                                                              <span class="p">(</span>   <span class="mi">4</span><span class="p">)</span>
<span class="mo">0032</span> <span class="n">putself</span>                                                          <span class="p">(</span>   <span class="mi">5</span><span class="p">)[</span><span class="no">Li</span><span class="p">]</span>
<span class="mo">0033</span> <span class="n">opt_send_without_block</span>                 <span class="o">&lt;</span><span class="n">calldata!mid</span><span class="ss">:something_else</span><span class="p">,</span> <span class="n">argc</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="no">FCALL</span><span class="o">|</span><span class="no">VCALL</span><span class="o">|</span><span class="no">ARGS_SIMPLE</span><span class="o">&gt;</span>
<span class="mo">0035</span> <span class="n">leave</span></code></pre></figure>

<p>The thing to notice here is the <code class="language-plaintext highlighter-rouge">opt_case_dispatch</code> instruction, which wasn’t present on the previous disassembly.
What this instruction does, is that it holds a Hash, of which the keys are the static values we use in the <code class="language-plaintext highlighter-rouge">when</code> statements
and the values are the bytecode offset to which to directly jump. The rest of the bytecode is the same, to be used as the fallback
if the <code class="language-plaintext highlighter-rouge">opt_case_dispatch</code> doesn’t match.</p>

<p>With this, we can check as many symbols as we want in somewhat constant time, all we had to do was to rewrite all that nasty C code in Ruby,
<a href="https://github.com/ruby/json/pull/617/commits/25db79dfaa8f019077ef7e713a5aa62ff6af4a99">which I did in the most straightforward way in a preparatory commit</a>.
That commit alone already brought a <code class="language-plaintext highlighter-rouge">3%</code> improvement, thanks to inline caches:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   230.150k i/100ms
Calculating -------------------------------------
               after      2.450M (± 0.5%) i/s  (408.23 ns/i) -     12.428M in   5.073603s

Comparison:
              before:  2370478.1 i/s
               after:  2449616.3 i/s - 1.03x  faster
</code></pre></div></div>

<p>But I then followed up in the same pull request, with <a href="https://github.com/ruby/json/pull/617/commits/a75c9eccfd35e1d6715b05cbd7ef4d83b1bc177e">a rewrite of <code class="language-plaintext highlighter-rouge">State#configure</code> to use a case dispatch</a>:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">configure</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
  <span class="k">unless</span> <span class="n">opts</span><span class="p">.</span><span class="nf">is_a?</span><span class="p">(</span><span class="no">Hash</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">opts</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_hash</span><span class="p">)</span>
      <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">to_hash</span>
    <span class="k">elsif</span> <span class="n">opts</span><span class="p">.</span><span class="nf">respond_to?</span><span class="p">(</span><span class="ss">:to_h</span><span class="p">)</span>
      <span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">.</span><span class="nf">to_h</span>
    <span class="k">else</span>
      <span class="k">raise</span> <span class="no">TypeError</span><span class="p">,</span> <span class="s2">"can't convert </span><span class="si">#{</span><span class="n">opts</span><span class="p">.</span><span class="nf">class</span><span class="si">}</span><span class="s2"> into Hash"</span>
    <span class="k">end</span>
  <span class="k">end</span>

  <span class="n">opts</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">|</span>
    <span class="k">case</span> <span class="n">key</span>
    <span class="k">when</span> <span class="ss">:indent</span>
      <span class="nb">self</span><span class="p">.</span><span class="nf">indent</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">when</span> <span class="ss">:space</span>
      <span class="nb">self</span><span class="p">.</span><span class="nf">space</span> <span class="o">=</span> <span class="n">value</span>
    <span class="c1"># ...</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></figure>

<p>And that brought a further <code class="language-plaintext highlighter-rouge">11%</code> improvement:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Encoding small mixed (34 bytes)
ruby 3.4.0rc1 (2024-12-12 master 29caae9991) +YJIT +PRISM [arm64-darwin23]
Warming up --------------------------------------
               after   247.127k i/100ms
Calculating -------------------------------------
               after      2.645M (± 0.6%) i/s  (378.07 ns/i) -     13.345M in   5.045454s

Comparison:
              before:  2379291.6 i/s
               after:  2645019.6 i/s - 1.11x  faster
</code></pre></div></div>

<p>So the rewrite in Ruby was a win-win, less C code to maintain, and more efficiency overall.</p>

<h2 id="to-be-continued">To Be Continued</h2>

<p>I only talked about two small optimizations, but I digressed so much that it’s already longer than part one,
and I probably won’t have time to write in the next few days, so it’s probably best if I stop here for part two.</p>

<p>At this rate, and based only on the number of commits I haven’t yet covered, I may need 5 or 6 more parts,
but I hope I won’t have to disgress as much as the series progress, and not all commits may be worth talking about.</p>

<p>Edit: <a href="/ruby/json/2024/12/27/optimizing-ruby-json-part-3.html">Part three is here</a>.</p>]]></content><author><name></name></author><category term="ruby" /><category term="json" /><summary type="html"><![CDATA[In the previous post, I covered my motivations for improving ruby/json’s performance, and detailed the first 4 notable optimizations applied to speed up JSON generation.]]></summary></entry></feed>